{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to My Blog","text":"<p>AI Engineer @ Microsoft | Building LLM &amp; RAG Apps | Always learning, exploring and sharing the frontiers of AI.</p>"},{"location":"404/","title":"404 - Page not found","text":"<p>Sorry, the page you were looking for doesn't exist.</p>"},{"location":"404/#what-might-have-happened","title":"What might have happened?","text":"<ul> <li>The page might have been moved or deleted</li> <li>You might have followed a broken link</li> <li>There might be a typo in the URL</li> </ul>"},{"location":"404/#what-can-you-do-now","title":"What can you do now?","text":"<ul> <li>Go back to the homepage</li> <li>Use the search function at the top of the page</li> </ul>"},{"location":"drafts/Andrej-DeepDiveIntoLLMs/","title":"Pretraining","text":"<p>training a neural network meaning just discover a set of parameters that seems to be consistent with statistics of the training data.</p> <ol> <li>When you talk to ChatGPT, you are talking to labeling engineers.</li> </ol>"},{"location":"drafts/Andrej-DeepDiveIntoLLMs/#hallucinations","title":"Hallucinations:","text":"<p>Mitigation #1:</p> <p>Use model interrogation to discover model's knowledge, and programmatically augment its training dataset with knowledge-based refusals in cases where the model doesn't know.</p> <p>Mitigation #2: Allow the model to search.</p> <p>Vague recollection vs working memory: Knowledge in the parameters == Vague recollection (e.g. of something you read 1 month ago) Knowledge in the tokens of the context window == Working memory </p>"},{"location":"drafts/Andrej-DeepDiveIntoLLMs/#knowledge-self","title":"Knowledge self:","text":"<p>The LLM has no knowledge of self \"out of the box\" If you do nothing, it will probably think it is ChatGPT, developed by OpenAl. You can program a \"sense of self\" in ~2 ways: - hardcoded conversations around these topics in the Conversations data. - \"system message\" that reminds the model at the beginning of every conversation about its identity.</p>"},{"location":"drafts/Andrej-DeepDiveIntoLLMs/#models-need-tokens-to-think","title":"Models need tokens to think:","text":""},{"location":"drafts/Andrej-DeepDiveIntoLLMs/#models-cant-count","title":"Models can't count","text":""},{"location":"drafts/Andrej-DeepDiveIntoLLMs/#models-are-not-good-with-spelling","title":"Models are not good with spelling.","text":""},{"location":"drafts/Andrej-DeepDiveIntoLLMs/#resources","title":"Resources:","text":"<p>https://tiktokenizer.vercel.app/?model=cl100k_base https://bbycroft.net/llm</p> <p>Old model: https://huggingface.co/playground?modelId=tiiuae/falcon-7b-instruct</p> <p>The Llama 3 Herd of Models: https://arxiv.org/abs/2407.21783</p>"},{"location":"2024/10/27/the-purpose-of-1-1s/","title":"The purpose of 1-1s","text":"","tags":["Growth"]},{"location":"2024/10/27/the-purpose-of-1-1s/#first-they-create-human-connection-between-you-and-your-manager","title":"First, they create human connection between you and your manager.","text":"<ol> <li>That doesn\u2019t mean you spend the whole time talking about your hobbies or families or making small talk about the weekend. </li> <li>But letting your manager into your life a little bit is important, because when there are stressful things happening, it will be much easier to ask your manager for time off or tell him what you need if he has context on you as a person.</li> <li>Being an introvert is not an excuse for making no effort to treat people like real human beings, however. The bedrock of strong teams is human connection, which leads to trust.</li> </ol>","tags":["Growth"]},{"location":"2024/10/27/the-purpose-of-1-1s/#second-1-1-is-a-regular-opportunity-for-you-to-speak-privately-with-your-manager","title":"Second, 1-1 is a regular opportunity for you to speak privately with your manager.","text":"<ol> <li>Expect your 1-1s to be scheduled with some predictability. So that you can plan for them, because it is not your manager\u2019s job to completely control the 1-1 agenda.</li> <li>That\u2019s OK,  don\u2019t do 1-1s regularly, or only do every few weeks. So long as you don\u2019t eliminate them completely. </li> <li>Ask more, if you find that you want to meet more frequently.</li> <li>Good 1-1s are not status meetings.<ol> <li>If your 1-1 is a dreadful obligation for delivering a boring status report, try using email or chat for that purpose instead to free up the time, and bringing some topics of your own to the 1-1.</li> </ol> </li> <li>Come with an agenda of things you would like to discuss. Share the responsibility of having good 1-1s with your manager. </li> <li>Ensure Your 1-1. If your manager cancels or reschedules on you regularly, push him to find a time that is more stable, or verify the day before (or that morning, for an afternoon meeting) that you will be meeting and share with him anything you are interested in discussing so he knows you want to meet.</li> </ol>","tags":["Growth"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/","title":"Microsoft Research: Why AI Agents Are the Next Big Thing in Tech (Podcast Summary)","text":"","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#understanding-ai-agents","title":"Understanding AI Agents","text":"<ul> <li>Defined as AI-based entities that can:</li> <li>Perceive their environment</li> <li>Act continuously to complete tasks</li> <li>Use tools and take actions in the real world</li> <li>Represents a paradigm shift from traditional AI models</li> <li>Focus on practical value and real-world applications</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#current-challenges-and-concerns","title":"Current Challenges and Concerns","text":"<ol> <li>Value Creation</li> <li>Need to move beyond simple input-output interactions</li> <li>Focus on building systems that are environment-aware</li> <li> <p>Emphasis on practical user value</p> </li> <li> <p>Responsible AI Development</p> </li> <li>Importance of addressing real problems rather than hypotheticals</li> <li>Need for proper resource allocation in addressing societal impacts</li> <li>Criticism of \"pause AI development\" approach</li> <li> <p>Advocacy for continued investment in responsible AI research</p> </li> <li> <p>Misconceptions and Media Representation</p> </li> <li>Discussion of the Task Rabbit anecdote controversy</li> <li>Concerns about misleading representations of AI capabilities</li> <li>Need for honest communication about AI's current state</li> </ol>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#speaker-background-ajek-amar","title":"Speaker Background: Ajek Amar","text":"<ul> <li>Current Role: VP of Research at Microsoft, Managing Director of AI Frontiers</li> <li>Academic Background: PhD from Harvard (2005-2010)</li> <li>Focus on Human-AI collaboration</li> <li>Studied under Barbara Gross</li> <li>Career Path:</li> <li>Started with Microsoft Research through internships</li> <li>Worked on various projects including ride-sharing systems</li> <li>Spent first decade focusing on responsible AI development</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#evolution-from-models-to-agents","title":"Evolution from Models to Agents","text":"<ul> <li>Traditional AI models are being transformed into more sophisticated agent-based systems</li> <li>Agents can perceive and interact with the world continuously</li> <li>Focus on delivering practical value rather than just input-output demonstrations</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#multi-agent-systems","title":"Multi-Agent Systems","text":"<ul> <li>Provides a programming paradigm for complex AI tasks</li> <li>Allows task decomposition into specialized components</li> <li>Each agent can focus on specific capabilities or expertise</li> <li>Orchestration can be managed through:</li> <li>Human-created workflows</li> <li>LLM-based orchestration and planning</li> <li>Hybrid approaches</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#autogen-overview","title":"Autogen Overview","text":"<ul> <li>Open-source multi-agent orchestration library by Microsoft</li> <li>Released in October 2023</li> <li>Features:</li> <li>Task definition and decomposition</li> <li>Agent creation and collaboration</li> <li>Community-driven development</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#autogen-new-version","title":"Autogen (New Version)","text":"<ul> <li>Scales to millions of agents</li> <li>Supports persistent agents</li> <li>Enhanced agent discovery</li> <li>Designed for organizational integration</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#real-world-applications","title":"Real-World Applications","text":"<ul> <li>Consumer simulation for large organizations</li> <li>Automation of time-consuming tasks (e.g., expense reporting)</li> <li>Large-scale simulations for society and science</li> <li>Organization-specific persistent agent teams</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#impact-and-significance","title":"Impact and Significance","text":"<ul> <li>Represents a paradigm shift in AI implementation</li> <li>Enables more sophisticated and practical AI solutions</li> <li>Provides value through real-world task completion</li> <li>Facilitates better understanding of consumer behavior</li> <li>Supports large-scale simulation and testing capabilities</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#research-and-innovation","title":"Research and Innovation","text":"<ul> <li>Organizations are pushing the frontiers of AI technology rapidly</li> <li>Focus is shifting to learning from AI rather than teaching it</li> <li>Emphasis on understanding how to effectively use tools like OTGEN</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#large-scale-simulations","title":"Large-Scale Simulations","text":"<ul> <li>Reference to Michael Bernstein's team at Stanford's work on SIM simulations</li> <li>Multi-agent systems where computer agents interact with each other</li> <li>Potential applications:</li> <li>Simulating different demographics</li> <li>Modeling political views</li> <li>Understanding organizational dynamics</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#scientific-discovery-and-ai","title":"Scientific Discovery and AI","text":"<ul> <li>Integration of AI models into scientific discovery</li> <li>Changes in scientific methodology through AI implementation</li> <li>Use of GPT-01 and chain of thought reasoning</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#multi-agent-solutions-and-safety-measures","title":"Multi-Agent Solutions and Safety Measures","text":"","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#current-developments","title":"Current Developments","text":"<ul> <li>Implementation of compliance-monitoring agents</li> <li>Development of agents to detect and correct hallucinations</li> <li>Creation of privacy proxy agents to protect user information</li> <li>Establishment of information-sharing boundaries between agents</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#challenges","title":"Challenges","text":"<ol> <li>System Reliability</li> <li>Current systems are stochastic</li> <li>Lack of 100% guarantees for agent behavior</li> <li> <p>Need for stronger verification techniques</p> </li> <li> <p>Human Factors</p> </li> <li>Automation bias concerns</li> <li>Risk of over-dependence on AI systems</li> <li>Challenge of maintaining human understanding of complex systems</li> </ol>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#future-research-and-development-needs","title":"Future Research and Development Needs","text":"","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#priority-areas","title":"Priority Areas","text":"<ol> <li>Interdisciplinary Research</li> <li>Integration of verification techniques with LLMs</li> <li>Translation of past safety practices to new AI systems</li> <li> <p>Development of guaranteed privacy and safety measures</p> </li> <li> <p>Responsible AI Development</p> </li> <li>Focus on design, development, and deployment safety</li> <li>Implementation of mitigation strategies and controls</li> <li>Learning from previous automation experiences (e.g., aviation industry)</li> </ol>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#suggested-solutions","title":"Suggested Solutions","text":"<ol> <li>System Architecture Improvements</li> <li>Reducing system stochasticity</li> <li>Building better transparency layers</li> <li> <p>Implementing pattern recognition for consistent behavior</p> </li> <li> <p>Human-AI Interaction</p> </li> <li>Development of appropriate attention-checking mechanisms</li> <li>Creation of effective transparency layers</li> <li>Balance between automation and human oversight</li> </ol>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#urgent-concerns","title":"Urgent Concerns","text":"<ul> <li>Rapid pace of AI development versus safety research</li> <li>Need for quick implementation of safety measures</li> <li>Challenge of retrofitting safety features into existing systems</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#community-innovation-and-development","title":"Community Innovation and Development","text":"<ul> <li>The AI community is collectively building and innovating</li> <li>Focus should be on solving real problems rather than hypothetical scenarios</li> <li>Need for coordinated efforts to address current challenges</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#enterprise-implementation","title":"Enterprise Implementation","text":"<ul> <li>AI agents are primarily being adopted in enterprise scenarios</li> <li>Value proposition:</li> <li>Automation of well-defined processes</li> <li>Clear financial benefits</li> <li>Companies across various sectors (not just tech) are developing agent solutions</li> <li>Lower barrier to entry for developing AI solutions</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#no-code-solutions","title":"No-Code Solutions","text":"<ul> <li>Growing demand for no-code agent development</li> <li>Notable developments:</li> <li>AutoGen Studio (research prototype)</li> <li>Microsoft Copilot Studio</li> <li>Focus on making agent development accessible to non-programmers</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#future-directions","title":"Future Directions","text":"","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#composable-agents","title":"Composable Agents:","text":"<ul> <li>Development of reusable and composable agents</li> <li>Potential for agent marketplace</li> <li>Ability to \"hire\" specialized agents for specific tasks</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#specialized-models","title":"Specialized Models:","text":"<ul> <li>Research focus on small, specialized models</li> <li>Custom capabilities for specific domains</li> <li>Improved efficiency through targeted model development</li> </ul>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/microsoft-research-why-ai-agents-are-the-next-big-thing-in-tech-podcast-summary/#challenges-and-considerations","title":"Challenges and Considerations","text":"<ul> <li>Need to balance speed with proper implementation</li> <li>Importance of practical problem-solving over theoretical discussions</li> <li>Focus on real-world applications and solutions</li> </ul> <p>Podcast link: Eye on AI - #214 Ece Kamar: Why AI Agents Are the Next Big Thing in Tech (Microsoft Research)</p>","tags":["AI Engineering","AI Agents"]},{"location":"2024/10/15/top-best-practices-for-building-production-ready-ai-apps/","title":"Top best practices for building production-ready AI apps","text":"<ol> <li>Build evals </li> <li> <p>Define test cases to ensure you're actively improving your app &amp; not causing any regressions.</p> </li> <li> <p>Break down one LLM call into multiple </p> </li> <li> <p>AI systems do a lot better when you have many LLM calls chained together. i.e, instead of sending an LLM call to a model to generate code, send it to a \"architect\" model to generate a plan, then a \"coding\" model to generate code, then a \"reviewer\" model to verify.</p> </li> <li> <p>Start simple (with 1 LLM call)</p> </li> <li>Then iterate with prompt engineering (few shot examples, chain of thought, descriptive prompts) before building a more complex system with chained LLM calls.</li> </ol> <ol> <li>Use RAG </li> <li> <p>When dealing with data you need the LLM to use as context, use RAG (then iterate with your evals to try different chunking/embedding strategies, adding a re-ranker, etc.).</p> </li> <li> <p>Use finetuning</p> </li> <li> <p>When you want to have the LLM optimize on a domain-specific thing or on a specific style (i.e, write emails like you do), use finetuning.</p> </li> <li> <p>When launching, ship with observability and look at the data </p> </li> <li>It's so important to look at how people are using your system, then you can do things like segment customer prompts, run evals on them, and get great info on where you need to improve your AI system.</li> </ol> <p>(source: @nutlope)</p>","tags":["AI Engineering"]},{"location":"2025/01/12/building-effective-agents/","title":"Building effective agents","text":""},{"location":"2025/01/12/building-effective-agents/#what-are-agents","title":"What are agents?","text":"<p>\"Agent\" can be defined in several ways. Some define agents as fully autonomous systems that operate independently over extended periods, using various tools to accomplish complex tasks. Others use the term to describe more prescriptive implementations that follow predefined workflows. At Anthropic, they categorize all these variations as agentic systems, but draw an important architectural distinction between workflows and agents:</p> <ul> <li>Workflows are systems where LLMs and tools are orchestrated through predefined code paths.</li> <li>Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.</li> </ul> <p>Below, we will explore both types of agentic systems in detail.</p>"},{"location":"2025/01/12/building-effective-agents/#when-and-when-not-to-use-agents","title":"When (and when not) to use agents","text":"<p>When building applications with LLMs, we recommend finding the simplest solution possible, and only increasing complexity when needed. This might mean not building agentic systems at all. Agentic systems often trade latency and cost for better task performance, and you should consider when this tradeoff makes sense.</p> <p>When more complexity is warranted, workflows offer predictability and consistency for well-defined tasks, whereas agents are the better option when flexibility and model-driven decision-making are needed at scale. For many applications, however, optimizing single LLM calls with retrieval and in-context examples is usually enough.</p>"},{"location":"2025/01/12/building-effective-agents/#when-and-how-to-use-frameworks","title":"When and how to use frameworks","text":"<p>There are many frameworks that make agentic systems easier to implement, including: LangGraph from LangChain, Autogen from Microswoft, and LlamaIndex, etc.</p> <p>These frameworks make it easy to get started by simplifying standard low-level tasks like calling LLMs, defining and parsing tools, and chaining calls together. However, they often create extra layers of abstraction that can obscure the underlying prompts \u200b\u200band responses, making them harder to debug. They can also make it tempting to add complexity when a simpler setup would suffice.</p> <p>We suggest that developers start by using LLM APIs directly: many patterns can be implemented in a few lines of code. If you do use a framework, ensure you understand the underlying code. Incorrect assumptions about what's under the hood are a common source of customer error.</p>"},{"location":"2025/01/12/building-effective-agents/#building-blocks-workflows-and-agents","title":"Building blocks, workflows, and agents","text":""},{"location":"2025/01/12/building-effective-agents/#building-block-the-augmented-llm","title":"Building block: The augmented LLM","text":"<p>The basic building block of agentic systems is an LLM enhanced with augmentations such as retrieval, tools, and memory. </p>"},{"location":"2025/01/12/building-effective-agents/#workflow-prompt-chaining","title":"Workflow: Prompt chaining","text":"<p>This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task. </p>"},{"location":"2025/01/12/building-effective-agents/#workflow-routing","title":"Workflow: Routing","text":"<p>Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model/algorithm. </p>"},{"location":"2025/01/12/building-effective-agents/#workflow-parallelization","title":"Workflow: Parallelization","text":"<p>Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results. For complex tasks with multiple considerations, LLMs generally perform better when each consideration is handled by a separate LLM call, allowing focused attention on each specific aspect. </p>"},{"location":"2025/01/12/building-effective-agents/#workflow-orchestrator-workers","title":"Workflow: Orchestrator-workers","text":"<p>This workflow is well-suited for complex tasks where you can\u2019t predict the subtasks needed (in coding, for example, the number of files that need to be changed and the nature of the change in each file likely depend on the task). Whereas it\u2019s topographically similar, the key difference from parallelization is its flexibility\u2014subtasks aren't pre-defined, but determined by the orchestrator based on the specific input.</p> <p></p>"},{"location":"2025/01/12/building-effective-agents/#workflow-evaluator-optimizer","title":"Workflow: Evaluator-optimizer","text":"<p>This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document. </p>"},{"location":"2025/01/12/building-effective-agents/#agents","title":"Agents","text":"<p>Agents are typically just LLMs using tools based on environmental feedback in a loop. </p> <p></p> <p>via</p>"},{"location":"2024/10/15/globalizing-your-startupone-person-company/","title":"Globalizing Your Startup/One Person Company","text":"","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#tldr","title":"TL;DR","text":"<ol> <li>Building in Public</li> <li>Individual Entrepreneurship is a Future Trend</li> <li>AI and remote work make one-person companies more feasible.</li> <li>No Need to Overly Rely on Funding; Start with Lean Startup Methods</li> <li>Register Platforms and Services as a Company, Not as an Individual </li> <li>Using a company entity can mitigate the risk of unlimited personal liability.</li> </ol>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#building-in-public","title":"Building in Public","text":"<ul> <li>Build a personal brand through social media.</li> <li>Sharing genuine stories and experiences is more effective than purely promoting products.</li> <li>Consistently create content to build an audience.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#ways-to-identify-product-needs","title":"Ways to Identify Product Needs","text":"<ul> <li>Solve your own real-world problems.</li> <li>Observe successful examples.</li> <li>Discover needs through user comments on official forums and communities.</li> <li>Seek opportunities in new products and trends, such as:</li> <li>Apple Vision Pro</li> <li>Meta Threads</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#product-development-strategy","title":"Product Development Strategy","text":"<ul> <li>Start with a small niche to avoid creating a large, all-encompassing product from the beginning.</li> <li>Choose a niche market to avoid direct competition with big companies.</li> <li>Focus on product differentiation and competitive advantages.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#product-pricing","title":"Product Pricing","text":"<ul> <li>Consider setting a higher price; avoid underpricing.</li> <li>Higher pricing helps users recognize the product\u2019s value.</li> <li>Adjust prices through discounts and other offers.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#product-launch-and-marketing","title":"Product Launch and Marketing","text":"<ul> <li>Launch on ProductHunt.</li> <li>Submit products to directory sites.</li> <li>Market on Reddit communities.</li> <li>Email marketing (especially cold emails).</li> <li>Paid advertising.</li> <li>Influencer marketing (with careful evaluation).</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#use-terms-like-independent-creator-or-one-person-company-instead-of-independent-developer","title":"Use Terms Like \"Independent Creator\" or \"One-Person Company\" Instead of \"Independent Developer\"","text":"<ul> <li>Creating products is more than just coding.</li> <li>It involves product design, operations, marketing, and other areas.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#avoid-over-reliance-on-funding","title":"Avoid Over-Reliance on Funding","text":"<ul> <li>The goal of an independent creator or one-person company is to achieve stable income, not explosive growth.</li> <li>Do what you want without restrictions from investors.</li> <li>Maintain full control over your product and company.</li> <li>Start with a lean approach:</li> <li>Begin on a small scale.</li> <li>Improve the product based on user feedback.</li> <li>Support growth with revenue to achieve sustainable development.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#company-registration-and-compliance","title":"Company Registration and Compliance","text":"<ul> <li>Register platforms and services as a company entity rather than as an individual.</li> <li>Using a company entity can help avoid the risk of unlimited personal liability.</li> <li>Avoid using informal registration methods to prevent account bans and personal data from being blacklisted.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#team-collaboration","title":"Team Collaboration","text":"<ul> <li>Be cautious when choosing partners.</li> <li>Build trust through long-term collaboration.</li> <li>Consider hiring agents or outsourcing teams.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#social-media-management","title":"Social Media Management","text":"<ul> <li>Run both English and Chinese accounts.</li> <li>Personal accounts are more relatable to users than brand accounts.</li> <li>Share personal stories and experiences to increase engagement.</li> <li>Actively interact and build connections:</li> <li>Respond to others' original posts.</li> <li>Engage in proactive outreach.</li> </ul>","tags":["Startup"]},{"location":"2024/10/15/globalizing-your-startupone-person-company/#platform-selection-suggestions","title":"Platform Selection Suggestions","text":"<ul> <li>Independent developer communities are primarily active on Twitter.</li> <li>Fashion and younger audiences prefer Instagram.</li> <li>Choose platforms based on target audience; go where your users are.</li> </ul> <p>Host: Guo Xiaoli Guest: @LuoSays / Chuhaiqu Incubator X Space Recording: Entrepreneurial Exchange: Basics for Independent Developers Going Global</p>","tags":["Startup"]},{"location":"2024/10/15/how-elon-musk-is-so-effective/","title":"How Elon Musk is so effective","text":"","tags":["Productivity"]},{"location":"2024/10/15/how-elon-musk-is-so-effective/#operating-philosophy","title":"Operating philosophy","text":"<ul> <li>Relentlessly focused on weekly progress</li> <li>The Elon method boiled all the way down is \"what have you gotten done this week?\"</li> <li>Rejects traditional corporate timelines and long-term planning over months and years</li> </ul>","tags":["Productivity"]},{"location":"2024/10/15/how-elon-musk-is-so-effective/#engineering-first-approach","title":"Engineering-first approach","text":"<ul> <li>Works predominantly with engineers</li> <li>Personally understands all technical systems</li> <li>Avoids non-engineering meetings/conversations when possible, joins all the core engineering focused meetings</li> <li>Skips management layers completely</li> <li>Talks directly to person in charge of specific project</li> <li>He's in there with 24-year-old engineers and they'll just walk through fire for him</li> <li>Engineers deeply respect his technical knowledge</li> </ul>","tags":["Productivity"]},{"location":"2024/10/15/how-elon-musk-is-so-effective/#weekly-problem-solving-method","title":"Weekly problem-solving method","text":"<ul> <li>Identifies key bottleneck at each company weekly</li> <li>Works directly with engineers to fix it that same week</li> <li>Maintains this pace across multiple companies simultaneously</li> <li>Late night work sessions are normal</li> </ul>","tags":["Productivity"]},{"location":"2024/10/15/how-elon-musk-is-so-effective/#rapid-iteration","title":"Rapid iteration","text":"<ul> <li>Embraces public failure as learning opportunity</li> <li>SpaceX:<ul> <li>Ran through five rocket generations of which four would fail but he would learn so much that the fifth one would work</li> <li>Would go through the five generations faster than his rocket competitors could do one generation</li> <li>Willing to have rockets explode in testing</li> </ul> </li> <li>Doesn't let public perception slow progress</li> </ul>","tags":["Productivity"]},{"location":"2024/10/15/how-elon-musk-is-so-effective/#first-principles-thinking","title":"First principles thinking","text":"<ul> <li>Gets to fundamental reality quickly</li> <li>Eliminates unnecessary processes</li> <li>Focuses purely on substance</li> <li>Rejects traditional corporate structure</li> <li>No Powerpoint presentations</li> <li>Minimal documentation</li> </ul>","tags":["Productivity"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/","title":"Playwright vs Puppeteer vs Selenium","text":"<p>In today\u2019s fast-paced development landscape, automated browser testing and web scraping are more vital than ever. Three of the most prominent tools in this space are Selenium, Puppeteer, and Playwright. Each has its unique strengths and target use cases. In this post, we\u2019ll explore how they stack up in terms of browser support, language options, performance, ease of use, and more.</p> <p>However, for the most powerful and reliable option, Playwright is the best of the three.</p>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview </li> <li>Supported Browsers </li> <li>Language Support </li> <li>Key Features </li> <li>Performance &amp; Reliability </li> <li>Ease of Use </li> <li>When to Choose Each Tool </li> <li>Conclusion</li> </ol>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#overview","title":"Overview","text":"Tool Description Primary Use Cases Selenium One of the oldest and most widely used frameworks for cross-browser testing. It automates browsers via the WebDriver protocol. Traditional E2E testing in large, legacy, or multi-language projects. Puppeteer A Node.js library providing a high-level API to control Chromium-based browsers (Chrome, Edge), developed by the Chrome DevTools team at Google. Fast, headless browser automation for Chrome/Chromium, often used in CI/CD pipelines. Playwright A newer cross-browser automation tool from Microsoft, supporting Chromium, Firefox, and WebKit under one unified API. Modern E2E testing with parallel execution, auto-waiting, and a robust feature set.","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#supported-browsers","title":"Supported Browsers","text":"<ul> <li>Selenium </li> <li>Officially supports Chrome, Firefox, Safari, Edge, and even Internet Explorer (via individual WebDriver executables).  </li> <li> <p>Excellent for legacy browser coverage in enterprise environments.</p> </li> <li> <p>Puppeteer </p> </li> <li>Primarily designed for Chromium (Chrome, Edge).  </li> <li> <p>Has experimental Firefox support, but it\u2019s not as mature or complete.</p> </li> <li> <p>Playwright </p> </li> <li>Provides native support for Chromium (Chrome, Edge), Firefox, and WebKit (Safari-like) using a single, consistent API.  </li> <li>Simplifies cross-browser coverage significantly.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#language-support","title":"Language Support","text":"<ul> <li>Selenium </li> <li>Offers multi-language support (Java, Python, C#, Ruby, JavaScript, etc.) via WebDriver.  </li> <li> <p>Large ecosystem, extensive community-driven documentation in each language.</p> </li> <li> <p>Puppeteer </p> </li> <li>Node.js only (JavaScript/TypeScript).  </li> <li> <p>Great for teams already using Node-based tooling.</p> </li> <li> <p>Playwright </p> </li> <li>Officially supports JavaScript/TypeScript, Python, .NET, and Java.  </li> <li>Continues to expand documentation and community support across all these languages.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#key-features","title":"Key Features","text":"","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#selenium","title":"Selenium","text":"<ul> <li>Mature ecosystem with many integrations (e.g., Selenium Grid for parallelization).  </li> <li>Works with older browsers and suits enterprise contexts.  </li> <li>Can be more verbose, requiring manual waits or condition checks.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#puppeteer","title":"Puppeteer","text":"<ul> <li>Fast, high-level API for controlling Chromium-based browsers.  </li> <li>Ideal for headless operations (CI, scraping, PDF generation).  </li> <li>Straightforward network interception, DOM manipulation, and screenshot/PDF features.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#playwright","title":"Playwright","text":"<ul> <li>Cross-browser out of the box: Chromium, Firefox, WebKit.  </li> <li>\u201cBatteries-included\u201d approach, especially in JavaScript/TypeScript with the <code>@playwright/test</code> runner.  </li> <li>Rich debugging features: auto-wait, screenshots, video recording, parallelization, and tracing.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#performance-reliability","title":"Performance &amp; Reliability","text":"<ul> <li>Selenium </li> <li>Interacts with browsers via the WebDriver protocol, which can be slower compared to direct DevTools connections.  </li> <li> <p>Generally stable but can become flaky if not carefully managed with explicit waits or synchronization.</p> </li> <li> <p>Puppeteer </p> </li> <li>Uses the DevTools Protocol for direct communication with Chromium, enabling faster and more reliable actions.  </li> <li> <p>Chrome/Chromium-specific focus can be a limitation if you need broader coverage.</p> </li> <li> <p>Playwright </p> </li> <li>Similar to Puppeteer for Chromium but also implements low-level integrations for Firefox and WebKit.  </li> <li>Auto-wait for elements reduces flakiness; the built-in test runner supports concurrency with minimal setup.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#ease-of-use","title":"Ease of Use","text":"<ul> <li>Selenium </li> <li>Requires more boilerplate (e.g., driver management).  </li> <li> <p>Extremely large community and many add-on frameworks, but this can mean a steeper learning curve compared to modern \u201cbatteries-included\u201d solutions.</p> </li> <li> <p>Puppeteer </p> </li> <li>Straightforward API for Chrome/Chromium automation.  </li> <li> <p>Good fit if you only need one browser and prefer a simpler Node.js library.</p> </li> <li> <p>Playwright </p> </li> <li>\u201cEverything you need\u201d out of the box (in JS/TS, the <code>@playwright/test</code> framework includes parallel tests, advanced debugging, and more).  </li> <li>Modern design handles common flakiness issues and concurrency with minimal extra code.</li> </ul>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#when-to-choose-each-tool","title":"When to Choose Each Tool","text":"<ol> <li>Selenium </li> <li>You need the widest browser coverage, including older browsers like Internet Explorer 11.  </li> <li>Large or enterprise environments already heavily invested in Selenium.  </li> <li> <p>You appreciate its mature ecosystem and the ability to use virtually any programming language.</p> </li> <li> <p>Puppeteer </p> </li> <li>You only require Chrome/Chromium and/or want a minimal overhead for headless testing or web scraping.  </li> <li>You\u2019re a Node.js user seeking a straightforward library with direct DevTools integration.  </li> <li> <p>Ideal for simpler workflows where cross-browser coverage isn\u2019t a priority.</p> </li> <li> <p>Playwright </p> </li> <li>You want a single modern API that covers Chromium, Firefox, and WebKit.  </li> <li>You value built-in features like auto-wait, parallelization, and full-page screenshots/traces without extra dependencies.  </li> <li>You\u2019re starting a new project and want a modern, robust approach that helps prevent flaky tests.</li> </ol>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/01/12/playwright-vs-puppeteer-vs-selenium/#my-favorite-playwright","title":"My favorite: Playwright","text":"<p>Since its launch, Playwright has evolved to become a comprehensive automation solution.</p> <p>Built with a more modern architecture, it works across Chrome, Firefox, and Safari browsers, solving a plethora of issues that arose with other contemporaries like Puppeteer and Selenium.</p> <p>One of the main benefits of Playwright is its simple syntax with powerful abstractions behind the scenes. This lets users write tests that look like real user actions. These actions happen when using a web application. This means that the code is not only easier to read and understand but also more maintainable over time. Developers can easily understand the purpose of the code. This makes it simpler to work with team members or help new developers join.</p> <p>A code example of how Playwright works: <pre><code>// Playwright\n\nimport { chromium } from 'playwright';\n\n(async () =&gt; {\n  // Launch the browser instead of connecting to BrowserBase\n  const browser = await chromium.launch();\n\n  // Create a new context (equivalent to an incognito window)\n  const context = await browser.newContext();\n\n  // Create a new page in the context\n  const page = await context.newPage();\n\n  // Navigate to the website\n  await page.goto('https://browserbase.com/');\n\n  // Close the page\n  await page.close();\n\n  // Close the browser\n  await browser.close();\n})().catch((error) =&gt; console.error(error.message));\n</code></pre></p> <p>As you can see, the playwright code is more straightforward than any other framework.</p>","tags":["AI Engineering","Playwright","Puppeteer","Selenium","Testing"]},{"location":"2025/02/21/prompt-engineering/","title":"Prompt Engineering","text":"","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#content","title":"Content","text":"<ul> <li>What is prompt engineering?</li> <li>Why prompt engineering matters?</li> <li>Basics of prompt engineering</li> <li>The prompt engineering lifecycle</li> <li>Inference Parameters</li> <li>Zero-Shot</li> <li>Few-Shot</li> <li>Chain of thought</li> <li>Self-Consistency</li> <li>General Tips for Designing Prompts</li> <li>Common Misconceptions About Prompts</li> <li>Prompt Generator Tools</li> <li>Reasoning Model (i.e. OpenAI o1/DeepSeek R1)</li> </ul> <p> Key Takeaways: Prompt engineering is an \ud835\uddf6\ud835\ude01\ud835\uddf2\ud835\uddff\ud835\uddee\ud835\ude01\ud835\uddf6\ud835\ude03\ud835\uddf2 \ud835\uddfd\ud835\uddff\ud835\uddfc\ud835\uddf0\ud835\uddf2\ud835\ude00\ud835\ude00 involving continuous \ud835\ude01\ud835\uddf2\ud835\ude00\ud835\ude01\ud835\uddf6\ud835\uddfb\ud835\uddf4, \ud835\uddfa\ud835\uddfc\ud835\uddf1\ud835\uddf6\ud835\uddf3\ud835\uddf6\ud835\uddf0\ud835\uddee\ud835\ude01\ud835\uddf6\ud835\uddfc\ud835\uddfb, \ud835\uddee\ud835\uddfb\ud835\uddf1 \ud835\uddfc\ud835\uddfd\ud835\ude01\ud835\uddf6\ud835\uddfa\ud835\uddf6\ud835\ude07\ud835\uddee\ud835\ude01\ud835\uddf6\ud835\uddfc\ud835\uddfb. As models continue to evolve, prompts must adapt accordingly to maintain effectiveness.</p> <p></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#what-is-prompt-engineering","title":"What is prompt engineering?","text":"<p>Prompt engineering is about \"communicating\" with LLM in a way that maximizes the model's understanding and performance on a given task. At its core, prompt engineering involves designing, refining, and optimizing the text inputs (prompts) given to models to elicit accurate, relevant, and useful responses.</p> <p></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#why-prompt-engineering-matters","title":"Why prompt engineering matters?","text":"<ul> <li>Enhancing AI capabilities: Well-engineered prompts can dramatically improve an AI's performance, enabling it to tackle complex tasks with greater accuracy and efficiency.</li> <li>Bridging the gap between human intent and AI output: Prompt engineering helps translate human objectives into language that AI models can effectively interpret and act upon.</li> <li>Optimizing resource usage: Skilled prompt engineering can reduce token usage, lowering costs and improving response times in production environments.</li> </ul> <p>Let's look at two examples that demonstrate how prompt engineering can significantly enhance the performance of large language models (LLMs)</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#1-medprompt-a-prompting-technique-from-a-study-by-microsoft-enhances-the-performance-of-gpt-4","title":"1. Medprompt (a prompting technique from a study by Microsoft) enhances the performance of GPT-4:","text":"<p>MedPrompt is composed of the following prompting techniques:  </p> <ul> <li>Dynamic few-shot selection: instead of using static few-shot examples, Medprompt selects few-shot examples dynamically based on the question.  </li> <li>Self-generated chain of thought.  </li> <li>Choice shuffle ensembling: performs choice shuffle and self-consistency prompting.  </li> </ul> <p>We will explore Few-Shot, Chain of Thought, and Self-Consistency in the following sections.</p> <p></p> <p>Response accuracy increases significantly when applying more advanced prompt engineering techniques.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#medprompt-allows-gpt-4-to-compete-with-fine-tuned-models-gpt-4-vs-fine-tuning","title":"MedPrompt allows GPT-4 to compete with fine-tuned models. (GPT-4 vs Fine-tuning)","text":"<ul> <li>While fine-tuning can boost performance, the process can be expensive. Fine-tuning often requires experts or professionally labeled datasets (e.g., via top clinicians in the MedPaLM project) and then computing model parameter updates. The process can be resource-intensive and cost-prohibitive, making the approach a difficult challenge for many small and medium-sized organizations. </li> </ul> <p>The Medprompt shows GPT-4\u2019s ability to compete a leading model that was fine-tuned specifically for medical applications, on the same benchmarks and by a significant margin.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#2-boosting-lower-tier-models-with-effective-prompting-gpt-35-vs-gpt-4","title":"2. Boosting Lower-Tier Models with Effective Prompting. (GPT-3.5 vs GPT-4)","text":"<p>By wraping in an iterative agent workflow, GPT-3.5 achieves up to 95.1% of GPT-4 on tasks, like, content summarization and translation. For example, we can ask the LLM to iterate over a document many times: (from Andrew Ng's post &amp; - What's next for AI agentic workflows ft. Andrew Ng of AI Fund - 2024 ) </p> <ul> <li>Plan an outline.</li> <li>Write a first draft.</li> <li>Read over the first draft to spot unjustified arguments or extraneous information.</li> <li>Revise the draft taking into account any weaknesses spotted.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#you-may-ask-why-not-always-use-the-most-advanced-models","title":"You may ask, why not always use the most advanced models?","text":"<ul> <li>Cost: The advanced models are more expensive to run.</li> <li>Speed: The advanced models are slower to generate responses.</li> <li>Availability: The advanced models might not be available in certain scenarios\u2014for example, on edge devices. </li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#basics-of-prompt-engineering","title":"Basics of prompt engineering","text":"<p>A prompt contains any of the following elements:\u200b</p> <ul> <li>Instruction: a specific task or instruction you want the model to perform\u200b.</li> <li>Context: external information or additional context that can steer the model to better responses\u200b.</li> <li>Input Data: the input or question that we are interested to find a response for\u200b.</li> <li>Output Indicator: the type or format of the output.\u200b</li> </ul> <p>You do not need all the four elements for a prompt and the format depends on the task at hand. We will touch on more concrete examples in upcoming guides.\u200b</p> <p></p> <p></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#the-prompt-engineering-lifecycle","title":"The prompt engineering lifecycle","text":"<p>It would be nice to sit down at a blank page and craft the perfect prompt on the first try, but the reality is that prompt engineering is an iterative process that involves creating, testing, and refining prompts to achieve optimal performance.</p> <p>Understanding this lifecycle is crucial for developing effective prompts and troubleshooting issues that arise. </p> <ol> <li>Initial prompt creation </li> <li>Testing and identifying issues</li> <li>Selecting appropriate techniques</li> <li>Implementing improvements</li> <li>Iterating and refining</li> </ol> <p></p> <p></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#inference-parameters","title":"Inference Parameters","text":"<p>Inference parameters are used to control the behavior of the model during inference. There are more inference parameters, we only cover the most common ones here.  </p> <ul> <li> <p>System prompt: A system prompt is a way to provide role playing, context, instructions, and few-shot to LLM, while putting a question or task in the \"User\" turn. </p> <ul> <li>Higher priority: System messages define the primary behavior and are less likely to be overridden by a later user message.</li> <li>Consistency: If your application always needs certain examples or guidelines, placing them in the system prompt ensures they remain in effect throughout the conversation.</li> </ul> </li> <li> <p>Max tokens: Set a limit on the number of tokens per model response. </p> <ul> <li>Set appropriate output limits. Use the max_tokens parameter to set a hard limit on the maximum length of the generated response. This prevents LLM from generating overly long outputs, which reduces latency.</li> <li>Note: Some LLMs' (e.g. Phi) max tokens = input tokens + output tokens, please be aware.  <p>One token is roughly 4 characters for typical English text.</p> </li> </ul> </li> <li> <p>Temperature: Controls randomness. Lowering the temperature means that the model will produce more focused and deterministic responses. Increasing the temperature will result in more diverse and creative responses. Try adjusting temperature or Top P but not both.</p> </li> <li> <p>Top P: Similar to temperature, this controls randomness but uses a different method. Lowering Top P will narrow the model\u2019s token selection to likelier tokens. Increasing Top P will let the model choose from tokens with both high and low likelihood. Try adjusting temperature or Top P but not both.</p> </li> <li> <p>Frequency penalty:  This decreases the likelihood of repeating the exact same text in a response.</p> <ul> <li>OpenAI models' range: -2.0 to 2.0, default value is 0.</li> </ul> </li> <li> <p>Presence penalty: This increases the likelihood of introducing new topics in a response.</p> <ul> <li>OpenAI models' range: -2.0 to 2.0, default value is 0.</li> </ul> </li> <li> <p>Stop sequence: Make the model end its response at a desired point. The model response will end before the specified sequence, so it won't contain the stop sequence text. For ChatGPT, using &lt;|im_end|&gt; ensures that the model response doesn't generate a follow-up user query. You can include as many as four stop sequences.</p> </li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#lets-look-at-some-of-the-most-commonly-used-prompting-techniques","title":"Let's look at some of the most commonly used prompting techniques:","text":"","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#zero-shot","title":"Zero-Shot","text":"<p>Zero-shot is to simply feed the task text to the model and ask for results. <pre><code>Text: i'll bet the video game is a lot more fun than the film.\nSentiment:\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#few-shot","title":"Few-Shot","text":"<p>Hands-on notebook: Few-Shot_Prompting.ipynb </p> <p>You might also encounter the phrase \"n-shot\" or \"one-shot\". The number of \"shots\" refers to how many examples are used within the prompt.</p> <p>Giving LLM examples of how you want it to behave (or how you want it not to behave) is extremely effective for:</p> <ul> <li>Getting the right answer</li> <li>Getting the answer in the right format (e.g. JSON, HTML, etc.). <ul> <li>Few-shot prompting is an effective way to obtain a JSON output when function calling or JSON mode is not supported by an LLM.</li> </ul> </li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#for-maximum-effectiveness-make-sure-that-your-examples-are","title":"For maximum effectiveness, make sure that your examples are:","text":"<ul> <li>Relevant: Your examples mirror your actual use case.</li> <li>Diverse: Your examples cover edge cases and potential challenges, and vary enough that LLM doesn't inadvertently pick up on unintended patterns.</li> <li>Clear: Your examples are wrapped in  tags (if multiple, nested within  tags) for structure. <p>No Examples: <pre><code>Analyze this customer feedback and categorize the issues. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low).\n\nHere is the feedback: {{FEEDBACK}}\n</code></pre> With Examples: <pre><code>Our CS team is overwhelmed with unstructured feedback. Your task is to analyze feedback and categorize issues for our product and engineering teams. Use these categories: UI/UX, Performance, Feature Request, Integration, Pricing, and Other. Also rate the sentiment (Positive/Neutral/Negative) and priority (High/Medium/Low). Here is an example:\n\n&lt;example&gt;\nInput: The new dashboard is a mess! It takes forever to load, and I can\u2019t find the export button. Fix this ASAP!\nCategory: UI/UX, Performance\nSentiment: Negative\nPriority: High\n&lt;/example&gt;\n\nNow, analyze this feedback: {{FEEDBACK}}\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#chain-of-thought","title":"Chain of thought","text":"<p>Hands-on notebook: Chain_of_Thought.ipynb </p> <p>Giving LLM space to think can dramatically improve its performance. This technique, known as chain of thought (CoT) prompting, encourages LLM to break down problems step-by-step, leading to more accurate and nuanced outputs. \u200b</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#why-let-llm-think","title":"Why let LLM think?","text":"<ul> <li>Accuracy: Stepping through problems reduces errors, especially in math, logic, analysis, or generally complex tasks.</li> <li>Coherence: Structured thinking leads to more cohesive, well-organized responses.</li> <li>Debugging: Seeing LLM\u2019s thought process helps you pinpoint where prompts may be unclear. \u200b</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#why-not-let-llm-think","title":"Why not let LLM think?","text":"<p>Increased output length may impact latency. Not all tasks require in-depth thinking. Use CoT judiciously to ensure the right balance of performance and latency.</p> <p>Use CoT for tasks that a human would need to think through, like complex math, multi-step analysis, writing complex documents, or decisions with many factors.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#how-to-prompt-for-thinking","title":"How to prompt for thinking","text":"<p>CoT tip: Always have LLM output its thinking. Without outputting its thought process, no thinking occurs!</p> <ul> <li>Basic prompt: Include \u201cThink step-by-step\u201d in your prompt.<ul> <li>Lacks guidance on how to think (which is especially not ideal if a task is very specific to your app, use case, or organization) <pre><code>Draft personalized emails to donors asking for contributions to this year\u2019s Care for Kids program.\n\nProgram information:\n&lt;program&gt;{{PROGRAM_DETAILS}}\n&lt;/program&gt;\n\nDonor information:\n&lt;donor&gt;{{DONOR_DETAILS}}\n&lt;/donor&gt;\n\nThink step-by-step before you write the email.\n</code></pre></li> </ul> </li> <li>Guided prompt: Outline specific steps for LLM to follow in its thinking process.<ul> <li>Lacks structuring to make it easy to strip out and separate the answer from the thinking. <pre><code>Draft personalized emails to donors asking for contributions to this year\u2019s Care for Kids program.\n\nProgram information:\n&lt;program&gt;{{PROGRAM_DETAILS}}\n&lt;/program&gt;\n\nDonor information:\n&lt;donor&gt;{{DONOR_DETAILS}}\n&lt;/donor&gt;\n\nThink before you write the email. First, think through what messaging might appeal to this donor given their donation history and which campaigns they\u2019ve supported in the past. Then, think through what aspects of the Care for Kids program would appeal to them, given their history. Finally, write the personalized donor email using your analysis.\n</code></pre></li> </ul> </li> <li>Structured prompt: Use XML tags like  and  to separate reasoning from the final answer.     <pre><code>Draft personalized emails to donors asking for contributions to this year\u2019s Care for Kids program.\n\nProgram information:\n&lt;program&gt;{{PROGRAM_DETAILS}}\n&lt;/program&gt;\n\nDonor information:\n&lt;donor&gt;{{DONOR_DETAILS}}\n&lt;/donor&gt;\n\nThink before you write the email in &lt;thinking&gt; tags. First, think through what messaging might appeal to this donor given their donation history and which campaigns they\u2019ve supported in the past. Then, think through what aspects of the Care for Kids program would appeal to them, given their history. Finally, write the personalized donor email in &lt;email&gt; tags, using your analysis.\n</code></pre> <p>Use code (e.g. extract from <code>&lt;answer&gt;</code> tags) to extract the desired answer from the LLM's response</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#self-consistency","title":"Self-Consistency","text":"<p>Proposed by Wang et al. (2022), self-consistency aims \"to replace the naive greedy decoding used in chain-of-thought prompting\". The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to select the most consistent answer. This helps to boost the performance of CoT prompting on tasks involving arithmetic and commonsense reasoning.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#more-prompting-techiques-if-you-are-interested","title":"More prompting techiques if you are interested.","text":"<ul> <li>Tree of Thought</li> <li>ReAct</li> <li>Reflexion</li> <li>...</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#general-tips-for-designing-prompts","title":"General Tips for Designing Prompts","text":"<p>Okey, we have covered the basics of prompt engineering. Now, let's dive into some general tips for designing prompts.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#1-start-simple-source","title":"1. Start Simple: (source)","text":"<ul> <li>As you get started with designing prompts, you should keep in mind that it is really an iterative process that requires a lot of experimentation to get optimal results. Using a simple playground, for example, Azure AI Foundry is a good starting point.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#2-be-clear-direct-and-detailed-source","title":"2. Be clear, direct, and detailed: (source)","text":"<p>Think of LLM like any other human that is new to the job. LLM has no context on what to do aside from what you literally tell it. Just as when you instruct a human for the first time on a task, the more you explain exactly what you want in a straightforward manner to LLM, the better and more accurate LLM's response will be.\"</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#when-in-doubt-follow-the-golden-rule-of-clear-prompting","title":"When in doubt, follow the Golden Rule of Clear Prompting:","text":"<ul> <li>Show your prompt to a colleague or friend and have them follow the instructions themselves to see if they can produce the result you want. If they're confused, LLM's confused.   </li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#how-to-be-clear-contextual-and-specific","title":"How to be clear, contextual, and specific:","text":"<ul> <li>What the task results will be used for</li> <li>What audience the output is meant for</li> <li>What workflow the task is a part of, and where this task belongs in that workflow</li> <li>The end goal of the task, or what a successful task completion looks like</li> <li>Be specific about what you want LLM to do: For example, if you want LLM to output only code and nothing else, say so.</li> <li>Provide instructions as sequential steps: Use numbered lists or bullet points to better ensure that LLM carries out the task the exact way you want it to.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#unclear-prompt","title":"Unclear Prompt","text":"<pre><code>Please remove all personally identifiable information from these customer feedback messages: {{FEEDBACK_DATA}}\n</code></pre>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#clear-prompt","title":"Clear Prompt","text":"<pre><code>Your task is to anonymize customer feedback for our quarterly review.\n\nInstructions:\n1. Replace all customer names with \u201cCUSTOMER_[ID]\u201d (e.g., \u201cJane Doe\u201d \u2192 \u201cCUSTOMER_001\u201d).\n2. Replace email addresses with \u201cEMAIL_[ID]@example.com\u201d.\n3. Redact phone numbers as \u201cPHONE_[ID]\u201c.\n4. If a message mentions a specific product (e.g., \u201cAcmeCloud\u201d), leave it intact.\n5. If no PII is found, copy the message verbatim.\n6. Output only the processed messages, separated by \u201d---\u201d.\n\nData to process: {{FEEDBACK_DATA}}\n</code></pre>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#3-giving-llm-a-role-with-a-system-prompt-source","title":"3. Giving LLM a role with a system prompt: (source)","text":"<ul> <li>Enhanced accuracy: In complex scenarios like legal analysis or financial modeling, role prompting can significantly boost LLM\u2019s performance.</li> <li>Tailored tone: Whether you need a CFO\u2019s brevity or a copywriter\u2019s flair, role prompting adjusts LLM\u2019s communication style.</li> <li>Improved focus: By setting the role context, LLM stays more within the bounds of your task\u2019s specific requirements. <p>Role prompting tip: Experiment with roles! A data scientist might see different insights than a marketing strategist for the same data. A data scientist specializing in customer insight analysis for Fortune 500 companies might yield different results still!</p> </li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#financial-analysis-without-role-prompting","title":"Financial analysis without role prompting.","text":"<pre><code>Analyze this dataset of our Q2 financials:\n&lt;data&gt;\n{{FINANCIALS}}\n&lt;/data&gt;\n\nHighlight key trends and recommend actions.\n</code></pre>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#financial-analysis-with-role-prompting","title":"Financial analysis with role prompting.","text":"<pre><code>You are the CFO of a high-growth B2B SaaS company. We\u2019re in a board meeting discussing our Q2 financials:\n&lt;data&gt;\n{{FINANCIALS}}\n&lt;/data&gt;\n\nAnalyze key trends, flag concerns, and recommend strategic actions. Our investors want aggressive growth but are wary of our burn rate.\n</code></pre>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#4-put-instructions-at-the-beginning-of-the-prompt-and-use-delimiters-like-or-or-xml-tags-to-separate-the-instruction-and-context-source","title":"4. Put instructions at the beginning of the prompt and use delimiters like, <code>###</code> or <code>\"\"\"</code>,  or XML tags to separate the instruction and context. (source)","text":"","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#5-be-specific-descriptive-and-as-detailed-as-possible-about-the-desired-context-outcome-length-format-style-etc-source","title":"5. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc.  (source)","text":"<p>Be specific about the context, outcome, length, format, style, etc.</p> <p>Less effective \u274c: <pre><code>Write a poem about OpenAI. \n</code></pre></p> <p>Better \u2705: <pre><code>Write a short inspiring poem about OpenAI, focusing on the recent DALL-E product launch (DALL-E is a text to image ML model) in the style of a {famous poet}\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#6-reduce-fluffy-and-imprecise-descriptions-source","title":"6. Reduce \u201cfluffy\u201d and imprecise descriptions: (source)","text":"<p>Less effective \u274c: <pre><code>The description for this product should be fairly short, a few sentences only, and not too much more.\n</code></pre></p> <p>Better \u2705: <pre><code>Use a 3 to 5 sentence paragraph to describe this product.\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#7-instead-of-just-saying-what-not-to-do-say-what-to-do-instead-source","title":"7. Instead of just saying what not to do, say what to do instead: (source)","text":"<p>Less effective \u274c: <pre><code>The following is a conversation between an Agent and a Customer. DO NOT ASK USERNAME OR PASSWORD. DO NOT REPEAT.\n\nCustomer: I can\u2019t log in to my account.\nAgent:\n</code></pre></p> <p>Better \u2705: <pre><code>The following is a conversation between an Agent and a Customer. The agent will attempt to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq\n\nCustomer: I can\u2019t log in to my account.\nAgent:\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#8-code-generation-specific-use-leading-words-to-nudge-the-model-toward-a-particular-pattern-source","title":"8. Code Generation Specific - Use \u201cleading words\u201d to nudge the model toward a particular pattern: (source)","text":"<p>Less effective \u274c: <pre><code># Write a simple python function that\n# 1. Ask me for a number in mile\n# 2. It converts miles to kilometers\n</code></pre></p> <p>In this code example below, adding \u201cimport\u201d hints to the model that it should start writing in Python. (Similarly \u201cSELECT\u201d is a good hint for the start of a SQL statement.) </p> <p>Better \u2705: <pre><code># Write a simple python function that\n# 1. Ask me for a number in mile\n# 2. It converts miles to kilometers\n\nimport\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#9-use-prompt-templates","title":"9. Use prompt templates","text":"<p>You should always use prompt templates and variables when you expect any part of your prompt to be repeated in another call to LLM.  Prompt templates offer several benefits:</p> <ul> <li>Consistency: Ensure a consistent structure for your prompts across multiple interactions</li> <li>Efficiency: Easily swap out variable content without rewriting the entire prompt</li> <li>Testability: Quickly test different inputs and edge cases by changing only the variable portion</li> <li>Scalability: Simplify prompt management as your application grows in complexity</li> <li>Version control: Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs</li> </ul> <pre><code>Translate this text from English to Spanish: {{text}}\n</code></pre>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#10-long-context-prompting-tips","title":"10. Long context prompting tips","text":"<ul> <li>Put longform data at the top: Place your long documents and inputs (~20K+ tokens) near the top of your prompt, above your query, instructions, and examples. This can significantly improve LLM's performance.</li> </ul> <p>Queries at the end can improve response quality by up to 30% in tests, especially with complex, multi-document inputs.</p> <ul> <li> <p>Structure document content and metadata with XML tags: When using multiple documents, wrap each document in  tags with  and  (and other metadata) subtags for clarity. <pre><code>&lt;documents&gt;\n  &lt;document index=\"1\"&gt;\n    &lt;source&gt;annual_report_2023.pdf&lt;/source&gt;\n    &lt;document_content&gt;\n      {{ANNUAL_REPORT}}\n    &lt;/document_content&gt;\n  &lt;/document&gt;\n  &lt;document index=\"2\"&gt;\n    &lt;source&gt;competitor_analysis_q2.xlsx&lt;/source&gt;\n    &lt;document_content&gt;\n      {{COMPETITOR_ANALYSIS}}\n    &lt;/document_content&gt;\n  &lt;/document&gt;\n&lt;/documents&gt;\n\nAnalyze the annual report and competitor analysis. Identify strategic advantages and recommend Q3 focus areas.\n</code></pre> <li> <p>Ground responses in quotes: For long document tasks, ask LLM to quote relevant parts of the documents first before carrying out its task. This helps LLM cut through the \u201cnoise\u201d of the rest of the document\u2019s contents. <pre><code>You are an AI physician's assistant. Your task is to help doctors diagnose possible patient illnesses.\n\n&lt;documents&gt;\n  &lt;document index=\"1\"&gt;\n    &lt;source&gt;patient_symptoms.txt&lt;/source&gt;\n    &lt;document_content&gt;\n      {{PATIENT_SYMPTOMS}}\n    &lt;/document_content&gt;\n  &lt;/document&gt;\n  &lt;document index=\"2\"&gt;\n    &lt;source&gt;patient_records.txt&lt;/source&gt;\n    &lt;document_content&gt;\n      {{PATIENT_RECORDS}}\n    &lt;/document_content&gt;\n  &lt;/document&gt;\n  &lt;document index=\"3\"&gt;\n    &lt;source&gt;patient01_appt_history.txt&lt;/source&gt;\n    &lt;document_content&gt;\n      {{PATIENT01_APPOINTMENT_HISTORY}}\n    &lt;/document_content&gt;\n  &lt;/document&gt;\n&lt;/documents&gt;\n\nFind quotes from the patient records and appointment history that are relevant to diagnosing the patient's reported symptoms. Place these in &lt;quotes&gt; tags. Then, based on these quotes, list all information that would help the doctor diagnose the patient's symptoms. Place your diagnostic information in &lt;info&gt; tags.\n</code></pre></p> </li>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#11-chain-complex-prompts","title":"11. Chain complex prompts","text":"<p>When working with complex tasks, LLM can sometimes drop the ball if you try to handle everything in a single prompt. Chain of thought (CoT) prompting is great, but what if your task has multiple distinct steps that each require in-depth thought?  Breaking down complex tasks into smaller, manageable subtasks.</p> <ul> <li>Accuracy: Each subtask gets LLM\u2019s full attention, reducing errors.</li> <li>Clarity: Simpler subtasks mean clearer instructions and outputs.</li> <li>Traceability: Easily pinpoint and fix issues in your prompt chain.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#example-chained-workflows","title":"Example chained workflows:","text":"<ul> <li>Content creation pipelines: Research \u2192 Outline \u2192 Draft \u2192 Edit \u2192 Format.</li> <li>Data processing: Extract \u2192 Transform \u2192 Analyze \u2192 Visualize.</li> <li>Decision-making: Gather info \u2192 List options \u2192 Analyze each \u2192 Recommend.</li> <li>Verification loops: Generate content \u2192 Review \u2192 Refine \u2192 Re-review.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#12-tool-use-function-calling","title":"12. Tool use (function calling)","text":"<p>Hands-on notebook: Tool_Use_Function-Calling.ipynb </p> <p>Function calling provides a powerful and flexible way for LLMs to interface with your code or external services, and has two primary use cases:</p> <ul> <li>Fetching Data Retrieve up-to-date information to incorporate into the model's response (RAG). Useful for searching knowledge bases and retrieving specific data from APIs (e.g. current weather data).</li> <li>Taking Action Perform actions like submitting a form, calling APIs, modifying application state (UI/frontend or backend), or taking agentic workflow actions (like handing off the conversation).</li> </ul> <p>When you define a function as part of your request, the details are injected into the system message using specific syntax that the model has been trained on. This means that functions consume tokens in your prompt and that you can apply prompt engineering techniques to optimize the performance of your function calls. The model uses the full context of the prompt to determine if a function should be called including function definition, the system message, and the user messages.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#improving-tool-use-quality-and-reliability","title":"Improving tool use quality and reliability","text":"<p>If the model isn't calling your function when or how you expect, there are a few things you can try to improve the quality.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#a-provide-more-details-in-your-function-definition","title":"a. Provide more details in your function definition","text":"<p>It's important that you provide a meaningful description of the function and provide descriptions for any parameter that might not be obvious to the model. For example, in the description for the location parameter, you could include extra details and examples on the format of the location. <pre><code>\"location\": {\n    \"type\": \"string\",\n    \"description\": \"The location of the hotel. The location should include the city and the state's abbreviation (i.e. Seattle, WA or Miami, FL)\"\n}\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#b-provide-more-context-in-the-system-message","title":"b. Provide more context in the system message","text":"<p>The system message can also be used to provide more context to the model. For example, if you have a function called search_hotels you could include a system message like the following to instruct the model to call the function when a user asks for help with finding a hotel.</p> <pre><code>{\"role\": \"system\", \"content\": \"You're an AI assistant designed to help users search for hotels. When a user asks for help finding a hotel, you should call the search_hotels function.\"}\n</code></pre>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#c-instruct-the-model-to-ask-clarifying-questions","title":"c. Instruct the model to ask clarifying questions","text":"<p>In some cases, you want to instruct the model to ask clarifying questions to prevent making assumptions about what values to use with functions. For example, with search_hotels you would want the model to ask for clarification if the user request didn't include details on location. To instruct the model to ask a clarifying question, you could include content like the next example in your system message. <pre><code>{\"role\": \"system\", \"content\": \"Don't make assumptions about what values to use with functions. Ask for clarification if a user request is ambiguous.\"}\n</code></pre></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#d-offload-the-burden-from-the-model-and-use-code-where-possible","title":"d. Offload the burden from the model and use code where possible.","text":"<ul> <li>Don't make the model fill arguments you already know. </li> <li>Combine functions that are always called in sequence. For example, if you always call <code>mark_location()</code> after <code>query_location()</code>, just move the marking logic into the query function call.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#e-keep-the-number-of-functions-small-for-higher-accuracy","title":"e. Keep the number of functions small for higher accuracy.","text":"<ul> <li>Evaluate your performance with different numbers of functions.</li> <li>Aim for fewer than 20 functions at any one time, though this is just a soft suggestion.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#13-increse-output-consistency-json-modestructured-output","title":"13. Increse output consistency (JSON mode/Structured Output)","text":"<p>Hands-on notebook: Structured_Output_JOSN-Mode.ipynb </p> <p>Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema, so you don't need to worry about the model omitting a required key, or hallucinating an invalid enum value.</p> <p>Some benefits of Structured Outputs include:</p> <ul> <li>Reliable type-safety: No need to validate or retry incorrectly formatted responses</li> <li>Explicit refusals: Safety-based model refusals are now programmatically detectable</li> <li>Simpler prompting: No need for strongly worded prompts to achieve consistent formatting</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#a-four-effective-ways-to-generate-structured-outputs","title":"a. Four Effective Ways to Generate Structured Outputs","text":"<p>When working with LLMs, ensuring structured outputs (such as JSON) can improve reliability and make parsing easier. Here are four key methods to achieve this:  </p> <ol> <li> <p>Use Few-Shot Examples </p> <ul> <li>Provide examples of the desired JSON output directly in the prompt to guide the model.  </li> <li>Particularly useful for models without native JSON mode or function calling support.  </li> </ul> </li> <li> <p>Leverage JSON Mode </p> <ul> <li>If supported, enable JSON mode to ensure outputs are strictly formatted as JSON.  </li> </ul> </li> <li> <p>Utilize Function Calling </p> <ul> <li>Define structured functions that the model can call, ensuring outputs adhere to a predefined schema.  </li> </ul> </li> <li> <p>OpenAI\u2019s new Structured Outputs feature </p> <ul> <li>OpenAI provides tools for generating well-structured responses, reducing errors in format consistency.  </li> </ul> </li> </ol>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#b-when-to-use-structured-outputs-via-function-calling-vs-via-response_format","title":"b. When to use Structured Outputs via function calling vs via response_format","text":"<p>Structured Outputs is available in two forms in the OpenAI API:</p> <ul> <li>When using function calling</li> <li>When using a json_schema response format</li> </ul> <p>Function calling is useful when you are building an application that bridges the models and functionality of your application.</p> <p>For example, you can give the model access to functions that query a database in order to build an AI assistant that can help users with their orders, or functions that can interact with the UI.</p> <p>Conversely, Structured Outputs via response_format are more suitable when you want to indicate a structured schema for use when the model responds to the user, rather than when the model calls a tool.</p> <p>Put simply:</p> <p>If you are connecting the model to tools, functions, data, etc. in your system, then you should use function calling.</p> <p>If you want to structure the model's output when it responds to the user, then you should use a structured response_format.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#c-structured-outputs-vs-json-mode","title":"c. Structured Outputs vs JSON mode","text":"<p>Structured Outputs is the evolution of JSON mode. While both ensure valid JSON is produced, only Structured Outputs ensure schema adherance. </p> <p>Always using Structured Outputs instead of JSON mode when possible.</p> <p>However, Structured Outputs with response_format: <code>{type: \"json_schema\", ...}</code> is only supported with the <code>gpt-4o-mini</code>, <code>gpt-4o-mini-2024-07-18</code>, and <code>gpt-4o-2024-08-06</code> model snapshots and later.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#14-reducing-latency","title":"14. Reducing Latency","text":"<p>Latency can be influenced by various factors, such as the size of the model, the complexity of the prompt, and the underlying infrastucture supporting the model and point of interaction.</p> <p>It\u2019s always better to first engineer a prompt that works well without model or prompt constraints, and then try latency reduction strategies afterward. Trying to reduce latency prematurely might prevent you from discovering what top performance looks like.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#how-to-reduce-latency","title":"How to reduce latency:","text":"<p>a. Choose the right model. b. Optimize prompt to use fewer input tokens:   </p> <ul> <li>Be clear but concise.</li> <li>Fine-tuning the model, to replace the need for lengthy instructions / examples.</li> <li>Filtering context input, like pruning RAG results, cleaning HTML, etc.</li> <li>Maximize shared prompt prefix, by putting dynamic portions (e.g. RAG results, history, etc) later in the prompt. This makes your request more KV cache-friendly (which most LLM providers use) and means fewer input tokens are processed on each request. <ul> <li>prompt-caching: structure prompts with static or repeated content at the beginning and dynamic content at the end.     </li> </ul> </li> </ul> <p>c. Generate fewer tokens: Generating tokens is almost always the highest latency step when using an LLM: as a general heuristic, cutting 50% of your output tokens may cut ~50% your latency.    </p> <ul> <li>Ask for shorter responses.</li> <li>Set appropriate output limits. Use the max_tokens parameter to set a hard limit on the maximum length of the generated response. This prevents LLM from generating overly long outputs.</li> <li>Use <code>stop_tokens</code> to end your generation early.</li> <li>Experiment with temperature: The temperature parameter controls the randomness of the output. Lower values (e.g., 0.2) can sometimes lead to more focused and shorter responses, while higher values (e.g., 0.8) may result in more diverse but potentially longer outputs.</li> </ul> <p>d. Process tokens faster.  </p> <ul> <li>Using a longer, more detailed prompt,</li> <li>Adding (more) few-shot examples, or</li> <li>Fine-tuning / distillation.</li> <li>Predicted output (OpenAI API) <pre><code>  const code = `\n  class User {\n    firstName: string = \"\";\n    lastName: string = \"\";\n    username: string = \"\";\n  }\n\n  export default User;\n  `.trim();\n\n  const completion = await openai.chat.completions.create({\n    model: \"gpt-4o\",\n    messages: [\n      {\n        role: \"user\",\n        content: refactorPrompt\n      },\n      {\n        role: \"user\",\n        content: code\n      }\n    ],\n    store: true,\n    prediction: {\n      type: \"content\",\n      content: code\n    }\n  });\n</code></pre></li> </ul> <p>e. Leverage streaming, make your users wait less.  </p> <p>Streaming is a feature that allows the model to start sending back its response before the full output is complete. </p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#15-avoiding-hallucinations","title":"15. Avoiding hallucinations","text":"<p>Hands-on notebook: Avoiding_Hallucinations.ipynb</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#a-allow-llm-to-say-i-dont-know","title":"a. Allow LLM to say \u201cI don\u2019t know\u201d.","text":"As our M&amp;A advisor, analyze this report on the potential acquisition of AcmeCo by ExampleCorp.  {{REPORT}}   Focus on financial projections, integration risks, and regulatory hurdles. If you\u2019re unsure about any aspect or if the report lacks necessary information, say \u201cI don\u2019t have enough information to confidently assess this.\u201d","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#b-use-direct-quotes-for-factual-grounding","title":"b. Use direct quotes for factual grounding:","text":"<ul> <li>For tasks involving long documents (&gt;20K tokens), ask LLM to extract word-for-word quotes first before performing its task. This grounds its responses in the actual text, reducing hallucinations.</li> </ul>  As our Data Protection Officer, review this updated privacy policy for GDPR and CCPA compliance.  {{POLICY}}  Extract exact quotes from the policy that are most relevant to GDPR and CCPA compliance. If you can\u2019t find relevant quotes, state \u201cNo relevant quotes found.\u201d 2. Use the quotes to analyze the compliance of these policy sections, referencing the quotes by number. Only base your analysis on the extracted quotes.","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#c-verify-with-citations","title":"c. Verify with citations:","text":"<p>Make LLM\u2019s response auditable by having it cite quotes and sources for each of its claims. You can also have LLM verify each claim by finding a supporting quote after it generates a response. If it can\u2019t find a quote, it must retract the claim.</p>  Draft a press release for our new cybersecurity product, AcmeSecurity Pro, using only information from these product briefs and market reports.  {{DOCUMENTS}}   After drafting, review each claim in your press release. For each claim, find a direct quote from the documents that supports it. If you can\u2019t find a supporting quote for a claim, remove that claim from the press release and mark where it was removed with empty [] brackets.","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#d-advanced-techniques","title":"d. Advanced techniques:","text":"<ul> <li> <p>Chain-of-thought verification: Ask LLM to explain its reasoning step-by-step before giving a final answer. This can reveal faulty logic or assumptions.</p> </li> <li> <p>Best-of-N verficiation: Run LLM through the same prompt multiple times and compare the outputs. Inconsistencies across outputs could indicate hallucinations.</p> </li> <li> <p>Iterative refinement: Use LLM\u2019s outputs as inputs for follow-up prompts, asking it to verify or expand on previous statements. This can catch and correct inconsistencies.</p> </li> <li> <p>External knowledge restriction: Explicitly instruct LLM to only use information from provided documents and not its general knowledge.</p> </li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#16-split-complex-tasks-into-simpler-subtasks","title":"16. Split complex tasks into simpler subtasks","text":"<p>Complex tasks tend to have higher error rates than simpler tasks. Furthermore, complex tasks can often be re-defined as a workflow of simpler tasks in which the outputs of earlier tasks are used to construct the inputs to later tasks.</p> <ul> <li>Use intent classification to identify the most relevant instructions for a user query</li> <li>For dialogue applications that require very long conversations, summarize or filter previous dialogue.</li> <li>Summarize long documents piecewise and construct a full summary recursively.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#17-test-changes-systematically","title":"17. Test changes systematically","text":"<p>Sometimes it can be hard to tell whether a change \u2014 e.g., a new instruction or a new design \u2014 makes your system better or worse. Looking at a few examples may hint at which is better, but with small sample sizes it can be hard to distinguish between a true improvement or random luck. Maybe the change helps performance on some inputs, but hurts performance on others.</p> <ul> <li>Evaluate model outputs with reference to gold-standard answers</li> </ul> <p>Leverage prompt evaluation tools to accelerate your assessment process:</p> <ul> <li>Anthropic</li> <li>OpenAI</li> <li>Ragas</li> <li>How to evaluate generative AI models and applications with Azure AI Foundry</li> </ul> <p></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#common-misconceptions-about-prompts","title":"Common Misconceptions About Prompts","text":"","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#1-a-prompt-is-static-write-it-once-and-youre-done","title":"1. A prompt is static; write it once and you\u2019re done. \u274c","text":"<ul> <li>Misconception: Some think writing a prompt is like writing an article\u2014once you finish, it\u2019s done, and no further changes are necessary.</li> <li>\u2705 Reality: A prompt is actually a complex programming method, requiring the same care we apply to code, such as version control and experiment tracking. Crafting a good prompt involves careful design and iteration, ensuring the model accurately understands the task and produces the desired output. Prompt engineering is an iterative process involving continuous testing, modification, and optimization.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#2-prompts-require-perfect-grammar-and-punctuation","title":"2. Prompts require perfect grammar and punctuation. \u274c","text":"<ul> <li>Misconception: People assume a model only understands a prompt if it\u2019s written in flawless grammar and punctuation.</li> <li>\u2705 Reality: While attention to detail is important, the model can typically handle prompts with typos or imperfect grammar. Conceptual clarity matters more than perfect grammar. Although it\u2019s good to correct errors in the final prompt, it\u2019s fine to have minor flaws during the iterative process.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#3-you-have-to-trick-the-model-into-working","title":"3. You have to \u2018trick\u2019 the model into working. \u274c","text":"<ul> <li>Misconception: Some believe the model is \u201cdumb\u201d and needs tricks or \u201clies\u201d to get the job done, such as saying \" I will tip you $500\".</li> <li>Reality: Models are quite capable. You don\u2019t need to \u201ctrick\u201d them. Rather, you should respect the model and provide clear, accurate information so it understands your goal. Simply describe your task directly, rather than using metaphors or a similar task to guide the model.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#4-prompt-engineering-is-all-about-crafting-a-perfect-instruction","title":"4. Prompt engineering is all about crafting a perfect instruction. \u274c","text":"<ul> <li>Misconception: Some think prompt engineering is just finding the perfect instruction, spending large amounts of time agonizing over every single word.</li> <li>\u2705 Reality: While precise instructions do matter, it\u2019s even more crucial to understand how the model operates and to learn from reading its outputs. Understanding the model\u2019s reasoning\u2014how it processes different inputs\u2014matters more than chasing a so-called perfect instruction. A good prompt engineer can interpret signals from the model\u2019s output and grasp its reasoning process, not just look at whether the result is correct.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#5-prompt-engineering-is-purely-about-writing-skill","title":"5. Prompt engineering is purely about writing skill. \u274c","text":"<ul> <li>Misconception: Some believe the main skill in prompt engineering is writing proficiency, so someone who writes well will naturally excel at it.</li> <li>\u2705 Reality: Although strong writing skills are necessary, they\u2019re not the core capability. Good prompt engineers need an experimental mindset, systematic thinking, problem-solving skills, and insight into how the model \u201cthinks.\u201d Iteration and testing matter more than writing ability alone.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#6-more-examples-always-produce-better-prompts","title":"6. More examples always produce better prompts. \u274c","text":"<ul> <li>Misconception: People may think providing a large number of examples is the only way to improve the model\u2019s performance.</li> <li>\u2705 Reality: While examples can help guide the model, having too many can limit creativity and variety. In research contexts, using illustrative rather than highly specific examples can be more effective, because it encourages the model to focus on the underlying task rather than just copying examples.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#7-you-should-avoid-giving-the-model-too-much-information","title":"7. You should avoid giving the model too much information. \u274c","text":"<ul> <li>Misconception: Some worry giving the model too many details will confuse it, so they keep the instructions minimal and hide complexity.</li> <li>\u2705 Reality: As models become more capable, they can handle more information and context. You should trust the model by giving it enough information to better understand your task.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#8-role-playing-prompts-always-work","title":"8. Role-playing prompts always work. \u274c","text":"<ul> <li>Misconception: Some believe that giving the model a specific role (e.g. \u201cYou are a teacher\u201d) automatically boosts its performance.</li> <li>\u2705 Reality: Role-playing prompts may help in certain scenarios but aren\u2019t always necessary. Often, simply stating your task is more effective. As models improve, it may be better to give a direct task description rather than assigning a fake identity.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#9-once-you-find-a-good-prompt-itll-work-forever","title":"9. Once you find a good prompt, it\u2019ll work forever. \u274c","text":"<ul> <li>Misconception: Some believe once you find an effective prompt, you can reuse it indefinitely without further changes.</li> <li>\u2705 Reality: As models keep improving, prompts that used to work can become obsolete. Some prompting techniques might get \u201cbaked into\u201d the model\u2019s training, making them unnecessary later. You have to keep learning and adapting to changes in the model.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#prompt-generator-tools","title":"Prompt Generator Tools","text":"<p>Now that you've explored various prompt engineering techniques and debunked common misconceptions, you might be wondering\u2014how can you generate high-quality prompts effortlessly?</p> <p>Following the detailed steps above can sometimes feel overwhelming, but don't worry! To make things easier, here are some prompt generator tools that can streamline the process and help you craft effective prompts with ease.</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#1-anthropic-prompt-generator","title":"1. Anthropic Prompt Generator","text":"<p>Anthropic prompt generator is my personal favorite. I use it frequently to generate prompts and enhance existing ones for better performance. It convert a simple text into a well-structured prompt. In most cases, you can use it as is without modifying the output.    </p> <p>An example input prompt: <pre><code>Summarize an article.\n</code></pre> Output prompt: <pre><code>You are tasked with summarizing an article. Please follow these instructions carefully:\n\n1. First, read the following article in its entirety:\n\n&lt;article&gt;\n{{ARTICLE}}\n&lt;/article&gt;\n\n2. After reading, take a moment to analyze the article's main points, key arguments, and overall structure.\n\n3. Create a concise summary of the article that captures its essence. Your summary should:\n   - Identify the main topic or thesis of the article\n   - Highlight the key points and arguments presented\n   - Include any significant data, statistics, or examples that support the main ideas\n   - Maintain the original tone and intent of the article\n\n4. Your summary should be approximately 3-5 sentences long, or about 100-150 words. It should be written in a clear, objective style.\n\n5. After the summary, provide a brief assessment (2-3 sentences) of the article's main contributions or significance to its field or to the broader discourse.\n\nPlease present your response in the following format:\n\n&lt;summary&gt;\n[Insert your 3-5 sentence summary here]\n&lt;/summary&gt;\n\n&lt;assessment&gt;\n[Insert your 2-3 sentence assessment here]\n&lt;/assessment&gt;\n\nRemember to focus on the most crucial information and maintain the original meaning of the article without inserting your own opinions or interpretations in the summary.\n</code></pre></p> <p> \ud83d\udd17 Try it here </p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#2-azure-ai-foundry","title":"2. Azure AI Foundry","text":"<p>Microsoft's Azure AI Foundry provides robust AI-powered tools to assist with prompt generation and optimization, making it a great resource for AI developers. \ud83d\udd17 Try it here </p> <p> </p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#3-microsoft-365-copilot","title":"3. Microsoft 365 Copilot","text":"<p>Microsoft 365 Copilot can assist in generating contextual prompts directly within your workflow. \ud83d\udd17 Try it here </p> <p> </p> <p>Hands-on notebook: Prompt_Generation.ipynb</p> <p></p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#reasoning-model-ie-openai-o1deepseek-r1","title":"Reasoning Model (i.e. OpenAI o1/DeepSeek R1)","text":"<p>Finally, let's explore the reasoning model, which highlights that prompt engineering is an iterative process, requiring prompts to evolve alongside model advancements. For instance, the chain of thought is no longer necessary for the reasoning model.</p> <p>Reasoning models think before they answer, producing a long internal chain of thought before responding to the user. </p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#a-how-reasoning-works","title":"a. How reasoning works","text":"<p>For example: the o1 models introduce reasoning tokens. The models use these reasoning tokens to \"think\", breaking down their understanding of the prompt and considering multiple approaches to generating a response. After generating reasoning tokens, the model produces an answer as visible completion tokens, and discards the reasoning tokens from its context.</p> <p>Here is an example of a multi-step conversation between a user and an assistant. Input and output tokens from each step are carried over, while reasoning tokens are discarded. </p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#b-advice-on-reasoning-model-prompting","title":"b. Advice on reasoning model prompting","text":"<p>These models perform best with straightforward prompts. Some prompt engineering techniques, like few-shot learning or instructing the model to \"think step by step,\" may not enhance performance (and can sometimes hinder it). Here are some best practices:</p> <ul> <li>Keep prompts simple and direct: The models excel at understanding and responding to brief, clear instructions without the need for extensive guidance.</li> <li>Avoid chain-of-thought prompts: Since these models perform reasoning internally, prompting them to \"think step by step\" or \"explain your reasoning\" is unnecessary.</li> <li>Use delimiters for clarity: Use delimiters like triple quotation marks, XML tags, or section titles to clearly indicate distinct parts of the input, helping the model interpret different sections appropriately.</li> <li>Try zero shot first, then few shot if needed: Reasoning models often don't need few-shot examples to produce good results, so try to write prompts without examples first. If you have more complex requirements for your desired output, it may help to include a few examples of inputs and desired outputs in your prompt. Just ensure that the examples align very closely with your prompt instructions, as discrepancies between the two may produce poor results</li> <li>Limit additional context in retrieval-augmented generation (RAG): When providing additional context or documents, include only the most relevant information to prevent the model from overcomplicating its response.</li> </ul>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/02/21/prompt-engineering/#c-below-example-illustrates-the-difference-between-the-non-reasoning-model-and-the-reasoning-model","title":"c. Below example illustrates the difference between the non-reasoning model and the reasoning model:","text":"<ul> <li> <p>Non-reasoning model outputs the response right away </p> </li> <li> <p>Internal reasoning process occurs in reasoning model </p> </li> </ul> <p>Congratulations! You've made it through the entire prompt engineering guide. I hope you've found it helpful and informative. Happy prompting!</p>","tags":["AI Engineering","Prompt Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/","title":"\ud83d\ude80 The Future of Engineering &amp; AI \u2014 Insights from CEOs","text":"","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#michael-truell-ceo-of-cursor","title":"Michael Truell - CEO of Cursor","text":"<p>\"We're not going straight to a world where AI does everything and engineers disappear. Instead, engineers are shifting roles\u2014from implementers to orchestrators.\"</p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#everyone-become-engineering-managers","title":"Everyone Become Engineering Managers","text":"<p>\"I think something people don't talk enough about when discussing AI agents and AI engineers doing all this stuff for you\u2026 is basically we're all becoming engineering managers.\"</p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#1-engineering-manager-analogy","title":"1. Engineering Manager Analogy:","text":"<ul> <li>As AI agents take on more of the implementation work, human engineers increasingly focus on specification, review, and iteration.</li> <li>It feels like managing a team of junior engineers that \u201caren\u2019t that smart yet\u201d \u2014 they constantly check in, and you need to inspect everything.</li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#2-cognitive-load-shifts","title":"2. Cognitive Load Shifts:","text":"<ul> <li>Instead of writing all the code, you spend more time:<ul> <li>Specifying the task with precision</li> <li>Reviewing AI output</li> <li>Iterating with tighter feedback loops</li> </ul> </li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#3-two-emerging-workflows","title":"3. Two Emerging Workflows:","text":"<ol> <li>Macro delegation: Specify everything upfront, let AI execute, then review the whole thing.</li> <li>Micro-iteration: Specify a small task, review the AI\u2019s output, iterate step-by-step.</li> </ol> <p>\"Most successful users today chop things up. They don\u2019t try to offload giant tasks all at once.\"</p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#4-the-vibe-coding-trap","title":"4. The Vibe Coding Trap:","text":"<ul> <li>Over-delegating to AI without sufficient understanding can lead to messy, unmaintainable code.</li> <li>Cursor aims to empower engineers to stay in the driver\u2019s seat while still leveraging automation.</li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#source-the-rise-of-cursor-the-300m-arr-ai-tool-that-engineers-cant-stop-using-michael-truell","title":"Source: The rise of Cursor: The $300M ARR AI tool that engineers can\u2019t stop using | Michael Truell.","text":"","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#varun-mohan-ceo-of-windsurf-acquired-by-openai","title":"Varun Mohan - CEO of Windsurf (acquired by OpenAI)","text":"<p>Why Varun believes 90% of Code Will Be AI-Generated \u2014 But Engineering Jobs Will Grow.</p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#1-code-becomes-the-commodity-taste-intent-become-the-skill","title":"1. Code Becomes the Commodity \u2014 Taste &amp; Intent Become the Skill","text":"<ul> <li>Most boilerplate and repetitive logic will be handled by AI.</li> <li>Engineers shift from typing syntax to defining what needs to be built \u2014 the higher-value, human work.</li> <li>This creates demand for more engineers who can think clearly, not just code.</li> </ul> <p>\"AI is lowering the barrier to turn ideas into working software. That doesn\u2019t kill engineering \u2014 it multiplies the demand.\" </p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#2-software-demand-is-unbounded","title":"2. Software Demand Is Unbounded","text":"<ul> <li>As cost of production drops, demand explodes:<ul> <li>More startups</li> <li>More internal tools</li> <li>More customization</li> </ul> </li> <li>Every team will want software tailored to their niche workflows.</li> </ul> <p>\"If software gets 10x cheaper to build, you don\u2019t fire engineers \u2014 you build 10x more software.\" </p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#3-engineers-become-architects-and-curators","title":"3. Engineers Become Architects and Curators","text":"<ul> <li>Engineers will act like project leads, reviewers, product thinkers.</li> <li>They\u2019ll manage AI-generated output, ensure quality, handle edge cases, and direct architecture decisions.</li> <li>This is analogous to how designers use Figma AI features \u2014 but the best still lead the process.</li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#4-ai-generates-code-not-context","title":"4. AI Generates Code, Not Context","text":"<ul> <li>AI lacks full understanding of:<ul> <li>Business goals</li> <li>User experience nuance</li> <li>Product strategy</li> </ul> </li> <li>Human engineers are essential for bridging code to real-world context.</li> </ul> <p>\"You still need humans to know what should be built \u2014 and why.\" </p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#5-more-non-engineers-will-create-software-but-engineers-will-enable-it","title":"5. More Non-Engineers Will Create Software \u2014 But Engineers Will Enable It","text":"<ul> <li>Low-code and AI tools let PMs, ops teams, and analysts build simple tools.</li> <li>But engineers are still needed to:<ul> <li>Build frameworks</li> <li>Ensure reliability</li> <li>Handle edge cases</li> <li>Maintain standards</li> </ul> </li> </ul> <p>\u201cAI is not replacing engineers \u2014 it\u2019s leveling them up.\u201d  </p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#source-building-a-magical-ai-code-editor-used-by-over-1m-developers-in-4-months-inside-windsurf","title":"Source: Building a magical AI code editor used by over 1m developers in 4 months: Inside Windsurf.","text":"","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#scott-wu-ceo-of-cognition-maker-of-devin","title":"Scott Wu - CEO of Cognition (maker of Devin)","text":"","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#1-why-engineering-will-shift-from-bricklayers-to-architects","title":"1. Why Engineering Will Shift from \u201cBricklayers\u201d to \u201cArchitects\u201d","text":"<p>\u201cOne of the ways that we've thought about Devin is really allowing engineers to go from bricklayer to architect.\u201d</p> <ul> <li> <p>Traditional Engineering is 90% Implementation</p> <ul> <li>Much of today\u2019s engineering involves debugging, boilerplate, migrations, CI/CD tasks, and infrastructure work.</li> <li>Only ~10% is truly architectural thinking \u2014 designing systems, understanding problems deeply, and crafting solutions.</li> </ul> </li> <li> <p>Devin Automates the Bricklaying</p> <ul> <li>By automating mundane and repetitive engineering tasks (e.g., writing boilerplate, fixing bugs, generating tests), Devin frees up engineers.</li> <li>Engineers can now focus on problem-solving, high-level system design, and decision-making.</li> </ul> </li> <li> <p>Programming Becomes More Important, Not Less</p> <ul> <li>Even as AI takes over more coding, knowing how to instruct the computer (i.e., understanding abstractions, systems, architecture) becomes even more valuable.</li> <li>Engineers evolve into system architects: defining the problem, specifying the desired solution, and orchestrating AI agents to execute it.</li> </ul> </li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#2-skills-that-will-grow-in-importance","title":"2. Skills That Will Grow in Importance:","text":"<ul> <li>System design and architecture</li> <li>Abstraction thinking and decomposition</li> <li>Precise specification and prompt engineering</li> <li>Understanding full-stack flows and trade-offs</li> <li>Collaborating with AI as a multiplier</li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#3-skills-that-will-diminish","title":"3. Skills That Will Diminish:","text":"<ul> <li>Low-level implementation</li> <li>Routine debugging and plumbing</li> <li>Manual CI/CD tasks and migrations</li> </ul>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#4-moats-and-stickiness-in-ai","title":"4. Moats and stickiness in AI","text":"<p>\"People talk about moats in AI \u2014 distribution, scale, model performance \u2014 but I think the real moat is user stickiness. AI that helps you with your data, your voice, your style, your tools, your business \u2014 the more personal it gets, the harder it is to switch.\" \u2014 Scott Wu</p>","tags":["AI Engineering"]},{"location":"2025/05/06/the-future-of-engineering--ai/#source-inside-devin-the-ai-engineer-thats-set-to-write-50-of-its-companys-code-this-year-scott-wu","title":"Source: Inside Devin: The AI engineer that's set to write 50% of its company\u2019s code this year | Scott Wu","text":"","tags":["AI Engineering"]},{"location":"2024/10/15/cursor-ai-done-right-lessons-from-building-multiple-mvps/","title":"Cursor AI Done Right: Lessons from Building Multiple MVPs","text":"<p>Cursor is really dumb if not given enough context about your project. Here what you can do to improve your Cursor workflow</p>","tags":["AI Engineering"]},{"location":"2024/10/15/cursor-ai-done-right-lessons-from-building-multiple-mvps/#1-brainstorm-first-code-second","title":"1. Brainstorm first, code second","text":"<p>Claude/o1 are your best friends here. You should create a whole document containing every single detail of your project.</p> <ul> <li>core features </li> <li>goals &amp; objectives</li> <li>tech stack &amp; packages</li> <li>project folder structure</li> <li>database design</li> <li>landing page components </li> <li>color palette </li> <li>copywriting </li> </ul> <p>All this should be put into an <code>instruction.md</code> (name it however you want) so Cursor can index at any time.</p>","tags":["AI Engineering"]},{"location":"2024/10/15/cursor-ai-done-right-lessons-from-building-multiple-mvps/#2-get-a-cursorrules-file","title":"2. Get a <code>.cursorrules</code> file","text":"<p>Many ignore this step. I get it\u2019s daunting to write a <code>.cursorrules</code> file but it will help tremendously.</p> <p>This is a great repo I always recommend to get you started. Choose your stack and edit it to match your preferences: awesome-cursorrules</p>","tags":["AI Engineering"]},{"location":"2024/10/15/cursor-ai-done-right-lessons-from-building-multiple-mvps/#3-use-v0-for-landing-page","title":"3. Use v0 for landing page","text":"<ul> <li> <p>Get your core features, color palette and components from your <code>instruction.md</code> file you got. </p> </li> <li> <p>Bonus tip is to use screenshots as reference from other landing pages just so v0 gets your idea. </p> </li> <li> <p>Use component libraries I recommend shadcn since v0 works great with it. I also use MagicUI. </p> </li> </ul> <p>Remember, you don\u2019t have to get it perfect with v0.  You only need something good enough you can take and edit later in cursor.</p>","tags":["AI Engineering"]},{"location":"2024/10/15/cursor-ai-done-right-lessons-from-building-multiple-mvps/#4-chat-vs-composer","title":"4. Chat vs Composer","text":"<ul> <li> <p>Use chat for smaller tasks and for explaining code/commands. Use it to ask questions and navigate your project. </p> </li> <li> <p>Use composer for writing the code, tag your <code>instruction.md</code> inside the composer always and tell him to update it as the project progresses.</p> </li> <li> <p>Only ask composer to do one task at a time. Make it make the changes step by step, if you ask to it to edit multiple files it will hallucinate and you will lose control.</p> </li> <li> <p>Always verify the code is clean before approving the change. </p> </li> <li> <p>Save your claude credits for the composer and use gpt-4o-mini with chat.</p> </li> </ul>","tags":["AI Engineering"]},{"location":"2024/10/15/cursor-ai-done-right-lessons-from-building-multiple-mvps/#5-tag-your-docs","title":"5. Tag your docs","text":"<ul> <li> <p>Copy the documentation for the framework you use.</p> </li> <li> <p>Go to Cursor Settings &gt; Features &gt; Docs </p> </li> <li> <p>Paste the links and use them inside chat/composer with <code>@Docs</code></p> </li> </ul>","tags":["AI Engineering"]},{"location":"2024/10/15/whats-model-context-protocol-mcp/","title":"What's Model Context Protocol (MCP)","text":"","tags":["AI Engineering","Model Context Protocol"]},{"location":"2024/10/15/whats-model-context-protocol-mcp/#introduction","title":"Introduction","text":"<p>Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to LLMs. It's a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.</p>","tags":["AI Engineering","Model Context Protocol"]},{"location":"2024/10/15/whats-model-context-protocol-mcp/#why-mcp","title":"Why MCP?","text":"<p>As AI assistants gain mainstream adoption, the industry has invested heavily in model capabilities, achieving rapid advances in reasoning and quality. Yet even the most sophisticated models are constrained by their isolation from data\u2014trapped behind information silos and legacy systems. Every new data source requires its own custom implementation, making truly connected systems difficult to scale.</p> <p>MCP addresses this challenge. It provides a universal, open standard for connecting AI systems with data sources, replacing fragmented integrations with a single protocol. The result is a simpler, more reliable way to give AI systems access to the data they need. \u200b</p>","tags":["AI Engineering","Model Context Protocol"]},{"location":"2024/10/15/whats-model-context-protocol-mcp/#general-architecture","title":"General architecture","text":"<p>MCP enables developers to build secure, two-way connections between their data sources and AI-powered tools. The architecture is straightforward: developers can either expose their data through MCP servers or build AI applications (MCP clients) that connect to these servers.</p> <p></p> <ul> <li>MCP Hosts: Programs like Claude Desktop, IDEs, or AI tools that want to access data through MCP</li> <li>MCP Clients: Protocol clients that maintain 1:1 connections with servers</li> <li>MCP Servers: Lightweight programs that each expose specific capabilities through the standardized Model Context Protocol</li> <li>Local Data Sources: Your computer\u2019s files, databases, and services that MCP servers can securely access</li> <li>Remote Services: External systems available over the internet (e.g., through APIs) that MCP servers can connect to</li> </ul>","tags":["AI Engineering","Model Context Protocol"]},{"location":"2024/10/15/what-is-rag/","title":"What is RAG?","text":"","tags":["AI Engineering"]},{"location":"2024/10/15/what-is-rag/#introduction","title":"Introduction\ud83d\ude80","text":"<p>RAG is a popular method that improves accuracy and relevance by finding the right information from reliable sources and transforming it into useful answers. </p> <p>Large Language Models are trained on a fixed dataset, which limits their ability to handle private or recent information. They can sometimes \"hallucinate\", providing incorrect yet believable answers. Fine-tuning can help but it is expensive and not ideal for retraining again and again on new data. The Retrieval-Augmented Generation (RAG) framework addresses this issue by using external documents to improve the LLM's responses through in-context learning. RAG ensures that the information provided by the LLM is not only contextually relevant but also accurate and up-to-date.</p> <p></p> <p>There are four main components in RAG:</p> <p>Indexing: First, documents (in any format) are split into chunks, and embeddings for these chunks are created. These embeddings are then added to a vector store.</p> <p>Retriever: Then, the retriever finds the most relevant documents based on the user's query, using techniques like vector similarity from the vector store.</p> <p>Augment: After that, the Augment part combines the user's query with the retrieved context into a prompt, ensuring the LLM has the information needed to generate accurate responses.</p> <p>Generate: Finally, the combined query and prompt are passed to the model, which then generates the final response to the user's query.</p> <p>These components of RAG allow the model to access up-to-date, accurate information and generate responses based on external knowledge. However, to ensure RAG systems are functioning effectively, it\u2019s essential to evaluate their performance.</p>","tags":["AI Engineering"]},{"location":"2024/10/15/what-is-rag/#rag-evaluation","title":"RAG Evaluation\ud83d\udcca","text":"<p>Evaluating RAG applications is important for understanding how well these systems work. We can see how effectively they combine information retrieval with generative models by checking their accuracy and relevance. This evaluation helps improve RAG applications in tasks like text summarization, chatbots, and question-answering. It also identifies areas for improvement, ensuring that these systems provide trustworthy responses as information changes.</p> <p></p>","tags":["AI Engineering"]},{"location":"2024/10/15/what-is-rag/#rag-techniques","title":"RAG Techniques\u2699\ufe0f","text":"Technique Tools Description Notebooks Naive RAG LangChain, Pinecone, Athina AI Combines retrieved data with LLMs for simple and effective responses. Hybrid RAG LangChain, Chromadb, Athina AI Combines vector search and traditional methods like BM25 for better information retrieval. Hyde RAG LangChain, Weaviate, Athina AI Creates hypothetical document embeddings to find relevant information for a query. Parent Document Retriever LangChain, Chromadb, Athina AI Breaks large documents into small parts and retrieves the full document if a part matches the query. RAG fusion LangChain, LangSmith, Qdrant, Athina AI Generates sub-queries, ranks documents with Reciprocal Rank Fusion, and uses top results for accurate responses. Contextual RAG LangChain, Chromadb, Athina AI Compresses retrieved documents to keep only relevant details for concise and accurate responses. Rewrite Retrieve Read LangChain, Chromadb, Athina AI Improves query, retrieves better data, and generates accurate answers. Corrective RAG LangChain, LangGraph, Chromadb, Athina AI Refines relevant documents, removes irrelevant ones or does the web search. Self RAG LangChain, LangGraph, FAISS, Athina AI Reflects on retrieved data to ensure accurate and complete responses. Adaptive RAG LangChain, LangGraph, FAISS, Athina AI Adjusts retrieval methods based on query type, using indexed data or web search.","tags":["AI Engineering"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/","title":"Why Reinforcement Learning (RL) is hot again?","text":"<p>Just finished listening to an incredible podcast featuring an interview with Wu Yi \u2014 a Tsinghua alum and former OpenAI researcher \u2014 and his take on Reinforcement Learning (RL) was one of the clearest I\u2019ve seen!</p>","tags":["AI Engineering","LLM"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/#1-what-is-rl-really-about","title":"\ud83d\udd0d 1. What is RL really about?","text":"<p>Wu Yi explains that RL is very different from traditional supervised learning (like image classification). In supervised learning, we train models using a fixed set of labeled data \u2014 one-shot answers.</p> <p>RL, on the other hand, is more like playing a game: you need to make a sequence of decisions (serve, move, react), and there's no single \u201ccorrect\u201d path. The quality of your decisions is judged by the final outcome (win or lose). It\u2019s about multi-step decision-making \u2014 much closer to how the real world works.</p>","tags":["AI Engineering","LLM"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/#2-why-is-rl-hot-again-whats-its-connection-to-llms","title":"\ud83e\udd16 2. Why is RL hot again? What\u2019s its connection to LLMs?","text":"<p>LLMs like GPT-3 were initially great at reciting facts but not great at following instructions.</p> <p>OpenAI used RL to fix that \u2014 specifically Reinforcement Learning from Human Feedback (RLHF). Humans rated model responses, which trained a \u201creward model\u201d to guide LLMs to be more helpful, honest, and harmless.</p> <p>Important insight: RLHF made LLMs more aligned, but not necessarily more intelligent.</p>","tags":["AI Engineering","LLM"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/#3-can-rl-make-llms-smarter","title":"\ud83e\udde0 3. Can RL make LLMs smarter?","text":"<p>People realized that humans solve complex problems by thinking first \u2014 step by step. So, what if LLMs could simulate \u201cslow thinking\u201d too?</p> <p>Turns out, if you let the model \u201cgenerate more thoughts\u201d (i.e., more tokens as intermediate reasoning steps), it mimics thought processes. And again, RL is used to train this \u2014 because we only care about the final answer being correct, not how it reasoned in between. Classic RL logic.</p>","tags":["AI Engineering","LLM"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/#4-rl-llm-power-combo","title":"\ud83d\udca1 4. RL + LLM = Power Combo","text":"<p>Can RL work alone? Not really. RL is great at decision-making, but weak at understanding. That\u2019s where LLMs come in \u2014 strong at comprehension and memory.</p> <p>So the winning formula is: LLM (understanding/memory) + RL (reasoning/decision-making) = stronger AI This is how OpenAI is building agents like Operator and Deep Research.</p>","tags":["AI Engineering","LLM"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/#5-future-of-rl-its-challenges","title":"\ud83d\ude80 5. Future of RL &amp; its challenges","text":"<p>RL still has massive untapped potential \u2014 its scaling laws are just getting started.</p> <p>Different companies are taking different paths:</p> <p>OpenAI is building agents</p> <p>Anthropic is focusing on code</p> <p>DeepSeek is pushing general reasoning (even answering philosophical questions)</p> <p>But RL is hard: high barrier to entry, complex infra, data requirements, and a \u201cblack magic\u201d vibe. Top talent is rare.</p>","tags":["AI Engineering","LLM"]},{"location":"2025/04/15/why-reinforcement-learning-rl-is-hot-again/#6-life-lessons-from-rl-this-part-was-brilliant","title":"\ud83c\udf31 6. Life Lessons from RL (this part was brilliant!)","text":"<p>Classic RL seeks one \u201coptimal policy\u201d and sticks with it. But Wu Yi found that humans are diversity-driven \u2014 we naturally try different paths to win.</p> <p>His life advice? Maximize entropy: try different things, especially while you\u2019re young and the cost of failure is low.</p> <p>Life is like RL \u2014 you have to explore to find your own \u201creward function\u201d (goals, meaning).</p> <p>Source: https://www.xiaoyuzhoufm.com/episode/67efcaf5f9578163d601286a</p>","tags":["AI Engineering","LLM"]},{"location":"posts/podcasts/","title":"Podcast Insights","text":"<p>Welcome to my collection of podcast summaries and insights, distilling key learnings from top tech and AI podcasts to keep you informed on technology, AI, software engineering, and personal growth.</p> <ul> <li>How to make first fortune</li> <li>How to overcome middle class</li> <li>The hidden power of introverts: How to thrive without changing who you are | Susan Cain</li> <li>The truth about leadership</li> <li>Persuasive communication and managing up</li> <li>How to speak</li> <li>Become a better communicator</li> </ul>"},{"location":"posts/podcasts/become_a_better_communicator/","title":"Become a better communicator","text":"<p>Specific frameworks to improve your clarity, influence, and impact.</p> <p>In today's fast-paced business environment, effective communication is not just a nice-to-have skill\u2014it's essential for career success. As Meta CTO Boz aptly states, \"Communication is the job.\" In this comprehensive guide, we'll explore powerful frameworks and tactics for becoming a more effective communicator, based on insights from communication expert Wes Kao.</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#why-communication-matters","title":"Why Communication Matters","text":"<p>The impact of poor communication can be far more significant than most people realize. As Wes explains:</p> <p>\"The blast radius of a poorly written memo is way bigger than most people think. If you're just shooting off a message in a Slack channel with 15 other people and it's confusing, there's going to be a bunch of back and forth. Whereas if you had just taken another look at it, those 15 people would be off to the races.\"</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#key-frameworks-for-better-communication","title":"Key Frameworks for Better Communication","text":"","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#1-sales-before-logistics","title":"1. Sales Before Logistics","text":"<p>One common mistake is jumping straight into the \"how\" before establishing the \"why.\" Wes advocates for a two-step approach:</p> <ol> <li>First, sell people on why something matters</li> <li>Only then share the logistics and details</li> </ol> <p>Even for seemingly quick communications, spending 30 seconds to frame the \"why\" can dramatically improve buy-in and understanding.</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#2-the-moo-framework-most-obvious-objection","title":"2. The MOO Framework (Most Obvious Objection)","text":"<p>Before presenting ideas or sending important communications, ask yourself: What are the most obvious objections someone might have? This simple practice helps you:</p> <ul> <li>Anticipate potential pushback</li> <li>Address concerns proactively</li> <li>Strengthen your argument before sharing</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#3-cedaf-framework-for-delegation","title":"3. CEDAF Framework for Delegation","text":"<p>When delegating tasks, whether to team members or AI assistants, use the CEDAF framework:  </p> <ul> <li>Comprehension: Ensure they have everything needed to understand the task  </li> <li>Excitement: Explain why this matters and generate enthusiasm</li> <li>De-risk: Identify and address potential risks upfront</li> <li>Align: Confirm mutual understanding</li> <li>Feedback: Establish short feedback loops</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#practical-tips-for-better-communication","title":"Practical Tips for Better Communication","text":"","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#being-concise","title":"Being Concise","text":"<p>Contrary to popular belief, being concise isn't about absolute word count\u2014it's about economy of words. Kao emphasizes:</p> <p>\"Being concise is not about absolute word count, it's about density of insight. You can have a 300-word memo that's meandering and long-winded and a thousand word memo that is tight and concise.\"</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#the-power-of-preparation","title":"The Power of Preparation","text":"<p>Even a few minutes of preparation before meetings or important communications can dramatically improve your effectiveness. Ask yourself:</p> <ul> <li>What do I want to achieve?</li> <li>What's my main point?</li> <li>What objections might arise?</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#managing-up-effectively","title":"Managing Up Effectively","text":"<p>The key to managing up isn't just updating your boss\u2014it's sharing your point of view. Instead of asking \"What should we do?\" try presenting your recommendation with supporting evidence and asking for feedback.</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#building-your-communication-toolkit","title":"Building Your Communication Toolkit","text":"","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#the-swipe-file-technique","title":"The Swipe File Technique","text":"<p>Create a collection of effective communication examples you encounter:</p> <ul> <li>Phrases that resonated</li> <li>Well-structured arguments</li> <li>Effective presentations</li> <li>Clear explanations</li> </ul> <p>Even if you rarely review it, the act of collecting these examples trains you to notice effective communication patterns.</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#leveraging-ai-for-better-communication","title":"Leveraging AI for Better Communication","text":"<p>AI tools like Claude can be powerful allies in improving communication. Kao shares how she uses AI:</p> <ul> <li>As a thought partner for drafting difficult messages</li> <li>To get alternative perspectives on communication approaches</li> <li>For refining and improving initial drafts</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#conclusion","title":"Conclusion","text":"<p>Becoming a better communicator isn't about dramatic changes\u2014it's about making small, consistent investments in how we communicate. As Wes emphasizes, spending just a few extra minutes on important communications can yield significant returns in clarity, influence, and impact.</p>","tags":["Growth"]},{"location":"posts/podcasts/become_a_better_communicator/#books-recommended","title":"Books Recommended","text":"<p>Here are the books mentioned by Wes and Lenny, along with why they\u2019re recommended:</p> <ul> <li> <p>On Writing Well by William Zinsser Recommended for learning to write more concisely and clearly. \u201cChapter after chapter of, \u2018Here\u2019s what you can cut. And you can cut more\u2026\u2019\u201d</p> </li> <li> <p>Stein on Writing by Sol Stein Another classic writing book, praised for its tactical advice.</p> </li> <li> <p>On Writing by Stephen King A popular memoir and guide on the craft of writing.</p> </li> <li> <p>A Series of Short Sentences About Writing by Verlyn Klinkenborg Recommended for understanding the power of short sentences.</p> </li> <li> <p>High Output Management by Andy Grove A classic on management and leadership, recommended by Wes.</p> </li> <li> <p>Your Brain at Work by Dr. David Rock Helps you understand your own brain and attention span to better allocate mental resources.</p> </li> </ul> <p>Link to the podcast: Become a better communicator: Specific frameworks to improve your clarity, influence, and impact </p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/","title":"Radical Self-Inquiry and the Real Equation for Great Leadership: Lessons from Jerry Colonna","text":"<p>What does it really take to be a great leader\u2014and a fulfilled human being? In a world obsessed with success, productivity, and constant growth, executive coach Jerry Colonna offers a radically different equation: practical skills plus radical self-inquiry plus shared experiences equals enhanced leadership and greater resilience. In a deeply honest and wide-ranging conversation, Jerry shares his insights on leadership, happiness, the myths of success, and the transformative power of asking ourselves the toughest questions.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#introduction-beyond-the-bullshit-of-success","title":"Introduction: Beyond the Bullshit of Success","text":"<p>From the outside, leaders often look like they\u2019re \u201ccrushing it.\u201d But as Jerry Colonna, CEO of Reboot and author of Reboot and Reunion, reminds us, appearances can be deceiving:</p> <p>\u201cWe're socialized to bullshit not only ourselves, but everybody else, especially in the entrepreneurial community. All our companies are moving up into the right. Every product is working. We don't really have any problems because we're crushing it, and that's just a lie.\u201d</p> <p>The real work, Jerry argues, is not just about acquiring more skills or strategies. It\u2019s about radical self-inquiry\u2014facing our own stories, fears, and motivations head-on.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#the-key-question-how-have-i-been-complicit","title":"The Key Question: How Have I Been Complicit?","text":"<p>At the heart of Jerry\u2019s coaching is a deceptively simple, yet profound question:</p> <p>\u201cHow have I been complicit in creating the conditions I say I don't want?\u201d</p> <p>This isn\u2019t about blaming yourself for your problems. Instead, it\u2019s about agency\u2014recognizing where we have power and responsibility to change our own lives. As Jerry explains:</p> <p>\u201cThe purpose of this question is actually to evoke your own agency, is to look at the ways in which you may have been diluting yourself.\u201d</p> <p>Whether it\u2019s chronic busyness, relationship issues, or dissatisfaction at work, Jerry encourages us to examine how our own choices, beliefs, and behaviors contribute to the situations we find ourselves in.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#the-equation-for-great-leadership","title":"The Equation for Great Leadership","text":"<p>Jerry\u2019s approach to leadership development boils down to a simple equation:</p> <p>Practical Skills + Radical Self-Inquiry + Shared Experiences = Enhanced Leadership and Greater Resilience</p> <ul> <li>Practical Skills: The \u201chow\u201d of leadership\u2014communication, decision-making, execution.</li> <li>Radical Self-Inquiry: The courage to ask hard questions about our motivations, fears, and patterns.</li> <li>Shared Experiences: Building community and vulnerability with others, breaking the isolation of leadership.</li> </ul> <p>\u201cPeople will come and ask me how, and I will drive them crazy because I will say something like, tell me about your father, or tell me why you chose to be in the job you're in the first place, or tell me about your relationship to money, or tell me about your relationship to self-worth.\u201d</p> <p>The goal? Not just to create better leaders, but to help people \u201cnot kill themselves in the process.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#the-big-lie-success-doesnt-guarantee-happiness","title":"The Big Lie: Success Doesn\u2019t Guarantee Happiness","text":"<p>One of the most persistent myths in our culture is that success leads to happiness. Jerry calls this out as \u201cthe big lie\u201d:</p> <p>\u201cA lot of people think that when they reach a certain point, become successful, make a certain amount of money, get a beautiful house, [they\u2019ll] be happy. And essentially what you're saying here is that's very often not the case. Maybe in most cases, not the case.\u201d</p> <p>He shares a personal story from his own life\u2014reaching outward success as a venture capitalist, only to find himself deeply depressed and unfulfilled. The lesson? Outward achievements don\u2019t resolve our inner struggles.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#consciousness-as-the-ultimate-hack","title":"Consciousness as the Ultimate Hack","text":"<p>So, what\u2019s the \u201chack\u201d for a more meaningful life and leadership? Jerry points to consciousness\u2014raising our awareness of why we do what we do.</p> <p>He encourages us to ask:</p> <ul> <li>What do I believe success will give me?</li> <li>Where did my definitions of success come from?</li> <li>What am I not saying that I need to say?</li> <li>How have my childhood experiences shaped my adult choices?</li> </ul> <p>\u201cThe hack, if you will, is consciousness. Part of what makes radical self-inquiry radical is we're socialized not to ask certain kinds of questions.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#facing-the-fear-of-consequences","title":"Facing the Fear of Consequences","text":"<p>Many people avoid self-inquiry because they fear what they\u2019ll find\u2014or what changes it might demand. Jerry acknowledges this fear:</p> <p>\u201cThe fear is if I go there, I don't know what's going to happen as a consequence of that... And the good news bad news is that's true. That is absolutely true.\u201d</p> <p>But avoiding our \u201cunsorted baggage\u201d only makes the pain worse over time. Jerry quotes Bruce Springsteen, who spent 25 years in psychoanalysis, warning that the price of not sorting out our childhood baggage \u201cmore often than not is in tears.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#radical-self-inquiry-in-practice-the-power-of-questions","title":"Radical Self-Inquiry in Practice: The Power of Questions","text":"<p>Jerry offers a set of powerful questions for radical self-inquiry, whether through journaling, meditation, or conversation:</p> <ul> <li>How have I been complicit in creating the conditions I say I don't want?</li> <li>What am I not saying that I need to say?</li> <li>What am I saying that's not being heard?</li> <li>What's being said that I'm not hearing?</li> </ul> <p>\u201cYou know you're in the radical self-inquiry zone when the questions take your breath away, when the questions... may cause us to be a little afraid of the answer, that's where the gold is.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#the-power-of-community-and-shared-experiences","title":"The Power of Community and Shared Experiences","text":"<p>Leadership\u2014and life\u2014can be lonely. That\u2019s why Jerry emphasizes the importance of shared experiences and supportive communities, whether in the form of circles, bootcamps, or simply honest conversations.</p> <p>\u201cImagine sitting in a circle of people who just have your back, who really care about you as a person. And imagine then discussing some of the answers to those questions... Imagine having the capacity to be in relationship with people where you can just tell the truth. That's what shared experiences are about.\u201d</p> <p>Even listening to authentic podcasts, Jerry suggests, can create space for realness and connection.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#the-trap-of-busyness-and-attachment","title":"The Trap of Busyness and Attachment","text":"<p>Why do so many of us stay perpetually busy? Often, it\u2019s to quiet the inner voice of self-doubt or to chase validation. But this \u201cattachment\u201d to outcomes\u2014whether it\u2019s success, money, or recognition\u2014only fuels suffering.</p> <p>\u201cWhen we become attached to the outcome, we inadvertently fuel our own suffering... But really the deeper attachment is see, I'm not nothing. See, I'm not a nobody, I'm a somebody, and that's the source of the suffering.\u201d</p> <p>The antidote? Learning to separate our self-worth from our achievements and embracing unconditional self-compassion.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#legacy-purpose-and-the-art-of-growing-up","title":"Legacy, Purpose, and the Art of Growing Up","text":"<p>As we reflect on our lives and leadership, questions of legacy and purpose inevitably arise. Jerry shares his own guiding question:</p> <p>\u201cWith my children being fully fledged adults, I am really focused on what kind of ancestor to my descendants would I like to be?... At the end of my days, what would I like the people who come after me to say about me?\u201d</p> <p>He finds meaning in striving to be kind, caring, and purposeful\u2014a \u201cgiving tree\u201d for others.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#the-impact-of-ai-and-the-future-of-humanity","title":"The Impact of AI and the Future of Humanity","text":"<p>The conversation also touches on the anxiety and excitement surrounding AI. Jerry is cautiously optimistic:</p> <p>\u201cWhat I am hopeful about is that that which does not matter in the experience of being human gets burned away and is taken care of, call it by AI, but that that which matters, which is presence and connection, human-to-human contact... that gets elevated and our skills get better at doing that.\u201d</p> <p>He encourages using AI as a tool for reflection and growth, but reminds us that the deepest answers still come from within.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#growth-mindset-a-double-edged-sword","title":"Growth Mindset: A Double-Edged Sword","text":"<p>While the concept of a \u201cgrowth mindset\u201d is popular, Jerry warns against turning it into another fixed rule:</p> <p>\u201cWhen we get too fixed on the proper way to do things, we're setting ourselves up for attachment and therefore suffering. So if you can hold something like a mindset loosely without attachment, go for it. Have a blast. Enjoy it. But the minute you start to nail it down to the floor and say this is the way it ought to be, I ought to always have a growth mindset, you've become fixed.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#radical-self-inquiry-in-teams-and-organizations","title":"Radical Self-Inquiry in Teams and Organizations","text":"<p>The issues that break teams and organizations, Jerry argues, are rarely about talent or strategy\u2014they\u2019re about unresolved personal and group dynamics, often rooted in childhood patterns.</p> <p>\u201cTeams are groups, and there are group dynamics that always happen... Without the individual's radical self-inquiry skills, groups tend to be condemned to repeating patterns oftentimes of their family of origin.\u201d</p> <p>Leaders, especially, have a moral responsibility to do their own internal work. As Parker Palmer says:</p> <p>\u201cIf you choose to live an unexamined life, please don't take a job that involves other people.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#conclusion-you-are-not-alone","title":"Conclusion: You Are Not Alone","text":"<p>Ultimately, Jerry\u2019s message is one of hope and solidarity:</p> <p>\u201cWhat I always hope from all of these intimate conversations that I try to do in podcasts is that people walk away going, \u2018Geez, I'm not alone.\u2019... What makes it hardest is to feel like. I'm the only one who's going through this.\u201d</p> <p>The path to great leadership\u2014and a meaningful life\u2014starts with radical honesty, deep self-inquiry, and the courage to connect with others. The questions may be hard, but the rewards are resilience, authenticity, and a sense of true belonging.</p>","tags":["Growth"]},{"location":"posts/podcasts/ceo_coaching/#books-mentioned-and-recommended","title":"Books Mentioned and Recommended","text":"<ul> <li> <p>Reboot: Leadership and the Art of Growing Up by Jerry Colonna Jerry\u2019s first book, foundational for radical self-inquiry and leadership.</p> </li> <li> <p>Reunion by Jerry Colonna Jerry\u2019s second book, exploring connection and self-discovery.</p> </li> <li> <p>Soldiers and Kings by Jason De Le\u00f3n Recommended by Jerry for its exploration of human smuggling and the realities of Central America.</p> </li> <li> <p>The Giving Tree by Shel Silverstein Referenced as a metaphor for legacy and purposeful living.</p> </li> <li> <p>Bruce Springsteen\u2019s Autobiography (Born to Run) Cited for its honest discussion of the \u201cunsorted baggage\u201d of childhood and the importance of self-work.</p> </li> </ul> <p>Ready to start your own journey of radical self-inquiry? Try journaling with Jerry\u2019s four questions, or gather a circle of friends for an honest conversation. Remember: better humans make better leaders\u2014and you are not alone.</p> <p>Podcast: How have I been complicit in creating the conditions I say I don\u2019t want? | Jerry Colonna </p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_make_first_fortune/","title":"\u5982\u4f55\u8d5a\u5230\u4eba\u751f\u7684\u7b2c\u4e00\u6876\u91d1\uff1a\u8ba4\u77e5\u4e0e\u884c\u52a8\u7684\u529b\u91cf","text":"<p>\u5728\u4eca\u5929\u7684\u64ad\u5ba2\u4e2d\uff0c\u6211\u4eec\u6df1\u5165\u63a2\u8ba8\u4e86\u4e00\u4e2a\u6240\u6709\u4eba\u90fd\u5173\u5fc3\u7684\u8bdd\u9898\u2014\u2014\u5982\u4f55\u8d5a\u5230\u4eba\u751f\u7684\u7b2c\u4e00\u6876\u91d1\u3002\u8fd9\u4e0d\u4ec5\u662f\u4e00\u4e2a\u8d22\u5bcc\u79ef\u7d2f\u7684\u8fc7\u7a0b\uff0c\u66f4\u662f\u5173\u4e8e\u8ba4\u77e5\u63d0\u5347\u3001\u6280\u80fd\u9009\u62e9\u4ee5\u53ca\u4eba\u751f\u610f\u4e49\u7684\u6df1\u523b\u8ba8\u8bba\u3002\u5982\u679c\u4f60\u4e5f\u5728\u5bfb\u627e\u5b9e\u73b0\u8d22\u5bcc\u81ea\u7531\u7684\u8def\u5f84\uff0c\u8fd9\u7bc7\u6587\u7ae0\u5c06\u4e3a\u4f60\u63d0\u4f9b\u542f\u53d1\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#_2","title":"\u7b2c\u4e00\u6876\u91d1\u7684\u91cd\u8981\u6027","text":"<p>\u5728\u64ad\u5ba2\u4e2d\uff0c\u5609\u5bbe\u4eec\u53cd\u590d\u5f3a\u8c03\u4e86\u201c\u7b2c\u4e00\u6876\u91d1\u201d\u7684\u91cd\u8981\u6027\u3002\u62e5\u6709\u7b2c\u4e00\u6876\u91d1\u540e\uff0c\u8d5a\u94b1\u7684\u6e38\u620f\u89c4\u5219\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u4ece\u201c\u65f6\u95f4\u6362\u94b1\u201d\u8f6c\u53d8\u4e3a\u201c\u8d44\u672c\u589e\u503c\u201d\u3002\u8fd9\u5c31\u50cf\u4e00\u4e2a\u6e38\u620f\uff0c\u79f0\u4e3a\u201c\u7ffb\u500d\u6e38\u620f\u201d\uff08Doubles Game\uff09\u3002\u5609\u5bbe\u6307\u51fa\uff1a</p> <p>\u201c\u5f53\u4f60\u6709\u4e86\u7b2c\u4e00\u6876\u91d1\u4e4b\u540e\uff0c\u4e4b\u540e\u7684\u91d1\u94b1\u6e38\u620f\u53d8\u5f97\u7b80\u5355\u4e86\u5f88\u591a\u3002\u201d</p> <p>\u7b2c\u4e00\u6876\u91d1\u4e0d\u4ec5\u662f\u8d22\u5bcc\u79ef\u7d2f\u7684\u5f00\u59cb\uff0c\u4e5f\u662f\u8ba4\u77e5\u63d0\u5347\u7684\u7ed3\u679c\u3002\u5b83\u4e3a\u6211\u4eec\u6253\u5f00\u4e86\u8d44\u672c\u56de\u62a5\u7387\u8fdc\u9ad8\u4e8e\u52b3\u52a8\u56de\u62a5\u7387\u7684\u5927\u95e8\uff0c\u5e26\u6765\u4e86\u66f4\u591a\u7684\u9009\u62e9\u548c\u673a\u4f1a\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#_3","title":"\u6559\u80b2\u4e0e\u8d22\u5bcc\uff1a\u4e3a\u4f55\u5b66\u6821\u6559\u80b2\u65e0\u6cd5\u6559\u4f1a\u6211\u4eec\u8d5a\u94b1\uff1f","text":"<p>\u64ad\u5ba2\u4e2d\u63d0\u5230\uff0c\u4f20\u7edf\u5b66\u6821\u6559\u80b2\u867d\u7136\u5e2e\u52a9\u6211\u4eec\u6210\u4e3a\u793e\u4f1a\u8fd0\u8f6c\u4e2d\u7684\u4e00\u9897\u87ba\u4e1d\u9489\uff0c\u5374\u5ffd\u7565\u4e86\u4e24\u4e2a\u5173\u952e\u9886\u57df\u2014\u2014\u5982\u4f55\u4f7f\u7528\u91d1\u94b1\u548c\u5982\u4f55\u8ffd\u6c42\u5e78\u798f\u3002\u54c8\u4f5b\u6821\u957f\u66fe\u63d0\u5230\uff1a</p> <p>\u201c\u5b66\u6821\u6559\u80b2\u7f3a\u5c11\u8ba9\u4eba\u4eec\u5b66\u4e60\u5982\u4f55\u53bb\u4f7f\u7528\u94b1\uff0c\u628a\u91d1\u94b1\u5f53\u505a\u4e00\u79cd\u5de5\u5177\uff0c\u4e5f\u7f3a\u5c11\u5173\u4e8e\u5e78\u798f\u5b66\u7684\u6559\u80b2\u3002\u201d</p> <p>\u8fd9\u4f7f\u5f97\u5927\u591a\u6570\u4eba\u53ea\u80fd\u4f9d\u9760\u51fa\u5356\u65f6\u95f4\u6362\u53d6\u91d1\u94b1\uff0c\u800c\u7f3a\u4e4f\u5173\u4e8e\u8d22\u5bcc\u79ef\u7d2f\u548c\u4eba\u751f\u610f\u4e49\u7684\u6df1\u523b\u8ba4\u77e5\u3002\u5609\u5bbe\u8fdb\u4e00\u6b65\u6307\u51fa\uff0c\u5f88\u591a\u5bb6\u5ead\u73af\u5883\u4e2d\uff0c\u7236\u6bcd\u5e76\u4e0d\u8ba8\u8bba\u5de5\u4f5c\u7684\u610f\u4e49\uff0c\u800c\u662f\u804a\u516b\u5366\u548c\u5de5\u8d44\uff0c\u8fd9\u8ba9\u5e74\u8f7b\u4eba\u96be\u4ee5\u57f9\u517b\u5bf9\u95ee\u9898\u672c\u8d28\u7684\u601d\u8003\u80fd\u529b\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#_4","title":"\u5982\u4f55\u8d5a\u5230\u7b2c\u4e00\u6876\u91d1\uff1f","text":"<p>\u64ad\u5ba2\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6e05\u6670\u7684\u8def\u5f84\uff0c\u4ece\u96f6\u5f00\u59cb\u79ef\u7d2f\u7b2c\u4e00\u6876\u91d1\uff1a</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#1","title":"1. \u6295\u8d44\u65f6\u95f4\u6362\u6280\u80fd","text":"<p>\u5728\u6ca1\u6709\u8d44\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u65f6\u95f4\u662f\u6211\u4eec\u6700\u5927\u7684\u8d44\u4ea7\u3002\u5609\u5bbe\u5efa\u8bae\uff1a</p> <p>\u201c\u521a\u5f00\u59cb\u6211\u4f1a\u6295\u8d44\u65f6\u95f4\u6362\u6280\u80fd\uff0c\u7136\u540e\u6280\u80fd\u6362\u6210\u73b0\u91d1\uff0c\u73b0\u91d1\u518d\u6362\u6210\u8d44\u4ea7\u3002\u201d</p> <p>\u5173\u952e\u662f\u9009\u62e9\u6709\u5e02\u573a\u4ef7\u503c\u7684\u6280\u80fd\uff0c\u4f8b\u5982\u7f16\u7a0b\u3001\u6570\u636e\u79d1\u5b66\u6216\u5176\u4ed6\u7b26\u5408\u5f53\u524d\u884c\u4e1a\u8d8b\u52bf\u7684\u9886\u57df\u3002\u5373\u4f7f\u8fd9\u4e9b\u6280\u80fd\u53ef\u80fd\u4e0d\u662f\u4f60\u7684\u70ed\u7231\uff0c\u5b83\u4eec\u53ea\u662f\u4e00\u4e2a\u5de5\u5177\uff0c\u7528\u6765\u5b9e\u73b0\u8d22\u5bcc\u79ef\u7d2f\u7684\u76ee\u6807\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#2","title":"2. \u57cb\u5934\u8d5a\u94b1\uff0c\u4e13\u6ce8\u76ee\u6807","text":"<p>\u79ef\u7d2f\u7b2c\u4e00\u6876\u91d1\u7684\u8fc7\u7a0b\u9700\u8981\u4e13\u6ce8\u548c\u8010\u5fc3\u3002\u5728\u8fd9\u4e00\u9636\u6bb5\uff0c\u5609\u5bbe\u5f3a\u8c03\u201c\u8bfe\u9898\u5206\u79bb\u201d\u7684\u91cd\u8981\u6027\uff1a</p> <p>\u201c\u79ef\u7d2f\u7b2c\u4e00\u6876\u91d1\u5c31\u662f\u4e3a\u4e86\u79ef\u7d2f\u7b2c\u4e00\u6876\u91d1\uff0c\u4e0d\u9700\u8981\u53bb\u8003\u8651\u592a\u591a\u4f60\u662f\u4e0d\u662f\u8981\u4e3a\u6b64\u6295\u5165\u4e00\u751f\u7684\u65f6\u95f4\u3002\u201d</p> <p>\u4e0d\u8981\u8fc7\u5ea6\u8ffd\u6c42\u7406\u60f3\uff0c\u53ea\u9700\u627e\u5230\u5355\u4f4d\u65f6\u95f4\u56de\u62a5\u9ad8\u7684\u5de5\u4f5c\uff0c\u5e76\u6301\u7eed\u6295\u5165\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#3","title":"3. \u63a7\u5236\u5f00\u652f\uff0c\u907f\u514d\u6d88\u8d39\u9677\u9631","text":"<p>\u64ad\u5ba2\u4e2d\u63d0\u5230\u4e00\u4e2a\u6545\u4e8b\uff1a\u4e00\u4f4d\u52a0\u6cb9\u7ad9\u5de5\u4f5c\u7684\u8001\u4eba\u53bb\u4e16\u540e\u88ab\u53d1\u73b0\u62e5\u6709800\u4e07\u7f8e\u5143\u8d44\u4ea7\u3002\u8fd9\u8bf4\u660e\u8d22\u5bcc\u79ef\u7d2f\u4e0e\u5de5\u4f5c\u672c\u8eab\u7684\u6536\u5165\u9ad8\u4f4e\u5e76\u65e0\u7edd\u5bf9\u5173\u7cfb\u3002\u5173\u952e\u5728\u4e8e\uff1a</p> <p>\u201c\u5728\u7b2c\u4e00\u4e2a\u9636\u6bb5\u6700\u5927\u7684\u4efb\u52a1\u5c31\u662f\u5b58\u94b1\uff0c\u800c\u4e0d\u662f\u53bb\u4e3a\u4e86\u6ee1\u8db3\u5176\u4ed6\u4eba\u7684\u671f\u5f85\u8d2d\u4e70\u5404\u79cd\u6d88\u8d39\u54c1\u3002\u201d</p> <p>\u901a\u8fc7\u8282\u4fed\u7684\u751f\u6d3b\u65b9\u5f0f\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u5f00\u652f\uff0c\u4f60\u53ef\u4ee5\u66f4\u5feb\u5730\u63a5\u8fd1\u4f60\u7684\u7b2c\u4e00\u6876\u91d1\u76ee\u6807\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#4","title":"4. \u63d0\u5347\u8ba4\u77e5\uff0c\u7a81\u7834\u4fe1\u606f\u51cf\u9632","text":"<p>\u5609\u5bbe\u7279\u522b\u5f3a\u8c03\u8ba4\u77e5\u7684\u91cd\u8981\u6027\uff1a</p> <p>\u201c\u4f60\u53ea\u80fd\u8d5a\u8ba4\u77e5\u5185\u7684\u94b1\uff0c\u8d5a\u4e86\u8ba4\u77e5\u5916\u7684\u94b1\u80af\u5b9a\u4f1a\u8d54\u6389\u3002\u201d</p> <p>\u63d0\u5347\u8ba4\u77e5\u7684\u65b9\u6cd5\u5305\u62ec\uff1a\u8fdc\u79bb\u4f4e\u4ef7\u503c\u7684\u4fe1\u606f\u6d88\u8d39\uff0c\u4e13\u6ce8\u4e8e\u6709\u610f\u4e49\u7684\u5b66\u4e60\u548c\u89c2\u5bdf\uff0c\u907f\u514d\u968f\u6ce2\u9010\u6d41\u3002\u53ea\u6709\u8ba4\u77e5\u63d0\u5347\uff0c\u624d\u80fd\u770b\u900f\u95ee\u9898\u7684\u672c\u8d28\uff0c\u627e\u5230\u9002\u5408\u81ea\u5df1\u7684\u673a\u4f1a\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#_5","title":"\u8d22\u5bcc\u81ea\u7531\u7684\u8def\u5f84\uff1a\u4ece\u7b2c\u4e00\u6876\u91d1\u5230\u8d44\u672c\u6e38\u620f","text":"<p>\u62e5\u6709\u7b2c\u4e00\u6876\u91d1\u540e\uff0c\u8d22\u5bcc\u79ef\u7d2f\u8fdb\u5165\u8d44\u672c\u589e\u503c\u9636\u6bb5\u3002\u5609\u5bbe\u89e3\u91ca\u4e86\u201c\u7ffb\u500d\u6e38\u620f\u201d\u7684\u89c4\u5219\uff1a</p> <p>\u201c\u5f53\u4f60\u6709\u4e00\u767e\u4e07\u4f5c\u4e3a\u7b2c\u4e00\u6876\u91d1\u65f6\uff0c\u53ea\u9700\u8981\u4e09\u4e2a\u7ffb\u500d\u5c31\u53ef\u4ee5\u53d8\u6210\u516b\u767e\u4e07\u3002\u201d</p> <p>\u5728\u8fd9\u4e00\u9636\u6bb5\uff0c\u6295\u8d44\u6210\u4e3a\u5173\u952e\u3002\u901a\u8fc7\u6b63\u786e\u7684\u6295\u8d44\u5de5\u5177\u548c\u7b56\u7565\uff0c\u8d44\u672c\u7684\u590d\u5229\u6548\u5e94\u5c06\u8fdc\u8fdc\u8d85\u8d8a\u52b3\u52a8\u56de\u62a5\u3002</p>"},{"location":"posts/podcasts/how_to_make_first_fortune/#_6","title":"\u7ed3\u8bed\uff1a\u8d22\u5bcc\u7684\u672c\u8d28\u4e0e\u4eba\u751f\u610f\u4e49","text":"<p>\u867d\u7136\u64ad\u5ba2\u7684\u4e3b\u9898\u662f\u8d22\u5bcc\uff0c\u4f46\u5609\u5bbe\u4eec\u66f4\u5e0c\u671b\u5927\u5bb6\u5173\u6ce8\u8d22\u5bcc\u80cc\u540e\u7684\u610f\u4e49\u3002\u91d1\u94b1\u53ea\u662f\u4e00\u4e2a\u5de5\u5177\uff0c\u5b83\u7684\u6700\u7ec8\u76ee\u7684\u662f\u670d\u52a1\u4e8e\u4eba\u751f\u7684\u5e78\u798f\u548c\u81ea\u7531\u3002\u6b63\u5982\u64ad\u5ba2\u4e2d\u63d0\u5230\u7684\uff1a</p> <p>\u201c\u8d22\u5bcc\u56e0\u4e3a\u592a\u7b80\u5355\u4e86\uff0c\u5b83\u6446\u5728\u773c\u524d\uff0c\u53ef\u662f\u90a3\u4e9b\u770b\u4e0d\u5230\u7684\u4e1c\u897f\u624d\u662f\u6700\u91cd\u8981\u7684\u3002\u201d</p> <p>\u79ef\u7d2f\u8d22\u5bcc\u7684\u8fc7\u7a0b\u4e0d\u4ec5\u662f\u4e00\u4e2a\u8d5a\u94b1\u7684\u65c5\u7a0b\uff0c\u66f4\u662f\u4e00\u4e2a\u8ba4\u77e5\u63d0\u5347\u548c\u81ea\u6211\u6210\u957f\u7684\u8fc7\u7a0b\u3002\u5e0c\u671b\u8fd9\u7bc7\u6587\u7ae0\u80fd\u4e3a\u4f60\u63d0\u4f9b\u542f\u53d1\uff0c\u5e2e\u52a9\u4f60\u8fc8\u5411\u4eba\u751f\u7684\u7b2c\u4e00\u6876\u91d1\u3002</p> <p>\u542c\u64ad\u5ba2\uff1a\u5982\u4f55\u79ef\u7d2f\u7b2c\u4e00\u6876\u91d1\uff1f\uff5c\u6446\u8131\u97ed\u83dc\u601d\u7ef4\u7684\u6700\u540e\u4e00\u6b21\u52aa\u529b\uff5cLeon\u8bbf\u8c08_\u4e0a</p>"},{"location":"posts/podcasts/how_to_overcome_middle_class/","title":"\u88ab\u56f0\u4e2d\u4ea7\uff1a\u9003\u51fa\u6d88\u8d39\u9677\u9631\uff0c\u8fc8\u5411\u8d22\u5bcc\u81ea\u7531\u7684\u53cd\u4eba\u6027\u6e38\u620f","text":""},{"location":"posts/podcasts/how_to_overcome_middle_class/#_2","title":"\u5f15\u8a00\uff1a\u4f60\u771f\u7684\u5728\u4e3a\u81ea\u5df1\u5de5\u4f5c\u5417\uff1f","text":"<p>\u5728\u8fd9\u4e2a\u4eba\u4eba\u8c08\u8bba\u201c\u8d22\u5bcc\u81ea\u7531\u201d\u7684\u65f6\u4ee3\uff0c\u5927\u591a\u6570\u4eba\u5374\u56f0\u5728\u4e86\u770b\u4e0d\u89c1\u7684\u67b7\u9501\u4e2d\u3002\u4e70\u623f\u4e70\u8f66\u3001\u7cbe\u81f4\u751f\u6d3b\u3001\u6602\u8d35\u987e\u95ee\u670d\u52a1\u2026\u2026\u6211\u4eec\u4ee5\u4e3a\u5728\u63d0\u5347\u751f\u6d3b\u54c1\u8d28\uff0c\u5374\u53ef\u80fd\u6b63\u9677\u5165\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u201c\u4e2d\u4ea7\u9677\u9631\u201d\u3002</p> <p>\u5728\u672c\u671f\u64ad\u5ba2\u4e2d\uff0c\u4e3b\u6301\u4eba\u548c\u5609\u5bbe\u6df1\u523b\u5256\u6790\u4e86\u73b0\u4ee3\u4e2d\u4ea7\u9762\u4e34\u7684\u4e09\u5927\u9677\u9631\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u201c\u53cd\u4eba\u6027\u201d\u7684\u7b56\u7565\u5b9e\u73b0\u9636\u5c42\u7a81\u7834\u3002\u4ed6\u4eec\u7528\u7280\u5229\u7684\u8bed\u8a00\u3001\u771f\u5b9e\u7684\u6848\u4f8b\u4ee5\u53ca\u5e7d\u9ed8\u7684\u6bd4\u55bb\uff0c\u4e3a\u6211\u4eec\u63ed\u793a\u4e86\u8d22\u5bcc\u6e38\u620f\u7684\u771f\u76f8\u3002</p>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_3","title":"\u4e2d\u4ea7\u9677\u9631\u4e00\uff1a\u6d88\u8d39\u662f\u4e00\u79cd\u9690\u5f62\u5974\u5f79","text":"<p>\u201c\u6d88\u8d39\u5176\u5b9e\u662f\u4e00\u79cd\u975e\u5e38\u9ad8\u660e\u7684\u5974\u96b6\u5236\u5ea6\u3002\u5b83\u7684\u5974\u96b6\u4e3b\u662f\u8c01\uff1fLVMH\u3002\u201d</p> <p>\u8fd9\u662f\u672c\u671f\u64ad\u5ba2\u4e2d\u6700\u5177\u51b2\u51fb\u529b\u7684\u89c2\u70b9\u4e4b\u4e00\u3002\u6d88\u8d39\u4e3b\u4e49\u901a\u8fc7\u6ee1\u8db3\u6211\u4eec\u7684\u865a\u8363\u3001\u5ac9\u5992\u4e0e\u8d2a\u5a6a\uff0c\u521b\u9020\u51fa\u672c\u4e0d\u5b58\u5728\u7684\u9700\u6c42\u3002\u5962\u4f88\u54c1\u54c1\u724c\u5982LVMH\uff0c\u6b63\u662f\u901a\u8fc7\u7cbe\u7ec6\u7684\u5b9a\u4ef7\u548c\u54c1\u724c\u5305\u88c5\uff0c\u8ba9\u5404\u4e2a\u6536\u5165\u9636\u5c42\u7684\u4eba\u90fd\u5fc3\u7518\u60c5\u613f\u5730\u201c\u88ab\u6536\u5272\u201d\u3002</p> <p>\u5178\u578b\u4f8b\u5b50\u5305\u62ec\uff1a</p> <ul> <li> <p>\u4e70\u8f66\u3001\u4e70\u5305\u3001\u4f4f\u8c6a\u5b85\uff0c\u6ee1\u8db3\u7684\u662f\u522b\u4eba\u7684\u773c\u5149\uff0c\u800c\u975e\u81ea\u5df1\u7684\u672c\u8d28\u9700\u6c42\uff1b</p> </li> <li> <p>\u9ad8\u6602\u7684\u670d\u52a1\u8d39\u7528\uff08\u5982\u79c1\u4eba\u987e\u95ee\u3001\u62a5\u7a0e\u5e08\uff09\uff0c\u4e5f\u5c5e\u4e8e\u201c\u7cbe\u81f4\u9677\u9631\u201d\uff1b</p> </li> <li> <p>\u8d37\u6b3e\u6d88\u8d39\u88ab\u5305\u88c5\u4e3a\u201c\u53ca\u65f6\u884c\u4e50\u201d\uff0c\u5b9e\u5219\u9501\u6b7b\u672a\u6765\u81ea\u7531\u3002</p> </li> </ul> <p>\u5efa\u8bae\uff1a</p> <ul> <li> <p>\u533a\u5206\u201c\u6d88\u8d39\u54c1\u201d\u4e0e\u201c\u8d44\u4ea7\u201d\uff1a\u4e70\u623f\u81ea\u4f4f\u2260\u6295\u8d44\uff0c\u80fd\u51fa\u79df\u4ea7\u751f\u73b0\u91d1\u6d41\u7684\u623f\u5b50\u624d\u662f\u771f\u6b63\u7684\u8d44\u4ea7\uff1b</p> </li> <li> <p>\u53cd\u5411\u601d\u8003\uff1a\u522b\u4eba\u4e89\u76f8\u8ffd\u9010\u7684\u4e1c\u897f\uff0c\u5f80\u5f80\u4e0d\u662f\u957f\u671f\u4ef7\u503c\u6240\u5728\u3002</p> </li> </ul>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_4","title":"\u4e2d\u4ea7\u9677\u9631\u4e8c\uff1a\u6295\u8d44\u4e0d\u662f\u6377\u5f84\uff0c\u662f\u53cc\u5203\u5251","text":"<p>\u6295\u8d44\u662f\u8d22\u5bcc\u589e\u503c\u7684\u5173\u952e\uff0c\u4f46\u6295\u8d44\u9677\u9631\u8fdc\u6bd4\u6d88\u8d39\u9677\u9631\u5371\u9669\u3002\u64ad\u5ba2\u7528\"\u8292\u679c\u7684\u6545\u4e8b\"\u8bf4\u660e\u4e86\u4eba\u6027\u5728\u6295\u8d44\u4e2d\u7684\u5f31\u70b9\u2014\u2014\u8d2a\u5a6a\u548c\u5bf9\u7b80\u5355\u7b54\u6848\u7684\u6e34\u671b\u3002  </p> <p>\u60f3\u8c61\u4f60\u624b\u4e0a\u6709\u5927\u91cf\u8292\u679c\uff0c\u60f3\u5356\u7ed9\u4e00\u4e2a\u4ece\u672a\u89c1\u8fc7\u8292\u679c\u7684\u6751\u5b50\u3002\u5927\u591a\u6570\u4eba\u4f1a\u60f3\u5230\uff1a</p> <p>\u201c\u6211\u505a\u5e7f\u544a\uff0c\u514d\u8d39\u53d1\u8bd5\u5403\u3002\u201d</p> <p>\u8fd9\u662f\u5236\u9020\u6d88\u8d39\u3002\u4f46\u5982\u679c\u4f60\u5047\u88c5\u8bf4\uff1a</p> <p>\u201c\u6211\u6765\u6536\u8292\u679c\uff0c\u4ef7\u683c\u8d8a\u9ad8\u8d8a\u597d\u3002\u201d</p> <p>\u6751\u6c11\u4e00\u542c\uff0c\u5f00\u59cb\u75af\u62a2\u8292\u679c\uff0c\u56db\u5904\u6536\u8d2d\uff0c\u7136\u540e\u8bd5\u56fe\u9ad8\u4ef7\u5356\u7ed9\u4f60\u3002\u4f60\u518d\u901a\u8fc7\u6e20\u9053\u4f4e\u4ef7\u628a\u8292\u679c\u201c\u5356\u56de\u6765\u201d\uff0c\u4ece\u800c\u83b7\u5229\u3002</p> <p>\u8fd9\u4e2a\u6e38\u620f\u5229\u7528\u4e86\u4eba\u6027\u7684\u8d2a\u5a6a\u3001\u4ece\u4f17\u5fc3\u7406\u548c\u6025\u4e8e\u66b4\u5bcc\u7684\u5e7b\u60f3\uff0c\u8ba9\u4eba\u81ea\u613f\u8fdb\u5957\u3002\u6545\u4e8b\u8bbd\u523a\u7684\u662f\uff0c\u5927\u90e8\u5206\u6240\u8c13\u201c\u673a\u4f1a\u201d\uff0c\u6b63\u662f\u4ed6\u4eba\u8bbe\u8ba1\u597d\u7684\u6536\u5272\u573a\u3002</p> <p>\u201c\u89c1\u6548\u5feb\u3001\u98ce\u9669\u4f4e\u3001\u56de\u62a5\u9ad8\uff0c\u8fd9\u5c31\u662f\u4e00\u4e2a\u9a97\u5c40\uff0c\u4f46\u5927\u591a\u6570\u4eba\u662f\u4e0d\u60f3\u53bb\u601d\u8003\u7684\u3002\u201d</p> <p>\u5927\u591a\u6570\u4eba\u8ffd\u9010\u90bb\u5c45\u7684\u6210\u529f\u7ecf\u9a8c\uff0c\u76f2\u76ee\u8ddf\u98ce\uff0c\u5bb9\u6613\u6389\u5165\u6295\u8d44\u9a97\u5c40\u3002 \u64ad\u5ba2\u5609\u5bbe\u63d0\u9192\uff1a\u201c\u5f53\u4f60\u60f3\u8981\u4e00\u4e2a\u7b80\u5355\u7b54\u6848\uff0c\u7b80\u5355\u7b54\u6848\u4f1a\u7ed9\u4f60\u7684\uff0c\u7136\u540e\u8fd9\u4e2a\u7b80\u5355\u7b54\u6848\u5c31\u662f\u5bf9\u4f60\u7684\u9677\u9631\u3002\u201d</p> <p>\u5e38\u89c1\u6295\u8d44\u9677\u9631\u5305\u62ec\uff1a</p> <ul> <li>\u88ab\u52a8\u8ffd\u98ce\u53e3\uff0c\u6bd4\u5982\u77ed\u671f\u66b4\u6da8\u7684\u80a1\u7968\u3001\u5e01\u5708\u3001NFT\uff1b</li> <li>\u5c06\u201c\u6d88\u8d39\u4f2a\u88c5\u6210\u6295\u8d44\u201d\uff0c\u4f8b\u5982\u623f\u3001\u8f66\u3001\u88c5\u4fee\u7b49\u65e0\u6cd5\u5e26\u6765\u6b63\u73b0\u91d1\u6d41\u7684\u652f\u51fa\uff1b</li> <li>\u5ffd\u89c6\u5e02\u573a\u5468\u671f\u4e0e\u4eba\u6027\u5f31\u70b9\uff0c\u5982\u7126\u8651\u3001\u8d2a\u5a6a\u548c\u6050\u60e7\u3002</li> </ul> <p>\u5efa\u8bae\uff1a</p> <ul> <li>\u8ba4\u6e05\u4eba\u6027\u4e2d\u7684\u5f31\u70b9\uff08\u8d2a\u5a6a\u3001\u6050\u60e7\u3001\u538c\u6076\u98ce\u9669\uff09</li> <li>\u62d2\u7edd\u77ed\u671f\u56de\u62a5\u8bf1\u60d1\uff0c\u9009\u62e9\u56de\u62a5\u5468\u671f\u957f\u3001\u98ce\u9669\u4f4e\u7684\u6295\u8d44\uff08\u5982\u6307\u6570\u57fa\u91d1\uff09</li> <li>\u4fdd\u6301\u8010\u5fc3\uff0c\u6295\u8d44\u9700\u89815\u5e74\u300110\u5e74\u751a\u81f3\u66f4\u957f\u65f6\u95f4\u624d\u80fd\u89c1\u5230\u590d\u5229\u6548\u5e94</li> </ul>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_5","title":"\u4e2d\u4ea7\u9677\u9631\u4e09\uff1a\u4eba\u751f\u89c4\u5212\u8d70\u5728\u201c\u5267\u672c\u201d\u91cc","text":"<p>\u64ad\u5ba2\u63d0\u51fa\u4e86\u4e00\u4e2a\u98a0\u8986\u6027\u7684\u89c2\u70b9\uff1a\u4e2d\u4ea7\u9636\u7ea7\u7684\u5178\u578b\u884c\u4e3a\uff0c\u6070\u6070\u662f\u8d22\u5bcc\u9636\u5c42\u56fa\u5316\u7684\u6839\u6e90\u3002</p> <p>\u201c\u4f60\u53ea\u8981\u4e0d\u53bb\u505a\u4e2d\u4ea7\u5178\u578b\u7684\u884c\u4e3a\uff0c\u4f60\u5c31\u5df2\u7ecf\u8d62\u4e8699%\u7684\u4eba\u4e86\u3002\u201d</p> <p>\u6bd4\u5982\uff0c\u6bd5\u4e1a\u540e\u4e70\u8f66\u4e70\u623f\u3001\u6500\u6bd4\u6d88\u8d39\uff0c\u8fd9\u4e9b\u770b\u4f3c\u201c\u6807\u51c6\u8def\u7ebf\u201d\u7684\u884c\u4e3a\uff0c\u5176\u5b9e\u8ba9\u4f60\u88ab\u56f0\u5728\u539f\u6709\u9636\u5c42\u3002\u8981\u60f3\u5b9e\u73b0\u9636\u5c42\u8dc3\u8fc1\uff0c\u9700\u8981\u201c\u53cd\u7740\u6e38\u620f\u53bb\u505a\u201d\uff1a</p> <ul> <li>\u4e0d\u76f2\u76ee\u6d88\u8d39\u3001\u4e0d\u505a\u65e0\u610f\u4e49\u7684\u793e\u4ea4</li> <li>\u628a\u94b1\u7528\u4e8e\u6295\u8d44\u800c\u975e\u6d88\u8d39</li> <li>\u8d2d\u4e70\u8d44\u4ea7\u800c\u975e\u8d1f\u503a\uff0c\u4f8b\u5982\u4e0e\u5176\u201c\u4e70\u4e00\u680b600\u4e07\u7684\u623f\u81ea\u4f4f\u201d\uff0c\u4e0d\u5982\u201c\u4e70\u56db\u680b150\u4e07\u7684\u6295\u8d44\u623f\u201d\u3002</li> <li>\u8ba9\u8d44\u4ea7\u80fd\u4e3a\u4f60\u4ea7\u751f\u73b0\u91d1\u6d41\uff0c\u800c\u4e0d\u662f\u8ba9\u6d88\u8d39\u54c1\u6210\u4e3a\u201c\u624b\u94d0\u201d</li> </ul>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_6","title":"\u8d22\u5bcc\u79ef\u7d2f\u7684\u672c\u8d28\uff1a\u8ba4\u77e5\u3001\u8010\u5fc3\u4e0e\u591a\u8bd5\u9519","text":"<p>\u201c\u94b1\u662f\u4e00\u4e2a\u5de5\u5177\uff0c\u53ef\u4ee5\u8de8\u8d8a\u65f6\u95f4\u548c\u7a7a\u95f4\u8f6c\u79fb\u4ef7\u503c\u3002\u201d \u8d22\u5bcc\u7684\u79ef\u7d2f\u5e76\u4e0d\u662f\u9760\u201c\u6253\u5de5\u201d\u6216\u201c\u7701\u5403\u4fed\u7528\u201d\u5b9e\u73b0\u7684\uff0c\u800c\u662f\u9760\u8ba4\u77e5\u7684\u63d0\u5347\u3001\u8010\u5fc3\u548c\u591a\u6b21\u8bd5\u9519\u3002</p> <p>\u201c\u5df4\u83f2\u727990%\u7684\u8d22\u5bcc\u90fd\u662f60\u5c81\u4e4b\u540e\u624d\u79ef\u7d2f\u7684\u3002\u201d</p> <ul> <li>\u8ba4\u6e05\u81ea\u5df1\u7684\u5c40\u9650\uff0c\u907f\u514d\u5f52\u56e0\u504f\u5dee\u548c\u201c\u82f1\u96c4\u4e3b\u4e49\u201d</li> <li>\u4e0d\u65ad\u63d0\u5347\u8ba4\u77e5\uff0c\u4e3b\u52a8\u5b66\u4e60\u91d1\u878d\u3001\u7ecf\u6d4e\u3001\u5fc3\u7406\u5b66\u7b49\u77e5\u8bc6</li> <li>\u591a\u8bd5\u9519\uff0c\u4fdd\u6301\u5f00\u653e\u5fc3\u6001\uff0c\u53ca\u65f6\u590d\u76d8\u548c\u8c03\u6574</li> </ul>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_7","title":"\u771f\u6b63\u7684\u8d22\u5bcc\u8dc3\u8fc1\uff1a\u7528\u8111\u5b50\u8d5a\u94b1\uff0c\u800c\u4e0d\u662f\u65f6\u95f4","text":"<p>\u201cEarn with your mind, not with your time.\u201d</p> <p>\u591a\u6570\u4eba\u4e00\u751f\u90fd\u5728\u201c\u7528\u65f6\u95f4\u6362\u94b1\u201d\uff0c\u5374\u96be\u4ee5\u5b9e\u73b0\u8d22\u52a1\u4e0a\u7684\u81ea\u7531\u3002\u800c\u771f\u6b63\u80fd\u7a81\u7834\u4e2d\u4ea7\u9636\u5c42\u7684\u5173\u952e\uff0c\u5728\u4e8e\u4ece\u201c\u6253\u5de5\u5fc3\u6001\u201d\u5411\u201c\u601d\u8003\u8005\u5fc3\u6001\u201d\u7684\u8f6c\u53d8\u3002</p> <p>\u601d\u8003\u8005\u5177\u5907\u7684\u7279\u8d28\u5305\u62ec\uff1a</p> <ul> <li>\u63d0\u9ad8\u8ba4\u77e5\uff0c\u8bc6\u522b\u8d8b\u52bf\uff1b</li> <li>\u5ba2\u89c2\u770b\u5f85\u5f52\u56e0\uff0c\u4e0d\u8ff7\u4fe1\u4e2a\u4eba\u52aa\u529b\uff1b</li> <li>\u6295\u8d44\u65f6\u95f4\u79ef\u7d2f\u590d\u5229\uff0c\u800c\u975e\u6025\u529f\u8fd1\u5229\u3002</li> </ul>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_8","title":"\u5bb6\u5ead\u6559\u80b2\uff1a\u8d22\u5bcc\u89c2\u4e0e\u8ba4\u77e5\u7684\u4f20\u627f","text":"<p>\u64ad\u5ba2\u6700\u540e\u89e6\u53ca\u5bb6\u5ead\u6559\u80b2\u7684\u91cd\u8981\u6027\u3002\u5b66\u6821\u6559\u80b2\u57f9\u517b\u201c\u793e\u4f1a\u673a\u5668\u7684\u9f7f\u8f6e\u201d\uff0c\u800c\u771f\u6b63\u51b3\u5b9a\u5b69\u5b50\u672a\u6765\u7684\u662f\u5bb6\u5ead\u6559\u80b2\u2014\u2014\u7236\u6bcd\u7684\u4ef7\u503c\u89c2\u548c\u8ba4\u77e5\u3002</p> <p>\u201c\u7236\u6bcd\u662f\u4ec0\u4e48\u6837\u7684\u4eba\uff0c\u91cd\u8981\u7684\u7a0b\u5ea6\u8fdc\u8fdc\u5927\u4e8e\u4f60\u4f5c\u4e3a\u4e00\u4e2a\u7236\u6bcd\u7a76\u7adf\u4e3a\u5b69\u5b50\u505a\u4e86\u54ea\u4e9b\u5177\u4f53\u7684\u4e8b\u3002\u201d</p> <ul> <li>\u57f9\u517b\u5b69\u5b50\u7684\u6027\u683c\u548c\u8ba4\u77e5\u80fd\u529b</li> <li>\u8ba9\u5b69\u5b50\u61c2\u5f97\u5e78\u798f\u3001\u91d1\u94b1\u548c\u81ea\u7531\u7684\u672c\u8d28</li> <li>\u7236\u6bcd\u548c\u5b69\u5b50\u5171\u540c\u6210\u957f\u3001\u76f8\u4e92\u5f71\u54cd</li> </ul>"},{"location":"posts/podcasts/how_to_overcome_middle_class/#_9","title":"\u7ed3\u8bed\uff1a\u8d22\u5bcc\u81ea\u7531\u7684\u672c\u8d28","text":"<p>\u8d22\u5bcc\u81ea\u7531\uff0c\u4e0d\u662f\u62e5\u6709\u591a\u5c11\u91d1\u94b1\uff0c\u800c\u662f\u62e5\u6709\u9009\u62e9\u7684\u81ea\u7531\u548c\u6e05\u9192\u7684\u8ba4\u77e5\u3002\u8df3\u51fa\u6d88\u8d39\u548c\u6295\u8d44\u7684\u9677\u9631\uff0c\u63d0\u5347\u8ba4\u77e5\uff0c\u8010\u5fc3\u79ef\u7d2f\uff0c\u53cd\u4eba\u6027\u5730\u601d\u8003\u548c\u884c\u52a8\uff0c\u624d\u6709\u53ef\u80fd\u5b9e\u73b0\u9636\u5c42\u7a81\u7834\u3002</p> <p>\u6b63\u5982\u64ad\u5ba2\u6240\u8bf4\uff1a</p> <p>\u201c\u6211\u4eec\u6765\u5230\u5730\u7403\u4e0a\uff0c\u5e76\u4e0d\u662f\u4e3a\u4e86\u4e3a\u94b1\u5de5\u4f5c\u3002\u6700\u91cd\u8981\u7684\u662f\u7528\u94b1\u8fd9\u4e2a\u5de5\u5177\u53bb\u6295\u8d44\uff0c\u4e5f\u8981\u53bb\u4eab\u53d7\u4eba\u751f\u3002\u201d</p> <p>\u542c\u64ad\u5ba2\uff1a\u5982\u4f55\u8d85\u8d8a\u4e2d\u4ea7\u9636\u7ea7\uff1f\uff5cLeon\u8c08\u8d22\u5bcc_\u4e0b</p>"},{"location":"posts/podcasts/how_to_speak/","title":"The Art of Speaking: Essential Lessons from Patrick Winston\u2019s Guide to Effective Communication","text":"<p>Good communication is not just a nice-to-have skill\u2014it\u2019s the key to unlocking opportunity and recognition in your career and life. In a compelling class, the late MIT professor Patrick Winston, renowned for his teaching and research in artificial intelligence, shares his hard-earned wisdom on how to give talks that inform, persuade, and inspire. Drawing from decades of experience, Winston offers practical heuristics, memorable stories, and actionable tips for anyone who wants their ideas to be heard and remembered.</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#introduction-communication-as-your-ultimate-weapon","title":"Introduction: Communication as Your Ultimate Weapon","text":"<p>Patrick Winston opens with a powerful analogy:</p> <p>\u201cThe Uniform Code of Military Justice specifies court martial for any officer who sends a soldier into battle without a weapon. There ought to be a similar protection for students because students shouldn't go out into life without the ability to communicate\u2026\u201d</p> <p>He argues that your success depends more on your ability to speak and write than even the quality of your ideas. Talent, he insists, is only a small part of the equation\u2014what matters most is knowledge and practice.</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#rules-of-engagement-the-importance-of-focus","title":"Rules of Engagement: The Importance of Focus","text":"<p>Before diving in, Winston insists on a simple rule: no laptops, no cell phones. Why? Because humans have only one language processor, and distractions\u2014both for you and those around you\u2014diminish the effectiveness of communication. </p> <p>\u201cIf your language processor is engaged browsing the web or reading your email, you're distracted. And worse yet, you distract all of the people around you.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#how-to-start-the-empowerment-promise","title":"How to Start: The Empowerment Promise","text":"<p>Forget about opening with a joke\u2014at least at the start. Winston recommends beginning your talk with an \u201cempowerment promise,\u201d a clear statement of what your audience will gain by listening.</p> <p>\u201cYou want to tell people what they're going to know at the end of the hour that they didn't know at the beginning... It's the reason for being here.\u201d</p> <p>This sets expectations and immediately gives your audience a reason to pay attention.</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#four-sample-heuristics-for-effective-speaking","title":"Four Sample Heuristics for Effective Speaking","text":"<p>Winston shares four simple but powerful heuristics that form the backbone of a strong presentation:</p> <ol> <li>Cycle on the Subject: Repeat key points in different ways. People fog out\u2014repetition ensures the message gets through.</li> <li>Build a Fence Around Your Idea: Distinguish your idea from others. Use comparisons and contrasts so your audience knows exactly what you mean.</li> <li>Verbal Punctuation: Use outlines, numbers, and transitions to help listeners \u201cget back on the bus\u201d if they lose track.</li> <li>Ask Questions: Engage your audience directly. Well-chosen questions draw people in and encourage participation.</li> </ol>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#the-tools-of-the-trade-time-place-boards-props-and-slides","title":"The Tools of the Trade: Time, Place, Boards, Props, and Slides","text":"","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#time-and-place","title":"Time and Place","text":"<p>Choose a time when your audience is alert (late morning is best) and a well-lit, appropriately sized room. \u201cCasing the joint\u201d\u2014checking out the venue in advance\u2014helps avoid surprises.</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#boards-and-props","title":"Boards and Props","text":"<p>Winston is a strong advocate for using blackboards and props:</p> <ul> <li>Boards allow for graphic explanations and keep your pace aligned with your audience\u2019s ability to absorb information.</li> <li>Props make abstract concepts tangible and memorable. For example, using a spinning bicycle wheel to illustrate physics principles or a steel ball pendulum to demonstrate conservation of energy.</li> </ul> <p>He attributes the power of props to \u201cempathetic mirroring\u201d\u2014when we watch someone interact with a physical object, our brains simulate the action, deepening understanding.</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#slides-less-is-more","title":"Slides: Less is More","text":"<p>Slides should be used for exposing ideas, not teaching them. The most common crimes:</p> <ul> <li>Too many slides</li> <li>Too many words per slide</li> <li>Fonts that are too small</li> <li>Reading slides aloud</li> </ul> <p>\u201cPeople in your audience know how to read, and reading will just annoy them.\u201d</p> <p>Winston\u2019s rules for slides:</p> <ul> <li>Minimize text</li> <li>Use large fonts (minimum 35-40pt)</li> <li>Eliminate clutter (backgrounds, logos, unnecessary bullets)</li> <li>Use images and air (white space)</li> <li>Never use a laser pointer\u2014use built-in arrows or callouts instead</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#informing-promise-inspiration-and-teaching-people-how-to-think","title":"Informing: Promise, Inspiration, and Teaching People How to Think","text":"<p>When informing, start with a promise and inject inspiration by showing passion for your subject. Winston found that people are inspired by:</p> <ul> <li>Teachers who believe in them</li> <li>Seeing problems in a new way</li> <li>Witnessing genuine enthusiasm</li> </ul> <p>He emphasizes the importance of storytelling:</p> <p>\u201cWe are storytelling animals\u2026 If we want to teach people how to think, you provide them with the stories they need to know, the questions they need to ask about those stories, mechanisms for analyzing those stories, ways of putting stories together, ways of evaluating how reliable a story is.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#persuading-oral-exams-job-talks-and-getting-famous","title":"Persuading: Oral Exams, Job Talks, and Getting Famous","text":"","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#oral-exams","title":"Oral Exams","text":"<p>Success hinges on situating your research in context and practicing with people who don\u2019t already know your work.</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#job-talks","title":"Job Talks","text":"<p>Within the first five minutes, you must establish your vision and demonstrate that you\u2019ve accomplished something.</p> <p>\u201cIf you haven't expressed your vision, if you haven't told people that you've done something in five minutes, you've already lost.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#getting-famous","title":"Getting Famous","text":"<p>Why care about fame? Because your ideas are like your children\u2014you don\u2019t want them to go into the world in rags. Winston introduces \u201cWinston\u2019s Star,\u201d a five-point checklist for memorable work:</p> <ul> <li>Symbol: A visual or conceptual anchor (e.g., an arch)</li> <li>Slogan: A catchy phrase (e.g., \u201cone shot learning\u201d)</li> <li>Surprise: An unexpected insight</li> <li>Salient Idea: The standout concept</li> <li>Story: The narrative behind your work</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#how-to-stop-the-final-slide-and-final-words","title":"How to Stop: The Final Slide and Final Words","text":"<p>Endings matter. Winston\u2019s advice:</p> <ul> <li>Don\u2019t finish with a long list of collaborators (put that at the start).</li> <li>Don\u2019t end with \u201cThank you\u201d or \u201cQuestions?\u201d\u2014these are wasted opportunities.</li> <li>The final slide should highlight your contributions.</li> <li>Final words should either be a well-timed joke, a salute to the audience, or a meaningful closing, not a perfunctory \u201cthank you.\u201d</li> </ul> <p>\u201cWhen you say thank you, even worse, thank you for listening, it suggests that everybody has stayed that long out of politeness and that they had a profound desire to be somewhere else.\u201d</p>","tags":["Growth"]},{"location":"posts/podcasts/how_to_speak/#conclusion-packaging-your-ideas-for-the-world","title":"Conclusion: Packaging Your Ideas for the World","text":"<p>Winston\u2019s talk is a masterclass in not just what to say, but how to say it. His core message is clear: the way you present your ideas determines whether they are heard, valued, and remembered. By following his practical heuristics\u2014starting with a promise, repeating key points, using props, simplifying slides, telling stories, and ending with impact\u2014you can ensure your ideas don\u2019t just survive, but thrive.</p> <p>\u201cBy being here, I think you have demonstrated an understanding that how you present and how you package your ideas is an important thing. And I salute you for that.\u201d</p> <p>Whether you\u2019re a student, a teacher, a scientist, or a business leader, Winston\u2019s advice is timeless: master the art of speaking, and you\u2019ll give your ideas their best shot at changing the world.</p> <p>Source: How to speak</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/","title":"Mastering the Art of Teaching, Writing, and Managing Up: Lessons from Wes Kao","text":"<p>What do Seth Godin, Scott Galloway, and the future of online education have in common? Wes Kao. In a recent episode of Lenny\u2019s Podcast, Wes Kao\u2014co-founder of Maven and an expert in cohort-based courses\u2014shared her journey, frameworks for better writing and teaching, and actionable advice for managing up and communicating effectively at work. Whether you\u2019re a course creator, a manager, or simply someone looking to level up your writing and communication, this episode is packed with insights you won\u2019t want to miss.</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#introduction-who-is-wes-kao","title":"Introduction: Who is Wes Kao?","text":"<p>Wes Kao is a powerhouse in the world of online education. After starting her career in corporate retail at Gap, she worked with industry giants like Seth Godin (co-founding the legendary altMBA), consulted for top creators, and eventually launched Maven\u2014a platform that makes it easier for experts to run cohort-based courses. Her unorthodox career path and obsession with craft have made her a sought-after authority on teaching, writing, and organizational effectiveness.</p> <p>\u201cI care a lot about craft, and I think more people should care about craft.\u201d \u2014 Wes Kao</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#from-corporate-retail-to-seth-godins-right-hand","title":"From Corporate Retail to Seth Godin\u2019s Right Hand","text":"<p>Wes\u2019s journey is a testament to the power of saying yes to unexpected opportunities. She described how a serendipitous application to Seth Godin\u2019s call for a \u201cspecial projects lead\u201d led her to co-create the altMBA, impacting thousands of students worldwide.</p> <p>Key Takeaway: Don\u2019t self-reject. Put your foot forward, even if you don\u2019t feel perfectly prepared.</p> <p>\u201cDon\u2019t take yourself out of the running before you get rejected. Don\u2019t reject yourself.\u201d \u2014 Wes Kao</p> <p>Working with Seth Godin, Wes learned the importance of high standards, speed, and rigor\u2014producing \u201chigh quality, fast, and economical\u201d work. She noted that Seth is even sharper and more genuine in person than he appears online.</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#the-super-specific-how-a-framework-for-better-writing","title":"The Super-Specific How: A Framework for Better Writing","text":"<p>One of Wes\u2019s most impactful concepts is the \u201csuper-specific how.\u201d Most writers and teachers focus too much on the what and why, but the real value is in the how.</p> <ul> <li>Cut the backstory: Get straight to the actionable advice.</li> <li>Be specific: Instead of generalities, offer concrete steps and examples.</li> <li>Start right before you get eaten by the bear: Begin your story or lesson at the most interesting, relevant moment.</li> </ul> <p>\u201cMost people need less context setting and preamble than you might think.\u201d \u2014 Wes Kao</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#the-content-hierarchy-where-bs-can-hide","title":"The Content Hierarchy: Where BS Can Hide","text":"<p>Wes introduced a \u201ccontent hierarchy\u201d pyramid: - Bottom: Twitter, podcasts, keynotes\u2014more room for unchallenged statements (\u201cBS\u201d). - Top: Cohort-based courses\u2014students can ask questions in real-time, so there\u2019s little room for fluff or inaccuracies.</p> <p>\u201cIn a cohort-based course... you have to be able to defend what you\u2019re saying and make sure that what you\u2019re saying is rigorous.\u201d \u2014 Wes Kao</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#the-state-change-method-keeping-audiences-engaged","title":"The State Change Method: Keeping Audiences Engaged","text":"<p>Whether you\u2019re teaching a course or running a Zoom meeting, Wes advocates for frequent \u201cstate changes\u201d\u2014deliberate shifts in activity or engagement to keep attention high.</p> <p>Examples of state changes: - Ask participants to respond in the chat. - Switch between gallery view and screen sharing. - Use polls or breakout rooms. - Invite others to speak or share.</p> <p>\u201cPunctuate your monologues with state changes. Anything that shakes your audience awake and adds some variety.\u201d \u2014 Wes Kao</p> <p>She also highlighted the importance of noticing \u201ceyes light up\u201d moments\u2014those times when your audience is visibly more engaged. Use these cues to refine your content and focus on what resonates.</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#managing-up-why-and-how","title":"Managing Up: Why and How","text":"<p>Managing up isn\u2019t just for junior employees; it\u2019s a key skill at every level.</p> <ul> <li>Why it matters: Proactively managing your relationship with your boss builds trust, opens up opportunities, and helps avoid surprises.</li> <li>How to do it: Keep your manager in the loop with regular, structured updates (e.g., a weekly \u201cState of Lenny\u201d email outlining priorities, blockers, and what\u2019s on your mind).</li> <li>Overcommunicate: Err on the side of too much communication\u2014especially in remote work.</li> </ul> <p>\u201cThe most senior people are best at managing up. This is why they got promoted in the first place.\u201d \u2014 Wes Kao</p> <p>Pro Tip: Use frameworks like \u201cbottom line up front\u201d (BLUF) and provide context for those who want to dig deeper.</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#writing-well-beyond-social-media-mimicry","title":"Writing Well: Beyond Social Media Mimicry","text":"<p>Wes encourages writers to go beyond copying popular formats on Twitter or LinkedIn and to study the actual craft of writing.</p> <ul> <li>Be precise: Avoid accidental bias or confusion in your writing.</li> <li>Structure matters: Start with your recommendation or main point, then provide supporting context.</li> <li>Build trust: If you present pros and cons, be transparent about your recommendation.</li> </ul> <p>\u201cMore people should learn the craft of writing and the technical aspects of writing\u2014not just look at what other people are doing to try to get audience engagement.\u201d \u2014 Wes Kao</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#the-art-of-saying-no-without-saying-no","title":"The Art of Saying No (Without Saying \u201cNo\u201d)","text":"<p>For people pleasers, saying no can be tough. Wes suggests reframing the conversation around trade-offs:</p> <ul> <li>Instead of a flat \u201cno,\u201d explain what saying \u201cyes\u201d would mean deprioritizing.</li> <li>Invite the requester to help decide on priorities.</li> </ul> <p>\u201cBy talking about trade-offs, you really get the outcome, which is you protect your bandwidth...without actually even having to say the word no.\u201d \u2014 Wes Kao</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#lightning-round-recommendations-and-contrarian-opinions","title":"Lightning Round: Recommendations and Contrarian Opinions","text":"<ul> <li>Most recommended books: See list below.</li> <li>Favorite Maven courses: Amanda Natividad\u2019s \u201cContent Marketing 201\u201d and Marylee Nicasio\u2019s \u201cBreaking into Technical Product Management.\u201d</li> <li>Least favorite fruit: Grapes (unless frozen!).</li> </ul>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#conclusion-raising-the-bar-on-teaching-writing-and-work","title":"Conclusion: Raising the Bar on Teaching, Writing, and Work","text":"<p>Wes Kao\u2019s frameworks and insights are a masterclass in intentionality\u2014whether you\u2019re writing, teaching, or collaborating at work. The main takeaways:</p> <ul> <li>Focus on the super-specific how in your writing and teaching.</li> <li>Keep your audience engaged with frequent state changes.</li> <li>Manage up by proactively communicating and avoiding surprises.</li> <li>Study the craft of writing, not just the formats.</li> <li>Protect your bandwidth by discussing trade-offs, not just saying \u201cno.\u201d</li> </ul> <p>If you\u2019re interested in creating your own cohort-based course, check out Maven\u2019s free Course Accelerator. And remember: don\u2019t self-reject. Take the leap\u2014you might just end up changing your own trajectory.</p>","tags":["Growth"]},{"location":"posts/podcasts/managing_up/#books-recommended-in-the-podcast","title":"Books Recommended in the Podcast","text":"<ul> <li> <p>It Was the Best of Sentences, It Was the Worst of Sentences by June Casagrande Recommended for mastering the craft of writing clear, effective sentences.</p> </li> <li> <p>Better Business Writing by Harvard Business Press A practical guide for improving business communication and writing skills.</p> </li> </ul> <p>Inspired by Wes Kao\u2019s appearance on Lenny\u2019s Podcast. For more, follow Wes on Twitter or visit maven.com.</p> <p>Podcast: Persuasive communication and managing up | Wes Kao (Maven, altMBA, Section4) </p>","tags":["Growth"]},{"location":"posts/podcasts/the_power_of_introvert/","title":"Embracing Your Introverted Strengths: Lessons from Susan Cain on Thriving in a Loud World","text":"<p>Introverts often feel out of place in a culture that celebrates extroversion\u2014loud voices, big personalities, and constant networking. But what if your quiet nature is actually your superpower? In a recent episode of Lenny\u2019s Podcast, Susan Cain, author of the bestselling book Quiet: The Power of Introverts in a World That Can\u2019t Stop Talking, shares her insights on understanding introversion, leveraging your unique strengths, and thriving both personally and professionally.</p> <p>Below, we dive into the key takeaways from this rich conversation, including practical advice for introverts, strategies for success in the workplace, and tips for raising introverted children.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#understanding-introversion-its-a-spectrum-not-a-binary","title":"Understanding Introversion: It\u2019s a Spectrum, Not a Binary","text":"<p>Susan Cain begins by reframing introversion and extroversion as two different kinds of strengths, rather than a binary choice:</p> <p>\"The problem in our culture is just that we emphasize one type of strength, the extroverted strength, usually more than we do the introverted strength, but they're equally valuable.\"</p> <p>She explains that most people fall somewhere along a spectrum between introversion and extroversion, and that many of the skills associated with extroversion\u2014like public speaking or networking\u2014can be learned by introverts without changing who they are at their core.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#are-you-an-introvert","title":"Are You an Introvert?","text":"<p>Cain offers two helpful questions to determine where you fall on the spectrum:</p> <ol> <li>How do you feel after a social event, even one you enjoy? If you feel drained and need time alone to recharge, you\u2019re likely more introverted.</li> <li>How would you ideally spend a free weekend? If your vision involves a small group of close friends or solo activities, that\u2019s a sign of introversion.</li> </ol> <p>She also introduces the concept of the \"ambivert,\" someone who falls in the middle of the spectrum, combining traits of both introverts and extroverts.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#acquiring-skills-vs-changing-who-you-are","title":"Acquiring Skills vs. Changing Who You Are","text":"<p>A common misconception is that introverts become extroverts by acquiring social skills. Cain clarifies:</p> <p>\"That's not really describing becoming more extroverted, that's more describing acquiring skills. As we grow and gain experience, we acquire all kinds of skills.\"</p> <p>For example, both Cain and the host, Lenny, used to fear public speaking but learned to manage that fear over time. The key is not to force yourself to become someone else, but to build the skills you need to succeed while staying true to your natural temperament.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#embracing-your-authentic-self","title":"Embracing Your Authentic Self","text":"<p>One of the most powerful insights from the conversation is the paradox that embracing your introverted self leads to greater success:</p> <p>\"The more introverts become deeply comfortable in their own skin, that's when they start to show up at the job interview or on the stage in a more powerful way, because you're now there as your own true being.\"</p> <p>Cain emphasizes the importance of finding role models in your field who are successful introverts. Whether it\u2019s Malcolm Gladwell in public speaking or Warren Buffet in finance, seeing others succeed as themselves can be deeply validating.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#practical-strategies-for-introverts-to-thrive","title":"Practical Strategies for Introverts to Thrive","text":""},{"location":"posts/podcasts/the_power_of_introvert/#1-show-your-value","title":"1. Show Your Value","text":"<p>Introverts often struggle with self-promotion, which can lead to their contributions being overlooked. Cain suggests:</p> <ul> <li>Start a company blog or share your expertise in writing.</li> <li>Volunteer for small public speaking opportunities, like introducing a guest speaker.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert/#2-leverage-one-on-one-connections","title":"2. Leverage One-on-One Connections","text":"<p>Instead of trying to \"work the room,\" focus on building deep, one-on-one relationships. Over time, these authentic connections can be even more powerful than broad networking.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#3-communicate-your-ambition","title":"3. Communicate Your Ambition","text":"<p>Don\u2019t let your quiet demeanor be mistaken for lack of ambition. Seek out mentors, share your goals, and ask for advice on how to achieve them.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#4-lean-into-your-strengths","title":"4. Lean Into Your Strengths","text":"<p>Identify your unique talents\u2014whether it\u2019s deep research, thoughtful writing, or attentive listening\u2014and use them as your professional foundation.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#5-practice-saying-no","title":"5. Practice Saying No","text":"<p>Protect your energy by being selective about commitments. Before agreeing to something, ask yourself, \"Would I want to do this if it were tomorrow?\" If not, it\u2019s okay to decline.</p> <p>\"If I said yes to these kinds of things, I wouldn't be able to do the creative work that I did.\" \u2013 Quoting Mihaly Csikszentmihalyi</p>"},{"location":"posts/podcasts/the_power_of_introvert/#6-rethink-networking","title":"6. Rethink Networking","text":"<p>Instead of traditional networking, focus on doing valuable work that attracts people to you. Quality trumps quantity when it comes to building meaningful professional relationships.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#meetings-and-the-workplace-how-introverts-can-be-heard","title":"Meetings and the Workplace: How Introverts Can Be Heard","text":"<p>Large meetings can be daunting for introverts. Cain\u2019s advice:</p> <ul> <li>Prepare in advance: Think about key points or questions you want to raise.</li> <li>Speak early: Ideas introduced early often become anchors for the discussion.</li> <li>Speak from conviction: People respond to authenticity, not just volume.</li> <li>Advocate for deep work: Block out time for focused, uninterrupted work.</li> </ul> <p>For managers, she recommends:</p> <ul> <li>Ensure everyone has a chance to contribute.</li> <li>Give advance notice to introverts if you want them to speak.</li> <li>Use \"brain writing\" (written idea sharing) to level the playing field.</li> <li>Create quiet times or meeting-free days to support deep work.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert/#raising-introverted-children","title":"Raising Introverted Children","text":"<p>Cain shares thoughtful advice for parents:</p> <ul> <li>Recognize the difference between introversion and shyness: Introversion is about energy preferences; shyness is about fear of judgment.</li> <li>Honor the \"longer runway\": Introverted kids may need more time to warm up to new situations. Use gradual exposure and celebrate small steps.</li> <li>Build confidence through mastery: Encourage your child to pursue activities they love and excel in.</li> <li>Normalize their feelings: Talk openly about shyness or discomfort, and share your own experiences.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert/#finding-the-right-career-fit","title":"Finding the Right Career Fit","text":"<p>Ultimately, Cain encourages introverts (and extroverts) to seek out work environments and roles that align with their temperament:</p> <p>\"You basically want a life where you're waking up, looking forward to what you're doing. Yes, with obstacles along the way, but more or less you should feel like you're in the right zone.\"</p> <p>This may mean creating boundaries around meetings, choosing roles that play to your strengths, or even designing your own career path.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#notable-quotes","title":"Notable Quotes","text":"<p>\"In a gentle way, you can shake the world.\" \u2014 Gandhi (as quoted by Susan Cain)</p> <p>\"There's a crack in everything. That's where the light gets in.\" \u2014 Leonard Cohen (dedication for Bittersweet)</p>"},{"location":"posts/podcasts/the_power_of_introvert/#recommended-books","title":"Recommended Books","text":"<ul> <li> <p>Quiet: The Power of Introverts in a World That Can\u2019t Stop Talking by Susan Cain The foundational book on introversion, showing the power and value of quiet people.</p> </li> <li> <p>Flow: The Psychology of Optimal Experience by Mihaly Csikszentmihalyi Recommended for understanding the state of deep focus and how it leads to fulfillment.</p> </li> <li> <p>The Power of Myth by Joseph Campbell For insights into the hero\u2019s journey and finding meaning in life.</p> </li> <li> <p>Bittersweet: How Sorrow and Longing Make Us Whole by Susan Cain Explores the value of embracing bittersweet emotions.</p> </li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert/#conclusion","title":"Conclusion","text":"<p>Introversion is not a flaw to be fixed, but a unique strength to be embraced. As Susan Cain\u2019s work and wisdom show, success comes not from pretending to be someone else, but from leaning into who you truly are\u2014while building the skills you need to navigate the world.</p> <p>Whether you\u2019re an introvert seeking to thrive at work, a manager looking to support quieter team members, or a parent raising an introverted child, the key is authenticity, self-awareness, and the courage to shape your environment to fit your strengths.</p> <p>Ready to embrace your quiet power? Start by asking yourself: If you had a free weekend, how would you spend it? Your answer might just lead you to your next big success.</p>"},{"location":"posts/podcasts/the_power_of_introvert/#further-reading-resources","title":"Further Reading &amp; Resources","text":"<ul> <li>The hidden power of introverts: How to thrive without changing who you are | Susan Cain </li> <li>Susan Cain\u2019s Substack: thequietlife.net \u2014 A community for the quiet, thoughtful, and sensitive.</li> <li>Lenny\u2019s Podcast: lennyspodcast.com \u2014 More episodes on product, growth, and career.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/","title":"Embracing Your Introverted Strengths: Lessons from Susan Cain on Thriving as an Introvert","text":"<p>What if your quiet nature was actually your superpower? In a world that often celebrates extroversion, Susan Cain\u2014author of the bestselling book Quiet\u2014joins Lenny Rachitsky to discuss the unique strengths of introverts and how to harness them for success in life and work. This episode is packed with actionable advice, personal stories, and powerful reframes for anyone who identifies as an introvert or wants to support introverts around them.</p> <p>Listen to the full podcast here</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#introduction-redefining-success-for-introverts","title":"Introduction: Redefining Success for Introverts","text":"<p>For years, society has favored the loudest voices in the room. But what if being an introvert is not a weakness to overcome, but a different kind of strength to celebrate? Susan Cain, whose work has helped millions of introverts embrace their true selves, shares why authenticity\u2014not forced extroversion\u2014is the real key to success.</p> <p>\u201cThe more introverts become deeply comfortable in their own skin, that\u2019s when they start to show up at the job interview or on the stage in a more powerful way, because you\u2019re now there as your own true being.\u201d \u2014 Susan Cain</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#understanding-introversion-its-a-spectrum-not-a-box","title":"Understanding Introversion: It\u2019s a Spectrum, Not a Box","text":""},{"location":"posts/podcasts/the_power_of_introvert1/#what-makes-someone-an-introvert","title":"What Makes Someone an Introvert?","text":"<p>Cain clarifies that introversion isn\u2019t about shyness or social awkwardness, but about energy and preferences:</p> <ul> <li>Introverts feel drained after socializing, even if they enjoy it, and recharge by spending time alone or with close friends.</li> <li>Extroverts feel energized by social interaction and seek out more of it.</li> <li>Ambiverts fall somewhere in the middle.</li> </ul> <p>She offers two questions to help you identify your true preference:</p> <ol> <li>After a few hours at a party you\u2019re enjoying, do you feel energized or exhausted?</li> <li>On a free weekend, do you crave a quiet day with a close friend or a big social gathering?</li> </ol>"},{"location":"posts/podcasts/the_power_of_introvert1/#skills-vs-personality","title":"Skills vs. Personality","text":"<p>Many introverts develop skills that look extroverted\u2014like public speaking\u2014but this doesn\u2019t change their core temperament. Cain herself once dreaded public speaking, but overcame her fear through gradual exposure, not by becoming an extrovert.</p> <p>\u201cAs we grow and gain experience, we acquire all kinds of skills. But I still come back to that question: how would you spend your time when you have no obligations?\u201d \u2014 Susan Cain</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#embracing-your-introverted-self-the-path-to-authentic-success","title":"Embracing Your Introverted Self: The Path to Authentic Success","text":""},{"location":"posts/podcasts/the_power_of_introvert1/#the-power-of-leaning-into-your-strengths","title":"The Power of Leaning Into Your Strengths","text":"<p>Instead of trying to become someone you\u2019re not, Cain encourages introverts to:</p> <ul> <li>Find role models: Look for successful introverts in your field (e.g., Warren Buffet, Bill Gates, Malcolm Gladwell).</li> <li>Leverage your natural strengths: Deep focus, thoughtful analysis, and meaningful one-on-one connections are introvert superpowers.</li> </ul> <p>\u201cWe tend to have one or two or three passions in our lives, and one or two or three people in our lives who are very devoted to you, and we lavish everything in the direction of those passions and those people. And that is an incredible superpower.\u201d \u2014 Susan Cain</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#overcoming-public-speaking-and-social-anxiety","title":"Overcoming Public Speaking and Social Anxiety","text":"<p>Cain shares her journey with public speaking anxiety and the power of desensitization: taking small, manageable steps to face your fears. She recommends:</p> <ul> <li>Joining supportive groups like Toastmasters</li> <li>Practicing in low-stakes environments</li> <li>Gradually increasing your exposure</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/#thriving-as-an-introvert-at-work","title":"Thriving as an Introvert at Work","text":""},{"location":"posts/podcasts/the_power_of_introvert1/#strategies-for-career-success","title":"Strategies for Career Success","text":"<p>Cain offers practical tactics for introverts in the workplace:</p> <ul> <li>Show your value: Don\u2019t assume your contributions will be noticed. Share your expertise through writing, or by taking small public roles (like introducing speakers).</li> <li>Build deep connections: Focus on one-on-one relationships rather than large networking events.</li> <li>Seek mentors: Share your ambitions and ask for advice\u2014most people love to help.</li> <li>Lean into your strengths: Use your analytical, listening, and deep work abilities to stand out.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/#the-importance-of-saying-no","title":"The Importance of Saying No","text":"<p>Introverts need to guard their energy. Cain shares a favorite tip:</p> <p>\u201cWhen someone asks you to do something that is three or four months away, ask yourself how you\u2019d feel if you had to do that thing tomorrow. That\u2019s the real test.\u201d</p> <p>She and Lenny discuss creating personal policies to protect your time and focus, so you don\u2019t lose the space that makes you effective.</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#rethinking-networking","title":"Rethinking Networking","text":"<p>Instead of traditional networking, focus on creating valuable work\u2014people will come to you. At events, aim to make a few deep connections rather than meeting everyone.</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#effective-meetings-and-work-environments-for-introverts","title":"Effective Meetings and Work Environments for Introverts","text":""},{"location":"posts/podcasts/the_power_of_introvert1/#tips-for-introverts-in-meetings","title":"Tips for Introverts in Meetings","text":"<ul> <li>Prepare in advance: Write down points or questions before the meeting.</li> <li>Speak up early: Early contributions tend to be remembered and help you feel more engaged.</li> <li>Speak from conviction: Authenticity is often more powerful than volume.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/#for-managers-and-team-leaders","title":"For Managers and Team Leaders","text":"<ul> <li>Structure meetings to include everyone: Go around the room or invite quieter members to share.</li> <li>Give advance notice: Let introverts know ahead of time if you\u2019d like them to contribute.</li> <li>Encourage written input: Use \u201cbrain writing\u201d or post-its for idea generation.</li> <li>Allow deep work time: Block out meeting-free hours for focused work.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/#raising-introverted-children","title":"Raising Introverted Children","text":"<p>Cain distinguishes between introversion (preference for low-stimulation environments) and shyness (fear of social judgment). Her advice for parents:</p> <ul> <li>Respect the longer runway: Introverted or shy kids may take longer to warm up in new situations. Support gradual exposure.</li> <li>Foster mastery for confidence: Self-confidence grows from mastering skills, not from forced socializing.</li> <li>Normalize their experience: Share your own stories and help them see their temperament as normal and valuable.</li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/#finding-the-right-career-fit","title":"Finding the Right Career Fit","text":"<p>Cain stresses the importance of choosing work that aligns with your temperament:</p> <p>\u201cYou basically want a life where you\u2019re waking up, looking forward to what you\u2019re doing. Yes, with obstacles along the way, but more or less you should feel like you\u2019re in the right zone.\u201d</p> <p>She and Lenny discuss the value of designing your career around your strengths and preferences\u2014whether that means avoiding team management, limiting meetings, or focusing on solo creative work.</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#conclusion-in-a-gentle-way-you-can-shake-the-world","title":"Conclusion: In a Gentle Way, You Can Shake the World","text":"<p>The ultimate message: Introverts don\u2019t need to become extroverts to succeed. By embracing their authentic selves, building essential skills, and leaning into their unique strengths, introverts can achieve extraordinary things.</p> <p>\u201cIn a gentle way, you can shake the world.\u201d \u2014 Mahatma Gandhi (quoted by Susan Cain)</p>"},{"location":"posts/podcasts/the_power_of_introvert1/#recommended-books-from-the-podcast","title":"Recommended Books from the Podcast","text":"<ul> <li> <p>Quiet: The Power of Introverts in a World That Can't Stop Talking by Susan Cain Susan\u2019s bestselling book that sparked the global conversation about introversion.</p> </li> <li> <p>Flow: The Psychology of Optimal Experience by Mihaly Csikszentmihalyi Recommended by Susan Cain for understanding the state of deep engagement and creativity.</p> </li> <li> <p>The Power of Myth by Joseph Campbell Praised for insights on the hero\u2019s journey and finding meaning in life.</p> </li> <li> <p>Bittersweet: How Sorrow and Longing Make Us Whole by Susan Cain Susan\u2019s exploration of the value of bittersweet emotions.</p> </li> </ul>"},{"location":"posts/podcasts/the_power_of_introvert1/#listen-to-the-full-conversation","title":"Listen to the Full Conversation","text":"<p>Watch or listen to the full podcast here</p> <p>Are you an introvert who\u2019s found your own way to thrive? Share your story in the comments below!</p>"},{"location":"archive/2025/","title":"2025","text":""},{"location":"archive/2024/","title":"2024","text":""},{"location":"category/ai-engineering/","title":"AI Engineering","text":""},{"location":"category/llm/","title":"LLM","text":""},{"location":"category/prompt-engineering/","title":"Prompt Engineering","text":""},{"location":"category/growth/","title":"Growth","text":""},{"location":"category/ai-agents/","title":"AI Agents","text":""},{"location":"category/startup/","title":"Startup","text":""},{"location":"category/productivity/","title":"Productivity","text":""},{"location":"category/model-context-protocol/","title":"Model Context Protocol","text":""},{"location":"category/retrieval-augmented-generation/","title":"Retrieval-Augmented Generation","text":""},{"location":"page/2/","title":"Welcome to My Blog","text":""}]}