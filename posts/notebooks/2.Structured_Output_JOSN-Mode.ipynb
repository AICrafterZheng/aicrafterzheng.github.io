{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output \n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_completion, get_completion_with_structured_output, AZURE_OPENAI_API_GPT_35_MODEL, AZURE_OPENAI_API_GPT_4o_MODEL, extract_llm_response\n",
    "\n",
    "model = AZURE_OPENAI_API_GPT_4o_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "**LLM can format its output in a wide variety of ways**. You just need to ask for it to do so!\n",
    "\n",
    "One of these ways is by using XML tags to separate out the response from any other superfluous text. You've already learned that you can use XML tags to make your prompt clearer and more parseable to LLM. It turns out, you can also ask LLM to **use XML tags to make its output clearer and more easily understandable** to humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Having the output in XML tags allows the end user to reliably get the output by writing a short program to extract the content between XML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN:\n",
      "Please write a poetry about Cat. Put it in <poetry> tags.\n",
      "\n",
      "ASSISTANT TURN:\n",
      "<poetry>\n",
      "\n",
      "------------------------------------- LLM's response -------------------------------------\n",
      "==================LLM gpt-4o response======================\n",
      "<poetry>  \n",
      "Beneath the moon's soft silver glow,  \n",
      "A shadow dances, sleek and slow.  \n",
      "With eyes like amber, sharp and bright,  \n",
      "The cat becomes the queen of night.  \n",
      "\n",
      "Her velvet paws, so light, so fleet,  \n",
      "Whisper secrets to the street.  \n",
      "A hunter's grace, a mystic's air,  \n",
      "She moves as though she isn't there.  \n",
      "\n",
      "Her purr, a song of warmth and peace,  \n",
      "A melody that bids time cease.  \n",
      "Yet in her gaze, a wild spark,  \n",
      "A fragment of the untamed dark.  \n",
      "\n",
      "She leaps, she prowls, she claims her throne,  \n",
      "A creature both of flesh and stone.  \n",
      "A guardian of dreams and lore,  \n",
      "A spirit ancient, evermore.  \n",
      "\n",
      "Oh, feline muse, so fierce, so free,  \n",
      "A living riddle, mystery.  \n",
      "In your soft fur, the cosmos swirls,  \n",
      "A universe in whiskered curls.  \n",
      "</poetry>  \n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a poetry about {ANIMAL}. Put it in <poetry> tags.\"\n",
    "\n",
    "# Prefill for LLM's response\n",
    "PREFILL = \"<poetry>\"\n",
    "\n",
    "# Print LLM's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN:\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN:\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- LLM's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL, model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-4o-08-06 response======================\n",
      "\n",
      "------------------------------------- LLM's response -------------------------------------\n",
      "```python\n",
      "def miles_to_kilometers():\n",
      "    try:\n",
      "        # Ask the user for a number in miles\n",
      "        miles = float(input(\"Enter a distance in miles: \"))\n",
      "        \n",
      "        # Conversion factor from miles to kilometers\n",
      "        conversion_factor = 1.60934\n",
      "        \n",
      "        # Convert miles to kilometers\n",
      "        kilometers = miles * conversion_factor\n",
      "        \n",
      "        # Display the result\n",
      "        print(f\"{miles} miles is equal to {kilometers:.2f} kilometers.\")\n",
      "    except ValueError:\n",
      "        print(\"Please enter a valid number.\")\n",
      "\n",
      "# Call the function\n",
      "miles_to_kilometers()\n",
      "```\n",
      "\n",
      "This function prompts the user to enter a distance in miles, converts it to kilometers using the conversion factor (1 mile = 1.60934 kilometers), and then prints the result. It also includes error handling to ensure that the input is a valid number.\n",
      "\n",
      "------------------------------------- Extracted LLM's response -------------------------------------\n",
      "def miles_to_kilometers():\n",
      "    try:\n",
      "        # Ask the user for a number in miles\n",
      "        miles = float(input(\"Enter a distance in miles: \"))\n",
      "        \n",
      "        # Conversion factor from miles to kilometers\n",
      "        conversion_factor = 1.60934\n",
      "        \n",
      "        # Convert miles to kilometers\n",
      "        kilometers = miles * conversion_factor\n",
      "        \n",
      "        # Display the result\n",
      "        print(f\"{miles} miles is equal to {kilometers:.2f} kilometers.\")\n",
      "    except ValueError:\n",
      "        print(\"Please enter a valid number.\")\n",
      "\n",
      "# Call the function\n",
      "miles_to_kilometers()\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\" \n",
    "Write a simple python function that\n",
    " 1. Ask me for a number in mile\n",
    " 2. It converts miles to kilometers\n",
    "\"\"\"\n",
    "PREFILL = \"import\"\n",
    "\n",
    "res = get_completion(PROMPT, prefill=PREFILL, model=model)\n",
    "print(\"\\n------------------------------------- LLM's response -------------------------------------\")\n",
    "print(res)\n",
    "\n",
    "extracted_res = extract_llm_response(res, tag=\"python\")\n",
    "print(\"\\n------------------------------------- Extracted LLM's response -------------------------------------\")\n",
    "print(extracted_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM also excels at using other output formatting styles, notably `JSON`. If you want to enforce JSON output (not deterministically, but close to it), you can also prefill LLM's response with the opening bracket, `{`}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Few Shots to get a JSON output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LLMs or SLMs that do not support JSON-mode or function calling, you can use few shots to get a JSON output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-4o response======================\n",
      "{\n",
      "    \"ExceptionType\": \"Type 'ConfigCluster' of Role 'Cluster' raised an exception\",\n",
      "    \"Message\": \"Cluster Validation failed in following tests: Name                           Value                                                                                     ----                           -----                                                                                     Network                        {Validate Network Communication}                                                          . Review the StorageClusterValidation report C:\\\\Windows\\\\temp\\\\StorageClusterValidationReport-2024-12-30.08-27-57 available under C:\\\\Windows\\\\Cluster\\\\Reports on the server for details.\",\n",
      "    \"StackTrace\": \"at Trace-Error, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Common\\\\Tracer.psm1: line 63 at Test-StorageCluster, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Classes\\\\Storage\\\\StorageHelpers.psm1: line 446 at ConfigCluster, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Classes\\\\Cluster\\\\Cluster.psm1: line 181 at <ScriptBlock>, C:\\\\CloudDeployment\\\\ECEngine\\\\InvokeInterfaceInternal.psm1: line 139 at Invoke-EceInterfaceInternal, C:\\\\CloudDeployment\\\\ECEngine\\\\InvokeInterfaceInternal.psm1: line 134 at <ScriptBlock>, <No file>: line 33\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant specialized in parsing exception logs and extracting key information into a structured JSON format.\n",
    "\n",
    "Given the logs (wrapped in ###) below create a JSON object with keys \"\"ExceptionType\"\",  \"\"Message\"\" and \"\"StackTrace\"\".\n",
    "\n",
    "For the \"\"ExceptionType\"\" property,\n",
    "1. Only assign who raised the exception, e.g. (\"\"Type 'SetUpdateURI' of Role 'URP' raised an exception\"\"), not the stack trace and other details.\n",
    "2. You can find the exception type before the stack trace.\n",
    "4. The value of \"\"ExceptionType\"\" should be extracted directly from the logs and not be modified.\n",
    "\n",
    "For the \"\"Message\"\" property:\n",
    "1. Only include the exception error message without any stack trace. The stack trace should never be included in the \"\"Message\"\".\n",
    "2. If the content is too long please only keep the first 1000 characters.\n",
    "For the \"\"StackTrace\"\" property:\n",
    "1. Please assign the stack trace. \n",
    "2. If the content is too long please only keep the first 1000 characters.\n",
    "The resulting JSON object should be in this format: {{ \"\"ExceptionType\"\": \"\"string\"\", \"\"Message\"\": \"\"string\"\", \"\"StackTrace\"\": \"\"string\"\"}}.\n",
    "Every \"\"string\"\" value must be escaped of Special Characters. Use the following rules to do so:\n",
    "\n",
    "Example INPUT 1:\n",
    "System.IO.FileNotFoundException: Could not load file or assembly 'SomeAssembly' or one of its dependencies. The system cannot find the file specified. at MyApp.Services.AssemblyLoader.Load(String assemblyPath) in C:__w\\1\\s\\src\\MyApp\\Services\\AssemblyLoader.cs:line 45 at MyApp.Services.PluginManager.InitializePlugins() in C:__w\\1\\s\\src\\MyApp\\Services\\PluginManager.cs:line 88 at MyApp.Program.Main(String[] args) in C:__w\\1\\s\\src\\MyApp\\Program.cs:line 29\n",
    "\n",
    "Example OUTPUT 1:\n",
    "{{ \"ExceptionType\": \"Could not load file or assembly 'SomeAssembly' or one of its dependencies\", \"Message\": \"Could not load file or assembly 'SomeAssembly' or one of its dependencies. The system cannot find the file specified.\", \"StackTrace\": \"at MyApp.Services.AssemblyLoader.Load(String assemblyPath) in C:\\__w\\1\\s\\src\\MyApp\\Services\\AssemblyLoader.cs:line 45 \\n at MyApp.Services.PluginManager.InitializePlugins() in C:\\__w\\1\\s\\src\\MyApp\\Services\\PluginManager.cs:line 88 \\n at MyApp.Program.Main(String[] args) in C:\\__w\\1\\s\\src\\MyApp\\Program.cs:line 29\" }}\n",
    "\n",
    "Example INPUT 2:\n",
    "System.UnauthorizedAccessException: Access to the path 'C:\\RestrictedFolder\\data.txt' is denied. at System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) at System.IO.FileStream.Init(String path, FileMode mode, FileAccess access, Int32 rights, Boolean useRights, FileShare share, Int32 bufferSize, FileOptions options, SECURITY_ATTRIBUTES secAttrs, String msgPath) at MyApp.FileReader.ReadFile(String filePath) in C:__w\\1\\s\\src\\MyApp\\FileReader.cs:line 60 at MyApp.Program.Main(String[] args) in C:__w\\1\\s\\src\\MyApp\\Program.cs:line 25\n",
    "\n",
    "Example OUTPUT 2:\n",
    "{{ \"ExceptionType\": \"Access to the path 'C:\\RestrictedFolder\\data.txt' is denied.\", \"Message\": \"Access to the path 'C:\\RestrictedFolder\\data.txt' is denied.\", \"StackTrace\": \"at System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath) \\n at System.IO.FileStream.Init(String path, FileMode mode, FileAccess access, Int32 rights, Boolean useRights, FileShare share, Int32 bufferSize, FileOptions options, SECURITY_ATTRIBUTES secAttrs, String msgPath) \\n at MyApp.FileReader.ReadFile(String filePath) in C:\\__w\\1\\s\\src\\MyApp\\FileReader.cs:line 60 \\n at MyApp.Program.Main(String[] args) in C:\\__w\\1\\s\\src\\MyApp\\Program.cs:line 25\" }}\n",
    "\n",
    "The \"\"Message\"\" field must exclude the stack trace, and only contain the exception message itself.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "The given logs: ###\\n{rawException}\\n###\n",
    "\"\"\"\n",
    "prefill = \"The JSON OUTPUT:\"\n",
    "\n",
    "from utils import read_file\n",
    "exception = read_file(\"data/1.txt\")\n",
    "user_input = USER_PROMPT_TEMPLATE.format(rawException=exception)\n",
    "# user_input = extract_exception_type_and_details_prompt(exception)\n",
    "\n",
    "# print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "# print(\"USER TURN:\")\n",
    "# print(user_input)\n",
    "response = get_completion(user_input, system_prompt=SYSTEM_PROMPT, prefill=prefill, model=model)\n",
    "# # print(\"\\n------------------------------------- LLM's response -------------------------------------\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using JSON-Mode to get a JSON output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-4o response======================\n",
      "{\n",
      "    \"ExceptionType\": \"Type 'ConfigCluster' of Role 'Cluster' raised an exception\",\n",
      "    \"Message\": \"Cluster Validation failed in following tests: Name                           Value                                                                                     ----                           -----                                                                                     Network                        {Validate Network Communication} . Review the StorageClusterValidation report C:\\\\Windows\\\\temp\\\\StorageClusterValidationReport-2024-12-30.08-27-57 available under C:\\\\Windows\\\\Cluster\\\\Reports on the server for details.\",\n",
      "    \"StackTrace\": \"at Trace-Error, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Common\\\\Tracer.psm1: line 63 at Test-StorageCluster, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Classes\\\\Storage\\\\StorageHelpers.psm1: line 446 at ConfigCluster, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Classes\\\\Cluster\\\\Cluster.psm1: line 181 at <ScriptBlock>, C:\\\\CloudDeployment\\\\ECEngine\\\\InvokeInterfaceInternal.psm1: line 139 at Invoke-EceInterfaceInternal, C:\\\\CloudDeployment\\\\ECEngine\\\\InvokeInterfaceInternal.psm1: line 134 at <ScriptBlock>, <No file>: line 33\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from utils import read_file\n",
    "# Print LLM's response\n",
    "exception = read_file(\"data/1.txt\")\n",
    "user_input = USER_PROMPT_TEMPLATE.format(rawException=exception)\n",
    "response = get_completion(user_input, system_prompt=SYSTEM_PROMPT, prefill=prefill, json_mode=True, model=model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-4o response======================\n",
      "ExceptionType=\"Type 'ConfigStorage' of Role 'Storage' raised an exception\" Message='Failed to configure storage on cluster Enable Storage Spaces Direct failed with error: . Run cluster validation, including the Storage Spaces Direct tests, to verify the configuration. Review the EnableClusterS2D report available under C:\\\\Windows\\\\Cluster\\\\Reports on the server for details.' StackTrace='at Set-SCStorageSystem, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\JEAModules\\\\Microsoft.AzureStack.Fabric.Storage.3.2411.1.3\\\\Microsoft.AzureStack.Fabric.Storage.Deploy.psm1: line 466  at ConfigStorage, C:\\\\NugetStore\\\\Microsoft.AzureStack.Fabric.Storage.SCPSModule.3.2411.1.3\\\\content\\\\CloudDeployment\\\\Classes\\\\Storage\\\\Storage.psm1: line 197  at <ScriptBlock>, C:\\\\CloudDeployment\\\\ECEngine\\\\InvokeInterfaceInternal.psm1: line 139  at Invoke-EceInterfaceInternal, C:\\\\CloudDeployment\\\\ECEngine\\\\InvokeInterfaceInternal.psm1: line 134  at <ScriptBlock>, <No file>: line 33'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Exception(BaseModel):\n",
    "    ExceptionType: str\n",
    "    Message: str\n",
    "    StackTrace: str\n",
    "\n",
    "from utils import read_file\n",
    "# Print LLM's response\n",
    "exception = read_file(\"data/1.txt\")\n",
    "\n",
    "user_input = USER_PROMPT_TEMPLATE.format(rawException=exception)\n",
    "\n",
    "response = get_completion_with_structured_output(user_input, system_prompt=SYSTEM_PROMPT, output_format=Exception)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use Structured Outputs via function calling vs via response_format\n",
    "Structured Outputs is available in two forms in the OpenAI API:\n",
    "\n",
    "- When using function calling\n",
    "- When using a json_schema response format\n",
    "\n",
    "Function calling is useful when you are building an application that bridges the models and functionality of your application.\n",
    "\n",
    "For example, you can give the model access to functions that query a database in order to build an AI assistant that can help users with their orders, or functions that can interact with the UI.\n",
    "\n",
    "Conversely, Structured Outputs via response_format are more suitable when you want to indicate a structured schema for use when the model responds to the user, rather than when the model calls a tool.\n",
    "\n",
    "Put simply:\n",
    "\n",
    "If you are connecting the model to tools, functions, data, etc. in your system, then you should use function calling.\n",
    "\n",
    "If you want to structure the model's output when it responds to the user, then you should use a structured response_format.\n",
    "\n",
    "\n",
    "### Structured Outputs vs JSON mode\n",
    "Structured Outputs is the evolution of JSON mode. While both ensure valid JSON is produced, only **Structured Outputs ensure schema adherance**. \n",
    "\n",
    "**Always using Structured Outputs instead of JSON mode when possible.**\n",
    "\n",
    "However, Structured Outputs with response_format: {type: \"json_schema\", ...} is only supported with the gpt-4o-mini, gpt-4o-mini-2024-07-18, and gpt-4o-2024-08-06 model snapshots and later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "You've learned how to generate structured output, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
