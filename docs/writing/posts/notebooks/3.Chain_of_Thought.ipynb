{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of thought (Thinking Step by Step)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_completion, AZURE_OPENAI_API_GPT_35_MODEL, AZURE_OPENAI_API_GPT_4o_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "If someone woke you up and immediately started asking you several complicated questions that you had to respond to right away, how would you do? Probably not as good as if you were given time to **think through your answer first**. \n",
    "\n",
    "Guess what? LLM is the same way.\n",
    "\n",
    "**Giving LLM time to think step by step sometimes makes LLM more accurate**, particularly for complex tasks. \n",
    "Ask LLM to output its thinking process to force the thinking occurres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Letting LLM think can shift LLM's answer from incorrect to correct**. It's that simple in many cases where LLM makes mistakes!\n",
    "\n",
    "Let's go through an example where LLM's answer is incorrect to see how asking LLM to think can fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "One famous movie starring an actor born in 1956 is \"Die Hard,\" starring Bruce Willis.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
    "\n",
    "# Print LLM's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by asking LLM to think step by step, this time in `<brainstorm>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "<brainstorm>\n",
      "- Tom Hanks (born in 1956)\n",
      "- Liam Neeson (born in 1952)\n",
      "- Mel Gibson (born in 1956)\n",
      "- Kevin Spacey (born in 1959)\n",
      "- Tim Robbins (born in 1958)\n",
      "</brainstorm>\n",
      "\n",
      "The famous movie starring an actor born in 1956 is \"The Da Vinci Code\" starring Tom Hanks.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
    "\n",
    "# Print LLM's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve math and logic questions.\n",
    "The correct answer: \n",
    "```\n",
    "Summing up the counts of people detected in each segment:\n",
    "2 + 1 + 3 + 1 + 2 + 3 + 1 + 2 + 3 = 18\n",
    "\n",
    "Therefore, a total of 18 people were detected across all segments of the video.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "Across all segments of the video, a total of 21 people were detected by the AI.\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI assistant for a Retrieval-Augmented Generation (RAG) application. Your task is to answer user questions based on retrieved contents and chat history (if any). Follow these instructions carefully:\n",
    "                                 \n",
    "1. Analyze the information:\n",
    "   - Carefully read and understand the retrieved contents.\n",
    "   - Review the chat history to grasp the context of the conversation. If no chat history is provided, assume there is no previous conversation.\n",
    "   - Identify information from the retrieved contents that is relevant to the user's question.\n",
    "\n",
    "2. Formulate your answer:\n",
    "   - Provide a clear, concise, and accurate answer based primarily on the retrieved contents.\n",
    "   - Ensure your response is relevant to the user's question and consistent with the chat history.\n",
    "   - If there are multiple relevant pieces of information, synthesize them into a coherent response.\n",
    "   - Avoid introducing information that is not present in the retrieved contents or chat history.\n",
    "   - If the question cannot be answered based on the provided information, just say you DO NOT have an answer.\n",
    "\n",
    "Remember, your goal is to provide helpful, accurate information based solely on the retrieved contents and chat history (if any). Do not invent or assume information that isn't provided.\n",
    "\n",
    "\"\"\"\n",
    "# Prompt\n",
    "PROMPT = \"\"\"\n",
    "Below is the retrieved contents:\n",
    "<retrieved_contents>\n",
    "In the section of the video from time 12:45:00 until 12:45:10, AI detected 2 people with ids 123e4567-e89b-12d3-a456-426614174000 and 123e4567-e89b-12d3-a456-426614174001, 1 dog with id 123e4567-e89b-12d3-a456-426614174002, and 3 cars with ids 123e4567-e89b-12d3-a456-426614174003, 123e4567-e89b-12d3-a456-426614174004, and 123e4567-e89b-12d3-a456-426614174005.\n",
    "In the section of the video from time 12:45:10 until 12:45:20, AI detected 1 person with id 123e4567-e89b-12d3-a456-426614174006, 2 cats with ids 123e4567-e89b-12d3-a456-426614174007 and 123e4567-e89b-12d3-a456-426614174008, and 1 suitcase with id 123e4567-e89b-12d3-a456-426614174009.\n",
    "In the section of the video from time 12:45:20 until 12:45:30, AI detected 3 people with ids 123e4567-e89b-12d3-a456-426614174010, 123e4567-e89b-12d3-a456-426614174011, and 123e4567-e89b-12d3-a456-426614174012, 1 car with id 123e4567-e89b-12d3-a456-426614174013, and 2 umbrellas with ids 123e4567-e89b-12d3-a456-426614174014 and 123e4567-e89b-12d3-a456-426614174015.\n",
    "In the section of the video from time 12:45:30 until 12:45:40, AI detected 1 person with id 123e4567-e89b-12d3-a456-426614174016, 1 dog with id 123e4567-e89b-12d3-a456-426614174017, and 2 cars with ids 123e4567-e89b-12d3-a456-426614174018 and 123e4567-e89b-12d3-a456-426614174019.\n",
    "In the section of the video from time 12:45:40 until 12:45:50, AI detected 2 people with ids 123e4567-e89b-12d3-a456-426614174020 and 123e4567-e89b-12d3-a456-426614174021, 1 cat with id 123e4567-e89b-12d3-a456-426614174022, and 1 suitcase with id 123e4567-e89b-12d3-a456-426614174023.\n",
    "In the section of the video from time 12:45:50 until 12:46:00, AI detected 3 people with ids 123e4567-e89b-12d3-a456-426614174024, 123e4567-e89b-12d3-a456-426614174025, and 123e4567-e89b-12d3-a456-426614174026, 2 cars with ids 123e4567-e89b-12d3-a456-426614174027 and 123e4567-e89b-12d3-a456-426614174028, and 1 umbrella with id 123e4567-e89b-12d3-a456-426614174029.\n",
    "In the section of the video from time 12:46:00 until 12:46:10, AI detected 1 person with id 123e4567-e89b-12d3-a456-426614174030, 2 dogs with ids 123e4567-e89b-12d3-a456-426614174031 and 123e4567-e89b-12d3-a456-426614174032, and 1 car with id 123e4567-e89b-12d3-a456-426614174033.\n",
    "In the section of the video from time 12:46:10 until 12:46:20, AI detected 2 people with ids 123e4567-e89b-12d3-a456-426614174034 and 123e4567-e89b-12d3-a456-426614174035, 1 cat with id 123e4567-e89b-12d3-a456-426614174036, and 2 suitcases with ids 123e4567-e89b-12d3-a456-426614174037 and 123e4567-e89b-12d3-a456-426614174038.\n",
    "In the section of the video from time 12:46:20 until 12:46:30, AI detected 3 people with ids 123e4567-e89b-12d3-a456-426614174039, 123e4567-e89b-12d3-a456-426614174040, and 123e4567-e89b-12d3-a456-426614174041, 1 car with id 123e4567-e89b-12d3-a456-426614174042, and 1 umbrella with id 123e4567-e89b-12d3-a456-426614174043.\n",
    "</retrieved_contents>\n",
    "Question: \n",
    "{question}\n",
    "\n",
    "Your answer:\n",
    "\"\"\"\n",
    "\n",
    "question = \"How many people were detected across all segments of the video?\"\n",
    "prompt = PROMPT.format(question=question)\n",
    "print(get_completion(prompt, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "1. In the first segment (12:45:00 - 12:45:10), 2 people were detected.\n",
      "2. In the second segment (12:45:10 - 12:45:20), 1 person was detected.\n",
      "3. In the third segment (12:45:20 - 12:45:30), 3 people were detected.\n",
      "4. In the fourth segment (12:45:30 - 12:45:40), 1 person was detected.\n",
      "5. In the fifth segment (12:45:40 - 12:45:50), 2 people were detected.\n",
      "6. In the sixth segment (12:45:50 - 12:46:00), 3 people were detected.\n",
      "7. In the seventh segment (12:46:00 - 12:46:10), 1 person was detected.\n",
      "8. In the eighth segment (12:46:10 - 12:46:20), 2 people were detected.\n",
      "9. In the ninth segment (12:46:20 - 12:46:30), 3 people were detected.\n",
      "\n",
      "Summing up the counts of people detected in each segment:\n",
      "2 + 1 + 3 + 1 + 2 + 3 + 1 + 2 + 3 = 18\n",
      "\n",
      "Therefore, a total of 18 people were detected across all segments of the video.\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = SYSTEM_PROMPT + \"\"\" \\nPlease think step by step. \n",
    "1. find the number of people in each segment\n",
    "2. sum up the counts of people detected in each segment\n",
    "3. please output your thinking process\"\"\"\n",
    "\n",
    "question = \"How many people were detected across all segments of the video?\"\n",
    "prompt = PROMPT.format(question=question)\n",
    "print(get_completion(prompt, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap output with tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "<think>\n",
      "1. Identify the number of people detected in each segment:\n",
      "   - Segment 1 (12:45:00 - 12:45:10): 2 people\n",
      "   - Segment 2 (12:45:10 - 12:45:20): 1 person\n",
      "   - Segment 3 (12:45:20 - 12:45:30): 3 people\n",
      "   - Segment 4 (12:45:30 - 12:45:40): 1 person\n",
      "   - Segment 5 (12:45:40 - 12:45:50): 2 people\n",
      "   - Segment 6 (12:45:50 - 12:46:00): 3 people\n",
      "   - Segment 7 (12:46:00 - 12:46:10): 1 person\n",
      "   - Segment 8 (12:46:10 - 12:46:20): 2 people\n",
      "   - Segment 9 (12:46:20 - 12:46:30): 3 people\n",
      "\n",
      "2. Sum up the counts of people detected in each segment:\n",
      "   - Total people detected = 2 + 1 + 3 + 1 + 2 + 3 + 1 + 2 + 3 = 18\n",
      "\n",
      "</think>\n",
      "<answer>There were a total of 18 people detected across all segments of the video.</answer>\n",
      "Extracted answer:\n",
      "There were a total of 18 people detected across all segments of the video.\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = SYSTEM_PROMPT + \"\"\" \\n\n",
    "Please think step by step. \n",
    "1. find the number of people in each segment\n",
    "2. sum up the counts of people detected in each segment\n",
    "3. please output your thinking process \n",
    "\n",
    "Please put your thinking process in <think> tags, and your answer in <answer> tags.\n",
    "\"\"\"\n",
    "\n",
    "question = \"How many people were detected across all segments of the video?\"\n",
    "prompt = PROMPT.format(question=question)\n",
    "response = get_completion(prompt, SYSTEM_PROMPT)\n",
    "print(response)\n",
    "from utils import extract_llm_response\n",
    "print(\"Extracted answer:\")\n",
    "print(extract_llm_response(response, \"answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "You've learned how to use CoT prompting, you're ready to move on to the next chapter. Happy prompting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
