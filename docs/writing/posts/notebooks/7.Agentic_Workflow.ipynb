{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic workflow\n",
    "\n",
    "Fron Andrew Ng\n",
    "> Today, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task! \n",
    "\n",
    "With an agent workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:\n",
    "\n",
    "- Plan an outline.\n",
    "- Decide what, if any, web searches are needed to gather more information.\n",
    "- Write a first draft.\n",
    "- Read over the first draft to spot unjustified arguments or extraneous information.\n",
    "- Revise the draft taking into account any weaknesses spotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_completion, read_file,AZURE_OPENAI_API_GPT_35_MODEL\n",
    "\n",
    "model = AZURE_OPENAI_API_GPT_35_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_and_example = \"\"\"\n",
    "<constraints_and_example>\n",
    "    Constraints:\n",
    "    1. Please give headline and list down the 3 key points as bullet points. I'm particularly interested in key points and any significant technological advancements or implications discussed.\n",
    "    2. If there are any fund raising details, please include the amount, the investors and valuation. If no fund raising info, just don't mention it.\"\n",
    "    3. Please DON't include the words \"Headline\" and \"Key points\" in the output.\n",
    "    4. Don't include any duplicate info.\n",
    "    \n",
    "    Example output:\n",
    "    Apple Introduces Private Cloud Compute for Enhanced AI Privacy.\n",
    "    • Apple has unveiled Private Cloud Compute (PCC), a cloud intelligence system designed to enhance the privacy of AI processing in the cloud. The system ensures user data sent to PCC isn't accessible to anyone, not even Apple, extending the security and privacy of Apple devices into the cloud.\n",
    "    • The PCC system is built with custom Apple silicon and a secure operating system. It is designed to fulfill user requests using complex machine learning models while maintaining privacy. The system maintains user data on PCC nodes only until the response is returned and does not retain any data afterward.\n",
    "    • To ensure the integrity of the system, Apple is making software images of every production build of PCC publicly available for scrutiny by the security research community. The company will also release a PCC Virtual Research Environment and a subset of the security-critical PCC source code to aid research.\n",
    "</constraints_and_example>\n",
    "\"\"\"\n",
    "INITIAL_SUMMARIZE_SYSTEM_PROMPT = \"\"\"\n",
    "You are a tech journalist writing a summary of a tech article. You will be provided with a tech article and you need to summarize it with key points and any significant technological advancements.\n",
    "\"\"\"\n",
    "\n",
    "INITIAL_SUMMARIZE_USER_PROMPT = \"\"\"Your task is to carefully read a source text and the summary of the text.\n",
    "{constraints_and_example}\n",
    "<SOURCE_TEXT>\n",
    "{text}\n",
    "</SOURCE_TEXT>\n",
    "\n",
    "Your output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "LazyGraphRAG: Setting a New Standard for GraphRAG Quality and Cost\n",
      "• LazyGraphRAG introduces a new approach to graph-enabled RAG that requires no prior summarization of source data, offering scalability in cost and quality.\n",
      "• LazyGraphRAG blends the advantages of vector RAG and Graph RAG, showing strong performance across cost-quality spectrum.\n",
      "• LazyGraphRAG's answer quality is state-of-the-art, outperforming competing methods on both local and global queries with varying relevance test budgets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "article = read_file(\"data/article.txt\")\n",
    "user_input = INITIAL_SUMMARIZE_USER_PROMPT.format(constraints_and_example= constraints_and_example, text= article) \n",
    "# print(user_input)\n",
    "response = get_completion(user_input, INITIAL_SUMMARIZE_SYSTEM_PROMPT, model=model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "LazyGraphRAG: Setting a New Standard for GraphRAG Quality and Cost\n",
      "• LazyGraphRAG introduces a new approach to graph-enabled RAG that requires no prior summarization of source data, offering scalability in cost and quality.\n",
      "• LazyGraphRAG blends the advantages of vector RAG and Graph RAG, showing strong performance across cost-quality spectrum.\n",
      "• LazyGraphRAG's answer quality is state-of-the-art, outperforming competing methods on both local and global queries with varying relevance test budgets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_input = INITIAL_SUMMARIZE_USER_PROMPT.format(constraints_and_example= constraints_and_example, text= article)\n",
    "initial_response = get_completion(user_input, INITIAL_SUMMARIZE_SYSTEM_PROMPT, model=model)\n",
    "print(initial_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "<Reflection>\n",
      "1. The summary should mention that LazyGraphRAG is a new approach that combines the benefits of vector RAG and Graph RAG without the need for prior data summarization, emphasizing its scalability in terms of cost and quality.\n",
      "2. Include details about LazyGraphRAG's performance across the cost-quality spectrum, highlighting its superiority over competing methods in both local and global queries.\n",
      "3. Emphasize the state-of-the-art answer quality of LazyGraphRAG and its ability to outperform other methods with varying relevance test budgets.\n",
      "</Reflection>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reflection\n",
    "REFLECTION_SUMMARIZE_SYSTEM_PROMPT = \"\"\"You are a tech journalist writing a summary of a tech article. You will be provided with a source text and its summary, and your goal is to improve the summary.\"\"\"\n",
    "REFLECTION_SUMMARIZE_USER_PROMPT = \"\"\"Your task is to carefully read a source text and the summary of the text, and then improve the summary with accuracy and constraints. Then give constructive criticism and helpful suggestions for improving the summary.\n",
    "<SOURCE_TEXT>\n",
    "{text}\n",
    "</SOURCE_TEXT>\n",
    "\n",
    "The summary of the indicated part, delimited below by <SUMMARY> and </SUMMARY>, is as follows:\n",
    "<SUMMARY>\n",
    "{summary}\n",
    "</SUMMARY>\n",
    "\n",
    "When writing suggestions, pay attention to whether there are ways to improve the summary's:\\n\\\n",
    "(i) accuracy (by correcting errors of addition, missummary, omission, or unsummaried text),\\n\\\n",
    "(ii) fluency (by applying grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\\n\\\n",
    "(iii) terminology (by ensuring terminology use is consistent and reflects the source text domain;).\\n\\\n",
    "{constraints_and_example}\n",
    "Write a list of specific, helpful and constructive suggestions for improving the summary.\n",
    "Each suggestion should address one specific part of the summary.\n",
    "\n",
    "Please put your suggestions in <Reflection> tags.\n",
    "\"\"\"\n",
    "\n",
    "reflection_input = REFLECTION_SUMMARIZE_USER_PROMPT.format(constraints_and_example= constraints_and_example, text= article, summary= initial_response)\n",
    "\n",
    "reflection_response = get_completion(reflection_input, REFLECTION_SUMMARIZE_SYSTEM_PROMPT, model=model)\n",
    "print(reflection_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================LLM gpt-35-turbo response======================\n",
      "Final output:\n",
      "<final_summary>\n",
      "LazyGraphRAG: Revolutionizing GraphRAG Efficiency and Quality\n",
      "• LazyGraphRAG introduces a novel approach to graph-enabled RAG that eliminates the need for prior data summarization, showcasing scalability in both cost and quality.\n",
      "• The system combines the strengths of vector RAG and Graph RAG, demonstrating superior performance across the cost-quality spectrum compared to competing methods.\n",
      "• LazyGraphRAG achieves state-of-the-art answer quality, surpassing other methods in both local and global queries with varying relevance test budgets.\n",
      "</final_summary>\n"
     ]
    }
   ],
   "source": [
    "FINAL_SUMMARIZE_SYSTEM_PROMPT = INITIAL_SUMMARIZE_SYSTEM_PROMPT\n",
    "FINAL_SUMMARIZE_USER_PROMPT = \"\"\"\n",
    "Your task is to carefully read, then improve a summary, taking into\n",
    "account a set of expert suggestions and constructive criticisms. Below, the source text, initial summary, and expert suggestions are provided.\n",
    "\n",
    "The source text is below, delimited by XML tags <SOURCE_TEXT> and </SOURCE_TEXT>, and the part that has been summarized\n",
    "is delimited by <SUMMARIZE_THIS> and </SUMMARIZE_THIS> within the source text. You can use the rest of the source text\n",
    "as context, but need to provide a summary only of the part indicated by <SUMMARIZE_THIS> and </SUMMARIZE_THIS>.\n",
    "\n",
    "<SOURCE_TEXT>\n",
    "{text}\n",
    "</SOURCE_TEXT>\n",
    "\n",
    "The summary of the indicated part, delimited below by <SUMMARIZE_THIS> and </SUMMARIZE_THIS>, is as follows:\n",
    "<SUMMARIZE_THIS>\n",
    "{summary}\n",
    "</SUMMARIZE_THIS>\n",
    "\n",
    "The expert summarys of the indicated part, delimited below by <EXPERT_SUGGESTIONS> and </EXPERT_SUGGESTIONS>, is as follows:\n",
    "<EXPERT_SUGGESTIONS>\n",
    "{reflection}\n",
    "</EXPERT_SUGGESTIONS>\n",
    "\n",
    "Taking into account the expert suggestions rewrite the summary to improve it, paying attention\n",
    "to whether there are ways to improve the summary's\n",
    "(i) accuracy (by correcting errors of addition, missummary, omission, or unsummaried text),\\n\\\n",
    "(ii) fluency (by applying grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\\n\\\n",
    "(iii) style (by ensuring the summaries is in a enaging mananer of social media post),\\n\\\n",
    "(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain;).\\n\\\n",
    "\n",
    "{constraints_and_example}\n",
    "\n",
    "Please put the final output in <final_summary> tags.\n",
    "Your output:\n",
    "\"\"\"\n",
    "reviewed_input = FINAL_SUMMARIZE_USER_PROMPT.format(constraints_and_example= constraints_and_example, text= article, summary= initial_response, reflection= reflection_response)\n",
    "\n",
    "reviewed_response = get_completion(reviewed_input, FINAL_SUMMARIZE_SYSTEM_PROMPT, model=model)\n",
    "print(\"Final output:\")\n",
    "print(reviewed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "You've done all the lab works. Happy prompting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
